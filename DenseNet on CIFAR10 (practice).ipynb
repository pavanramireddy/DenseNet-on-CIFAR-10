{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "wVIx_KIigxPV"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import models, layers, regularizers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import BatchNormalization, Activation, Flatten\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "UNHw6luQg3gc"
   },
   "outputs": [],
   "source": [
    "# this part will prevent tensorflow to allocate all the avaliable GPU Memory\n",
    "# backend\n",
    "import tensorflow as tf\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "dsO_yGxcg5D8"
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "batch_size = 64\n",
    "num_classes = 10\n",
    "epochs = 75\n",
    "l = 6\n",
    "num_filter = 32\n",
    "compression = 0.5\n",
    "dropout_rate = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "executionInfo": {
     "elapsed": 8458,
     "status": "ok",
     "timestamp": 1597935303448,
     "user": {
      "displayName": "Applied AI Course",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhuSQ5tWcMSEyUXWi5GYagbq0BttLJf6r6PPxrB=s64",
      "userId": "00484516897554883881"
     },
     "user_tz": -330
    },
    "id": "mB7o3zu1g6eT",
    "outputId": "d5da5d49-b5b0-442d-8095-c049f6051504"
   },
   "outputs": [],
   "source": [
    "# Load CIFAR10 Data\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "img_height, img_width, channel = X_train.shape[1],X_train.shape[2],X_train.shape[3]\n",
    "\n",
    "# convert to one hot encoing \n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 8430,
     "status": "ok",
     "timestamp": 1597935303450,
     "user": {
      "displayName": "Applied AI Course",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhuSQ5tWcMSEyUXWi5GYagbq0BttLJf6r6PPxrB=s64",
      "userId": "00484516897554883881"
     },
     "user_tz": -330
    },
    "id": "3lAk_Mw_5-rn",
    "outputId": "e8fbe50f-2cbf-4ad1-e1fd-d116fec50493"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 8423,
     "status": "ok",
     "timestamp": 1597935303451,
     "user": {
      "displayName": "Applied AI Course",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhuSQ5tWcMSEyUXWi5GYagbq0BttLJf6r6PPxrB=s64",
      "userId": "00484516897554883881"
     },
     "user_tz": -330
    },
    "id": "DVkpgHsc5-rp",
    "outputId": "2c100d0a-c980-4b3e-b55f-f05d5dc8c6a8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 32, 32, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=False,\n",
    "    samplewise_center=False,\n",
    "    featurewise_std_normalization=False,\n",
    "    samplewise_std_normalization=False,\n",
    "    zca_whitening=False,\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=False\n",
    "    )\n",
    "datagen.fit(X_train)\n",
    "img_gen = datagen.flow(X_train, y_train, batch_size=batch_size)\n",
    "steps = X_train.shape[0] // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "ee-sge5Kg7vr"
   },
   "outputs": [],
   "source": [
    "# Dense Block\n",
    "def denseblock(input, num_filter = 12, dropout_rate = 0.2):\n",
    "    global compression\n",
    "    temp = input\n",
    "    for _ in range(l): \n",
    "        BatchNorm = layers.BatchNormalization()(temp)\n",
    "        relu = layers.Activation('elu')(BatchNorm)\n",
    "        Conv2D_3_3 = layers.Conv2D(int(num_filter*compression), (3,3),kernel_regularizer=regularizers.l2(1e-4),\n",
    "                                   use_bias=False ,padding='same')(relu)\n",
    "        if dropout_rate>0:\n",
    "            Conv2D_3_3 = layers.Dropout(dropout_rate)(Conv2D_3_3)\n",
    "        concat = layers.Concatenate(axis=-1)([temp,Conv2D_3_3])\n",
    "        \n",
    "        temp = concat\n",
    "        \n",
    "    return temp\n",
    "\n",
    "## transition Blosck\n",
    "def transition(input, num_filter = 12, dropout_rate = 0.2):\n",
    "    global compression\n",
    "    BatchNorm = layers.BatchNormalization()(input)\n",
    "    relu = layers.Activation('elu')(BatchNorm)\n",
    "    Conv2D_BottleNeck = layers.Conv2D(int(num_filter*compression), (1,1),kernel_regularizer=regularizers.l2(1e-4),\n",
    "                                      use_bias=False ,padding='same')(relu)\n",
    "    if dropout_rate>0:\n",
    "         Conv2D_BottleNeck = layers.Dropout(dropout_rate)(Conv2D_BottleNeck)\n",
    "    avg = layers.AveragePooling2D(pool_size=(2,2))(Conv2D_BottleNeck)\n",
    "    return avg\n",
    "\n",
    "#output layer\n",
    "def output_layer(input):\n",
    "    global compression\n",
    "    BatchNorm = layers.BatchNormalization()(input)\n",
    "    relu = layers.Activation('elu')(BatchNorm)\n",
    "    AvgPooling = layers.AveragePooling2D(pool_size=(2,2))(relu)\n",
    "    flat = layers.Flatten()(AvgPooling)\n",
    "    output = layers.Dense(num_classes, activation='softmax')(flat)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "anPCpQWhhGb7"
   },
   "outputs": [],
   "source": [
    "input = layers.Input(shape=(img_height, img_width, channel,))\n",
    "First_Conv2D = layers.Conv2D(num_filter, (3,3), use_bias=False ,padding='same')(input)\n",
    "\n",
    "First_Block = denseblock(First_Conv2D, num_filter, dropout_rate)\n",
    "First_Transition = transition(First_Block, num_filter, dropout_rate)\n",
    "\n",
    "Second_Block = denseblock(First_Transition, num_filter, dropout_rate)\n",
    "Second_Transition = transition(Second_Block, num_filter, dropout_rate)\n",
    "\n",
    "Third_Block = denseblock(Second_Transition, num_filter, dropout_rate)\n",
    "Third_Transition = transition(Third_Block, num_filter, dropout_rate)\n",
    "\n",
    "Last_Block = denseblock(Third_Transition,  num_filter, dropout_rate)\n",
    "output = output_layer(Last_Block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 13803,
     "status": "ok",
     "timestamp": 1597935311171,
     "user": {
      "displayName": "Applied AI Course",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhuSQ5tWcMSEyUXWi5GYagbq0BttLJf6r6PPxrB=s64",
      "userId": "00484516897554883881"
     },
     "user_tz": -330
    },
    "id": "1kFh7pdxhNtT",
    "outputId": "c1464c86-cd44-4ca4-f175-500cfb03bf17",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 32, 32, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 32, 32, 32)   864         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 32, 32, 32)  128         ['conv2d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 32, 32, 32)   0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 32, 32, 16)   4608        ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 32, 32, 48)   0           ['conv2d[0][0]',                 \n",
      "                                                                  'conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 32, 32, 48)  192         ['concatenate[0][0]']            \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 32, 32, 48)   0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 32, 32, 16)   6912        ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 32, 32, 64)   0           ['concatenate[0][0]',            \n",
      "                                                                  'conv2d_2[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 32, 32, 64)  256         ['concatenate_1[0][0]']          \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 32, 32, 64)   0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 32, 32, 16)   9216        ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 32, 32, 80)   0           ['concatenate_1[0][0]',          \n",
      "                                                                  'conv2d_3[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 32, 32, 80)  320         ['concatenate_2[0][0]']          \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 32, 32, 80)   0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 32, 32, 16)   11520       ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 32, 32, 96)   0           ['concatenate_2[0][0]',          \n",
      "                                                                  'conv2d_4[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 32, 32, 96)  384         ['concatenate_3[0][0]']          \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 32, 32, 96)   0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 32, 32, 16)   13824       ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate)    (None, 32, 32, 112)  0           ['concatenate_3[0][0]',          \n",
      "                                                                  'conv2d_5[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 32, 32, 112)  448        ['concatenate_4[0][0]']          \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 32, 32, 112)  0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 32, 32, 16)   16128       ['activation_5[0][0]']           \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate)    (None, 32, 32, 128)  0           ['concatenate_4[0][0]',          \n",
      "                                                                  'conv2d_6[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 32, 32, 128)  512        ['concatenate_5[0][0]']          \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 32, 32, 128)  0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 32, 32, 16)   2048        ['activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " average_pooling2d (AveragePool  (None, 16, 16, 16)  0           ['conv2d_7[0][0]']               \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 16, 16, 16)  64          ['average_pooling2d[0][0]']      \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 16, 16, 16)   0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 16, 16, 16)   2304        ['activation_7[0][0]']           \n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate)    (None, 16, 16, 32)   0           ['average_pooling2d[0][0]',      \n",
      "                                                                  'conv2d_8[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 16, 16, 32)  128         ['concatenate_6[0][0]']          \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 16, 16, 32)   0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 16, 16, 16)   4608        ['activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " concatenate_7 (Concatenate)    (None, 16, 16, 48)   0           ['concatenate_6[0][0]',          \n",
      "                                                                  'conv2d_9[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 16, 16, 48)  192         ['concatenate_7[0][0]']          \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 16, 16, 48)   0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 16, 16, 16)   6912        ['activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " concatenate_8 (Concatenate)    (None, 16, 16, 64)   0           ['concatenate_7[0][0]',          \n",
      "                                                                  'conv2d_10[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 16, 16, 64)  256         ['concatenate_8[0][0]']          \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 16, 16, 16)   9216        ['activation_10[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_9 (Concatenate)    (None, 16, 16, 80)   0           ['concatenate_8[0][0]',          \n",
      "                                                                  'conv2d_11[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 16, 16, 80)  320         ['concatenate_9[0][0]']          \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 16, 16, 80)   0           ['batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 16, 16, 16)   11520       ['activation_11[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_10 (Concatenate)   (None, 16, 16, 96)   0           ['concatenate_9[0][0]',          \n",
      "                                                                  'conv2d_12[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 16, 16, 96)  384         ['concatenate_10[0][0]']         \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_12 (Activation)     (None, 16, 16, 96)   0           ['batch_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 16, 16, 16)   13824       ['activation_12[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_11 (Concatenate)   (None, 16, 16, 112)  0           ['concatenate_10[0][0]',         \n",
      "                                                                  'conv2d_13[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 16, 16, 112)  448        ['concatenate_11[0][0]']         \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_13 (Activation)     (None, 16, 16, 112)  0           ['batch_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 16, 16, 16)   1792        ['activation_13[0][0]']          \n",
      "                                                                                                  \n",
      " average_pooling2d_1 (AveragePo  (None, 8, 8, 16)    0           ['conv2d_14[0][0]']              \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 8, 8, 16)    64          ['average_pooling2d_1[0][0]']    \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_14 (Activation)     (None, 8, 8, 16)     0           ['batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 8, 8, 16)     2304        ['activation_14[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_12 (Concatenate)   (None, 8, 8, 32)     0           ['average_pooling2d_1[0][0]',    \n",
      "                                                                  'conv2d_15[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 8, 8, 32)    128         ['concatenate_12[0][0]']         \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_15 (Activation)     (None, 8, 8, 32)     0           ['batch_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 8, 8, 16)     4608        ['activation_15[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_13 (Concatenate)   (None, 8, 8, 48)     0           ['concatenate_12[0][0]',         \n",
      "                                                                  'conv2d_16[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 8, 8, 48)    192         ['concatenate_13[0][0]']         \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_16 (Activation)     (None, 8, 8, 48)     0           ['batch_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 8, 8, 16)     6912        ['activation_16[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_14 (Concatenate)   (None, 8, 8, 64)     0           ['concatenate_13[0][0]',         \n",
      "                                                                  'conv2d_17[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 8, 8, 64)    256         ['concatenate_14[0][0]']         \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_17 (Activation)     (None, 8, 8, 64)     0           ['batch_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 8, 8, 16)     9216        ['activation_17[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_15 (Concatenate)   (None, 8, 8, 80)     0           ['concatenate_14[0][0]',         \n",
      "                                                                  'conv2d_18[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_18 (BatchN  (None, 8, 8, 80)    320         ['concatenate_15[0][0]']         \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_18 (Activation)     (None, 8, 8, 80)     0           ['batch_normalization_18[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)             (None, 8, 8, 16)     11520       ['activation_18[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_16 (Concatenate)   (None, 8, 8, 96)     0           ['concatenate_15[0][0]',         \n",
      "                                                                  'conv2d_19[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_19 (BatchN  (None, 8, 8, 96)    384         ['concatenate_16[0][0]']         \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_19 (Activation)     (None, 8, 8, 96)     0           ['batch_normalization_19[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)             (None, 8, 8, 16)     13824       ['activation_19[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_17 (Concatenate)   (None, 8, 8, 112)    0           ['concatenate_16[0][0]',         \n",
      "                                                                  'conv2d_20[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_20 (BatchN  (None, 8, 8, 112)   448         ['concatenate_17[0][0]']         \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_20 (Activation)     (None, 8, 8, 112)    0           ['batch_normalization_20[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)             (None, 8, 8, 16)     1792        ['activation_20[0][0]']          \n",
      "                                                                                                  \n",
      " average_pooling2d_2 (AveragePo  (None, 4, 4, 16)    0           ['conv2d_21[0][0]']              \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " batch_normalization_21 (BatchN  (None, 4, 4, 16)    64          ['average_pooling2d_2[0][0]']    \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_21 (Activation)     (None, 4, 4, 16)     0           ['batch_normalization_21[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)             (None, 4, 4, 16)     2304        ['activation_21[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_18 (Concatenate)   (None, 4, 4, 32)     0           ['average_pooling2d_2[0][0]',    \n",
      "                                                                  'conv2d_22[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_22 (BatchN  (None, 4, 4, 32)    128         ['concatenate_18[0][0]']         \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_22 (Activation)     (None, 4, 4, 32)     0           ['batch_normalization_22[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)             (None, 4, 4, 16)     4608        ['activation_22[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_19 (Concatenate)   (None, 4, 4, 48)     0           ['concatenate_18[0][0]',         \n",
      "                                                                  'conv2d_23[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_23 (BatchN  (None, 4, 4, 48)    192         ['concatenate_19[0][0]']         \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_23 (Activation)     (None, 4, 4, 48)     0           ['batch_normalization_23[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)             (None, 4, 4, 16)     6912        ['activation_23[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_20 (Concatenate)   (None, 4, 4, 64)     0           ['concatenate_19[0][0]',         \n",
      "                                                                  'conv2d_24[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_24 (BatchN  (None, 4, 4, 64)    256         ['concatenate_20[0][0]']         \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_24 (Activation)     (None, 4, 4, 64)     0           ['batch_normalization_24[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)             (None, 4, 4, 16)     9216        ['activation_24[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_21 (Concatenate)   (None, 4, 4, 80)     0           ['concatenate_20[0][0]',         \n",
      "                                                                  'conv2d_25[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_25 (BatchN  (None, 4, 4, 80)    320         ['concatenate_21[0][0]']         \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_25 (Activation)     (None, 4, 4, 80)     0           ['batch_normalization_25[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)             (None, 4, 4, 16)     11520       ['activation_25[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_22 (Concatenate)   (None, 4, 4, 96)     0           ['concatenate_21[0][0]',         \n",
      "                                                                  'conv2d_26[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_26 (BatchN  (None, 4, 4, 96)    384         ['concatenate_22[0][0]']         \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_26 (Activation)     (None, 4, 4, 96)     0           ['batch_normalization_26[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)             (None, 4, 4, 16)     13824       ['activation_26[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_23 (Concatenate)   (None, 4, 4, 112)    0           ['concatenate_22[0][0]',         \n",
      "                                                                  'conv2d_27[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_27 (BatchN  (None, 4, 4, 112)   448         ['concatenate_23[0][0]']         \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_27 (Activation)     (None, 4, 4, 112)    0           ['batch_normalization_27[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_3 (AveragePo  (None, 2, 2, 112)   0           ['activation_27[0][0]']          \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 448)          0           ['average_pooling2d_3[0][0]']    \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 10)           4490        ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 225,962\n",
      "Trainable params: 222,154\n",
      "Non-trainable params: 3,808\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs=[input], outputs=[output])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 1167,
     "status": "ok",
     "timestamp": 1597935314969,
     "user": {
      "displayName": "Applied AI Course",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhuSQ5tWcMSEyUXWi5GYagbq0BttLJf6r6PPxrB=s64",
      "userId": "00484516897554883881"
     },
     "user_tz": -330
    },
    "id": "8Aqzk9AFXb1y",
    "outputId": "edb9053d-7b21-4a3b-ec99-4b4dd25604ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115\n"
     ]
    }
   ],
   "source": [
    "print(len(model.layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "b4XOsW3ahSkL"
   },
   "outputs": [],
   "source": [
    "# determine Loss function and Optimizer\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(learning_rate=0.001,decay=1e-6),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'my_best_model.epoch{epoch:02d}-accuracy{val_accuracy:.2f}.hdf5'\n",
    "checkpoint = ModelCheckpoint(filepath=filepath, \n",
    "                             monitor='val_accuracy',\n",
    "                             verbose=1, \n",
    "                             save_best_only=True,\n",
    "                             mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1771
    },
    "id": "crhGk7kEhXAz",
    "outputId": "e3e2d0d0-1492-41ab-df5b-5a7ecd705c2c",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n",
      "781/781 [==============================] - ETA: 0s - loss: 1.5504 - accuracy: 0.4597 - ETA - ETA: 41s - loss: 1.88 - ETA: 40s - loss: 1.8576 - accu - ETA: 39s - loss: 1.8444 - accuracy: 0 - ET - ETA: 36s - loss: 1.80 - ETA: 35s - loss: 1.7944 - acc - ETA: 34s - loss: 1.7850 - accuracy: 0.3 - ETA: 34s - loss: 1.7833 - accuracy: 0.3 - ETA: 33s - loss: 1. - ETA: 32s - loss: 1.7691 - accuracy - ETA: 31s - loss: 1.7636 - ETA: 30s - loss: 1.7506 - accuracy: - ETA: 30s - loss: 1.7452 - accuracy - ETA: 29s - loss: 1.7400 - accurac - ETA: 28s - loss: 1.7 - ETA:   - ETA: 19s - loss: 1.6661 - accuracy:  - ETA: 19s - loss: 1.6622 - accuracy: 0.416 - ETA: 19s - loss: 1.6616 - accurac - ETA: 18s - loss - ETA: 16s - loss: 1.6470 - accuracy: - ETA: 16s - loss: 1.6434 - accuracy: 0. - ETA: 16s -  - ETA:  - ETA - ETA: 2s - - ETA: 1s - loss: 1.5564 - accuracy: 0. - ETA: 0s - loss: 1.555 - ETA: 0s - loss: 1.5527 - accura\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.51650, saving model to my_best_model.epoch01-accuracy0.52.hdf5\n",
      "781/781 [==============================] - 66s 74ms/step - loss: 1.5504 - accuracy: 0.4597 - val_loss: 1.5459 - val_accuracy: 0.5165\n",
      "Epoch 2/75\n",
      "781/781 [==============================] - ETA: 0s - loss: 1.1751 - accuracy: 0.6077 - ETA: 47s - loss: 1.2782 - accuracy: 0. - ETA: 47s - ETA: 45s  - ETA: 42s - loss: 1.2749 - accurac - ETA: 42s - loss: 1.2691  - ETA: 37s - loss: 1.2640 - accuracy: 0.5 - ETA: 37s - loss: 1.2 - ETA: 36s - loss - ETA: 34s - loss: 1 - ETA: 32s - loss: 1.2431 - accuracy: 0. - ETA: 32s -  - ETA: 27s - loss: 1.2300 - accuracy:  - ETA: 27s - loss: 1.2282  - ETA: 26s - los - ETA: 18s - loss:  - ETA: 16s - loss: 1.2027 - accuracy: 0.5 - ETA: 16s - loss: 1.2025 - accuracy: 0 - ETA: 16s - loss: 1.2 - - ETA: 12s - loss: 1. - ETA: 1s - loss: 1.1768 -  - ETA: 0s - loss: 1.1770 - accuracy:  - ETA: 0s - loss: 1.1 - ETA: 0s - loss: 1.1751 - accuracy: 0.6078\n",
      "Epoch 00002: val_accuracy improved from 0.51650 to 0.63510, saving model to my_best_model.epoch02-accuracy0.64.hdf5\n",
      "781/781 [==============================] - 56s 72ms/step - loss: 1.1751 - accuracy: 0.6078 - val_loss: 1.1833 - val_accuracy: 0.6351\n",
      "Epoch 3/75\n",
      "781/781 [==============================] - ETA: 0s - loss: 1.0302 - accuracy: 0.6638 - ETA - ETA: 46s - loss: 1.0569 - accurac - ETA: 45s - loss: 1.0600 - - ETA: 44s - loss: 1.0591 - accura - ETA: 43s - loss: 1.0620 - accuracy: 0.652 - ETA: 43s - loss: 1.0625 - accuracy: 0.652 - ETA: 43s - l - ETA: 41s - loss: 1.0558 - accuracy: - ETA: 40s - loss: - ETA: 38s - loss: 1.0541 - accurac - ETA: 38s - los - ETA: 36s - loss: 1.0472 - accuracy: 0.6 - ETA: 36s - loss: 1.0483 - accuracy: 0.6 - ETA: 36s - loss: 1.0494 - accuracy: 0.65 - ETA: 35s - loss:  - ETA: 34s - loss: 1.0468 - accuracy: - ETA: 33s - loss: 1.0470 - accuracy:  - ETA: 33s - loss: 1.0460 - accuracy: 0 - ETA: 33s - lo - ETA: 25s - loss: 1.0444 - accuracy: 0.6 - ETA: 25s - loss: 1.0453 - accur - ETA: 24s - loss: 1.0420 - accuracy: 0.657 - ETA: 24s - loss: 1.0418 - - ETA: 23s - loss: 1.0419 - a - ETA: 19s - loss: 1.0401 - accuracy: 0.658 - ETA: 19s - loss: 1.03 - ETA: 17s - loss: 1.0395 - accuracy: 0.6 - ETA: 17s - loss: 1.0395 - ETA: 16s - loss: 1.03 - ETA: 14s - loss: 1.0382 - accuracy: 0.659 - ETA: 14s - loss: 1.0383 - accuracy: - ETA: 14s - loss: 1.0377 - accuracy: 0.6 - ETA: 14s - loss: 1.0375 - acc - E\n",
      "Epoch 00003: val_accuracy improved from 0.63510 to 0.65450, saving model to my_best_model.epoch03-accuracy0.65.hdf5\n",
      "781/781 [==============================] - 56s 72ms/step - loss: 1.0302 - accuracy: 0.6638 - val_loss: 1.1029 - val_accuracy: 0.6545\n",
      "Epoch 4/75\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.9513 - accuracy: 0.6955 - ETA: 50s - loss:  - ETA: 49s - loss: 0.9654 - accuracy - ETA: 48s - loss: 0.9683  - ETA: 47s - loss: 0.9624 - accuracy: 0.69 - ETA: 47s - loss: 0.9621 - accuracy: 0 - ETA: 47s - loss: 0.9664 - accuracy:  - ETA: 46s - loss: 0.9599 - accuracy: 0.69 - ETA: 46s  - ETA: 44s - los - ETA: 43s - loss: 0.9566 - accuracy: - ETA: 42s - loss: 0.9604 - ac - ETA: 41 - ETA: 38s - loss: 0.9670 - accuracy - ETA: 38s - loss: 0.9686 - accuracy:  - ETA: 38s - loss: 0.9682 - accuracy: 0.688 - ETA: 37s - loss: 0.9690 - accura - ETA: 37s - loss: 0.9655 - accur - ETA: 36 - ETA: 34s - loss: 0.9666 - accur - ETA: 33s - loss: 0.9651 - accuracy: 0 - ETA: 33s - - ETA: 28s - ETA: 25s - loss: 0.9628 - accuracy:  - ETA: 25s - loss: 0.9631 - accuracy: 0 - ETA: 25s - loss:  - ETA: 23s - loss: 0.9 - ETA: 22s - loss: 0.9614 - accuracy: - ETA: 21s - loss: 0.9621  - ETA: 20s - loss: 0.961 - ETA: 19s - loss: 0. - ETA: 17s - loss: 0.9608 - accuracy: 0. - ETA: 17s - loss: 0.9609 - accuracy: 0.6 - ETA: 17s - loss: 0.9607 - accuracy:  - ETA: - ETA: 3s - loss: 0.9543 - accu\n",
      "Epoch 00004: val_accuracy improved from 0.65450 to 0.66380, saving model to my_best_model.epoch04-accuracy0.66.hdf5\n",
      "781/781 [==============================] - 57s 73ms/step - loss: 0.9513 - accuracy: 0.6955 - val_loss: 1.1145 - val_accuracy: 0.6638\n",
      "Epoch 5/75\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.8975 - accuracy: 0.7124 - ETA: 49s - loss: 0.8487 - ETA: 49s - ETA: 47s - loss: 0.9289 - accuracy - ETA: 43s - l - ETA: 41 - ETA: 39s - loss: 0.9216 - accurac - ETA: 3 - ETA: 36s - loss: 0.9109 - accura - ETA: 35s - loss: 0.9115 - accuracy: 0.70 - ETA: 35s - loss: 0. - ETA: 34s - lo - ETA - ETA: 29s - loss: 0.9104 - accuracy: 0. - ETA: 29s - los - ETA: 27s - loss: 0.9102 - accur - ETA: 27s - loss: 0.9 - ETA: 25s - loss: 0.9079 - accuracy: 0.70 - ETA: 25s - loss: 0.9081 - accuracy - ETA: 24s - loss: 0.9093 - accuracy - ETA: 24s - loss: 0.9110 - accuracy: 0.706 - ETA: 24s  - ETA: 22s - loss: 0.9083 - accuracy: 0 - ETA: 21s - loss: 0.9084 - accuracy:  - ETA: 21s - loss: - ETA: 19s - loss: 0.9070 - ETA: 18 - ETA: 16s - loss: 0.9 - ETA: 14s - loss:  -  - ETA: 8s - loss: 0.8998 - accuracy: 0. - ETA:  - E - ETA: 6s - loss: 0.8980 - accu - ETA: 0s - loss: 0.8973 - accuracy: 0.7125\n",
      "Epoch 00005: val_accuracy improved from 0.66380 to 0.72760, saving model to my_best_model.epoch05-accuracy0.73.hdf5\n",
      "781/781 [==============================] - 56s 72ms/step - loss: 0.8973 - accuracy: 0.7125 - val_loss: 0.9115 - val_accuracy: 0.7276\n",
      "Epoch 6/75\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.8563 - accuracy: 0.7288 - ETA: 50s - loss: 0.8 - ETA: - ETA: 43s - loss: 0.8511 - accuracy - ETA: 43s - loss: 0.8510 - accuracy: 0.727 - ETA: 4 - E - ETA: 32s - loss: 0.8578 - accuracy - ETA: 32s - loss: 0.8574 - a - ETA: 31s - loss: 0.8563 - - ETA: 29s - loss: 0.8541 - accuracy: 0.727 - ETA: 29s - loss: 0.8539 - accuracy - ETA: 29s - loss: 0.8548 - acc - ETA: 28s - loss: 0.8548 - accuracy: 0. - ETA: 28s - loss: 0.8532 - accuracy: 0. - ETA: 27s - loss: 0.8542 - accurac - ETA: 27s - loss: 0.8521 - ETA: 26s - loss: 0.8519 - accurac - ETA: 25s - loss: 0.851 - ETA: 24s -  - ETA: 22s - loss: 0.8543  - ETA: 18s - loss: 0.8543 - accuracy: 0 - ETA: 17s - loss: 0.8549 - a - ETA: 16s - loss: 0.8553 - - ETA: 15s - loss: 0.8570  - ETA: 14s - los - ETA: 12s - loss: 0.8574 - a - ETA: 11s - loss: 0.8596 - accuracy: 0.72 - ETA: 11s - loss: 0.8592 - accur - ETA: 10s - loss: 0.8596 - accuracy: 0.72 - ETA: 10s - loss: 0.8599 - accuracy - E - ETA: 1s - los - ETA: 0s - loss: 0.8558 - accuracy: 0. - ETA: 0s - loss: 0.8555 - accura\n",
      "Epoch 00006: val_accuracy improved from 0.72760 to 0.73460, saving model to my_best_model.epoch06-accuracy0.73.hdf5\n",
      "781/781 [==============================] - 56s 72ms/step - loss: 0.8563 - accuracy: 0.7288 - val_loss: 0.8778 - val_accuracy: 0.7346\n",
      "Epoch 7/75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "781/781 [==============================] - ETA: 0s - loss: 0.8191 - accuracy: 0.7436 - ETA: 49s -  - ETA: 47s - loss: 0.8406 - accuracy:  - ETA: 47s - loss: 0. - ETA: - ETA: 39s - loss: 0.8210 - accuracy: 0 - ETA: 39s - - ETA: 37s - l - ETA: 35s - loss: 0.823 - ETA: 33s - loss: - ETA: 32s - - ETA: 30s - loss: 0.8210 - accuracy: 0.740 - E - ETA: 27s - loss: 0.8245 - accuracy - ETA: 26s - loss: 0.8235 - accuracy: - ETA: 26s - loss: 0.8230  - ETA: 25s - loss: 0.8221 - ac - ETA: 24s -  - ETA: 22s - loss: 0.8230 - accuracy: 0.7 - ETA: 22s - loss: 0.8223 - accuracy:  - E - ETA: 18s - loss: 0.8241 - accurac - ETA: 18s - loss: 0.8234 - accuracy: 0.7 - ETA: 18s -  - ETA: - ETA: 13s - loss: 0.8238  - ETA: 12s - loss - ETA: 8s - loss: 0 - ETA: 8s - loss: 0.8192 - accura - ETA: 7s - loss: 0.8187 - accu - ETA: 7s - loss: 0.8191 - accuracy: 0.74 - ETA: 7s - loss: 0.8 - ETA: 6s - loss: 0.8191 - accuracy: 0. - ETA: 6s - los - ETA\n",
      "Epoch 00007: val_accuracy improved from 0.73460 to 0.74400, saving model to my_best_model.epoch07-accuracy0.74.hdf5\n",
      "781/781 [==============================] - 56s 72ms/step - loss: 0.8191 - accuracy: 0.7436 - val_loss: 0.8462 - val_accuracy: 0.7440\n",
      "Epoch 8/75\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.7860 - accuracy: 0.7593 - ETA: 49s - loss: 0.8530 - accuracy: - ETA: 50s - loss: 0.8432 - accuracy: 0.747 - ETA: 49s - loss: 0.8456 - accuracy - ETA: 50s - loss: 0.8215 - accura - ETA: 4 - ETA: 40s - loss: 0.8016 - accu - ETA: 40s - loss: 0.8009 - accu - ETA: 39s - loss: 0.8005 - accuracy - ETA: 38s - loss - ETA: 33s - loss: 0.7995 - a - ETA: 30s - loss: 0.7992 - accuracy: - ETA: 29s - loss: 0.7971 - accurac - ETA: 28s - loss: 0.7950  - ETA: 27s - loss: 0.7966 - accurac - ETA: 27s - loss: 0.7972 - acc - ETA: 26s - loss: 0. - ETA: 24s - l - ETA: 22s - loss: 0.7938 - accuracy: 0.755 - ETA: 2 -  - ETA: 17s - loss: 0.7935 - ac - ETA: 13s - loss: 0.7945 - accuracy: 0. - ETA: 13s - loss: 0.7936 - accuracy: - ETA: 12 - ETA: 10s - loss: 0.7920 - accuracy: 0. - ETA: 10s - l - ETA: 9s - loss: 0.7901 -  - ETA: 8s - loss: 0.7 - ETA: 7s - loss: 0.7889 - accu - ETA: 7s - loss: 0.789 - ETA: 6s - loss: 0.7889 - accu - ETA: 6s - loss: 0.7879 - accuracy - ETA - ETA: 3s - loss: 0.7864 - accu - ETA: 3s - loss: 0.7858 - accuracy - ETA: 2s - loss: 0 - ETA: 0s - loss: 0.785\n",
      "Epoch 00008: val_accuracy improved from 0.74400 to 0.75820, saving model to my_best_model.epoch08-accuracy0.76.hdf5\n",
      "781/781 [==============================] - 56s 72ms/step - loss: 0.7860 - accuracy: 0.7593 - val_loss: 0.7971 - val_accuracy: 0.7582\n",
      "Epoch 9/75\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.7613 - accuracy: 0.7677 - ETA: 50s - loss: 0.7394 - accuracy: - ET - ETA - ETA: 44s - loss: 0.7736 - accur - ETA: 43s - loss: 0.7711 - a - ETA: 42s - loss: 0.7683 - accur - ETA: 42s - loss: 0.7643 - ETA: 38s - loss: 0.7642 - accuracy - ETA: 37s - los - ETA: 35s - loss: 0.7595 -  - ETA: 34s - loss: 0.7614 - accuracy: 0. - ETA: 34s - loss: 0.7622 - a - ETA: 33s - loss: 0.7629 - accu - ETA: 32s - loss: 0.7634  - ETA: 31s - loss: 0.7650 - accurac - ETA: 30s -  - ETA: 22s  - ETA: 20s - loss: 0.7621 - accuracy: - ETA: 20s - loss: 0.7614 - accuracy - ETA: 16s - loss: 0.762 - ETA: 8s - loss: 0.7610 - accuracy: 0.76 - ETA: 8s - loss: 0.7614 - accuracy: 0.76 - ETA: 8s - loss: 0.7615 - accuracy:  - ETA: 8s - loss: 0.7 - ETA: 4s - loss: 0.7603 - accuracy: 0.76\n",
      "Epoch 00009: val_accuracy improved from 0.75820 to 0.76610, saving model to my_best_model.epoch09-accuracy0.77.hdf5\n",
      "781/781 [==============================] - 56s 72ms/step - loss: 0.7613 - accuracy: 0.7677 - val_loss: 0.7768 - val_accuracy: 0.7661\n",
      "Epoch 10/75\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.7399 - accuracy: 0.7769 - ETA: 49s - loss: 0.7 - ETA: 48s - loss - ETA: 47s - loss: 0.7 - ETA: 45s - loss: - ETA: 43s - loss: 0.7375 - accuracy - E - ETA: 40s - loss: 0.7382 - accuracy: - ETA: 39s - loss: 0.7374 - accuracy: 0.7 - ETA - ETA: 34s - loss: 0.7457 -  - ETA: 30s - loss: 0.7455 - accuracy: 0.77 - ETA: 29s - loss: 0.7454 - accuracy: - ETA: 29s - loss: 0.7451 - accuracy: 0 - ETA: 29s - loss: 0.7460 - - ETA: 28s - loss: 0.7435 - accuracy: 0.774 - ETA: 27s - loss: - ETA: 11s - loss: 0.7428 - accuracy: - ETA: 1 - ETA: 7s - loss: 0.7 - ETA:  - ETA: 5s - loss: 0.7404 - accuracy: 0. - ETA:  - ETA: 4s - loss: 0.7405 - accu - ETA: 4s - loss: 0.7406 - accuracy: 0. - ETA:  - ETA: 2s - - ETA: 1s - ETA: 0s - loss: 0.7407 - accu - ETA: 0s - loss: 0.7404 - accura\n",
      "Epoch 00010: val_accuracy improved from 0.76610 to 0.77070, saving model to my_best_model.epoch10-accuracy0.77.hdf5\n",
      "781/781 [==============================] - 56s 72ms/step - loss: 0.7399 - accuracy: 0.7769 - val_loss: 0.7890 - val_accuracy: 0.7707\n",
      "Epoch 11/75\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.7216 - accuracy: 0.7824 - ETA: 48s - loss: 0.7279 - ac - ETA: 47s - loss: 0.7426 - accuracy - ETA: 47s - loss: 0.7446 - accuracy: - ETA: 46s - loss: 0.7420 - ac - ETA: 42s - loss: 0.7352 - accuracy: 0. - ETA: 42s - loss: 0.7311 - accuracy: 0 - ETA: 41s - loss: 0.7294 - accuracy: 0.780 - ETA: 41s - loss: 0.7290 - accuracy: 0.78 - ETA: 41s - loss: 0.7304 - accuracy: 0. - ETA: 41s - loss: 0.7275 - accuracy: 0 - ETA: 38s - loss: 0.7323 - ETA: 36s - loss: 0.7294 - accurac - ETA: 33s - loss: 0.7342 - accuracy: 0.780 - ETA: 32s - loss: 0.73 - ETA: 31s - lo - ETA: 29s - loss: 0.7335 - accuracy: 0 - ETA: 29s - loss: 0.7 - ETA: 28s - loss: 0.7322 - accuracy: 0.77  - ETA: 25s - loss: 0.7298 - accuracy: 0.7 - ETA: 24s - loss: 0.7294 - - ETA: 23s - loss: 0.7280 -  - ETA: 19s - loss: 0.7255 - accuracy: 0.7 - ETA:  - ETA: 3s - loss: 0.7227 - accuracy - E - ETA: 0s - loss: 0.7220 - accura - ETA: 0s - loss: 0.7217 - accuracy: 0.7824\n",
      "Epoch 00011: val_accuracy improved from 0.77070 to 0.79280, saving model to my_best_model.epoch11-accuracy0.79.hdf5\n",
      "781/781 [==============================] - 56s 72ms/step - loss: 0.7217 - accuracy: 0.7824 - val_loss: 0.7087 - val_accuracy: 0.7928\n",
      "Epoch 12/75\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.6984 - accuracy: 0.7919 - ETA: 49s - loss: 0.6793 - accur - ETA: 49s - loss: 0 - ETA: 48s - loss: 0.6665 - accuracy: 0.79 - ETA: 47s - l - ETA: 45s - loss: 0.6818 - ac - ETA: 45s - lo - ETA: 43s - loss: 0.6837 - accuracy: 0 - ETA: 42s - loss: 0.6829 - accurac - ETA: 42s - loss: 0.6839 - acc - E - ETA: 38s - loss: 0.68 - ETA: 37s - loss: 0.6 - ETA: 35s - loss: 0.690 - ETA: 34s - loss: 0.6944 - accuracy: 0 - ETA: 34s - loss: 0.6947 -  - ETA: 33s - loss: 0.6958 - accuracy:  - ETA: 29s - loss: 0.6960 - accuracy - ETA: 23s - loss: 0.6958 - accu - ETA: 19s - loss: 0.6973  - ETA: 18s - loss: 0.69 - ETA: 17s - loss:  - ETA: 15s - loss: 0.6968 - acc - ETA: 14s - loss: 0.6965 - a - ETA: 13s - loss: 0.6968 - accuracy: 0.792 - ETA: 13s - loss: 0.6969 - accu - ETA: 12s - loss: 0.6976 - accur - ETA: 12s - loss: 0.6971 - accuracy: 0.7 - ETA: 11s - loss: 0.6971 - accuracy: 0.792 - ETA: 11s - l - E - -\n",
      "Epoch 00012: val_accuracy improved from 0.79280 to 0.80210, saving model to my_best_model.epoch12-accuracy0.80.hdf5\n",
      "781/781 [==============================] - 56s 72ms/step - loss: 0.6984 - accuracy: 0.7919 - val_loss: 0.6832 - val_accuracy: 0.8021\n",
      "Epoch 13/75\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.6827 - accuracy: 0.7977 - ETA: 49s - l - ETA: 29s - loss: 0.6737 - accuracy: 0.798 - ETA: 29s - loss: 0.6735 - acc - ETA: 28s - loss: 0.6753 -  - ETA: 21s - loss: 0.6796 - accu - ETA: - ETA: 18s - loss: 0.6786 - accuracy - ETA: 14s - loss: 0.68 - ETA: 13s  - ETA: 10s - loss: 0.6816 - accuracy: 0.797 - ETA: 10s - loss: 0.6813 - accurac - ETA: 10s - loss - ETA: 9s - loss: - ETA: 6s - l - ETA: 3s - loss: 0.6 - ETA: 0s - los\n",
      "Epoch 00013: val_accuracy did not improve from 0.80210\n",
      "781/781 [==============================] - 56s 72ms/step - loss: 0.6827 - accuracy: 0.7977 - val_loss: 0.7267 - val_accuracy: 0.7920\n",
      "Epoch 14/75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "781/781 [==============================] - ETA: 0s - loss: 0.6746 - accuracy: 0.80107 - ETA: 48s - loss: 0.7 - ETA: 46s - loss: 0.6710 - accu - ETA: 45s - loss: 0 - ETA:  - ETA: 41s - loss: 0.67 - ETA: 40s - loss: 0.6764 -  - ETA: 36s - loss: 0.6763 - a - ETA: 35s - loss: 0.6737 - accuracy: 0.802 - ETA: 35s - loss: 0.6746 - accuracy: 0.8 - ETA: 35s - loss: 0.6732 - accurac - ETA: 34s - loss: 0.6738 - a - ETA: 33s - loss: 0.6755 - accuracy: 0.80 - ETA: 33s - loss: 0.6756 - ET - ETA: 26s - loss: 0.67 - ETA: 25s - loss: 0.6752 - ETA: 24s - loss: 0.6740 - accuracy: 0.801 - ETA: 24s - loss:  - ETA: 22s - loss: 0.6730 - accuracy: 0.8 - ETA: 22s - loss: 0.6738 - accuracy: 0.80 - ETA: 22s - loss: 0.6732 - accurac - ETA: 21s - loss: 0.6729 - acc - ETA: 20s - lo - ETA: 15s - loss:  - ETA: 14s - loss: 0.675 - ETA: 12s - loss: 0.6763 - accur - ETA: 12s - loss:  - ETA: 10s - loss: 0.6764 - accuracy:  - ETA: 9s  - ETA: 4s - loss: 0.6759 - accuracy - ETA: 4s - los - ETA: 3s - loss: 0.6762 - accu\n",
      "Epoch 00014: val_accuracy improved from 0.80210 to 0.80250, saving model to my_best_model.epoch14-accuracy0.80.hdf5\n",
      "781/781 [==============================] - 56s 72ms/step - loss: 0.6746 - accuracy: 0.8010 - val_loss: 0.7057 - val_accuracy: 0.8025\n",
      "Epoch 15/75\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.6614 - accuracy: 0.8066 - ETA: 51s - loss: 0.7073  - ETA: 49s - loss: 0.66 - ETA: - ETA - ETA: 39s - loss: 0.6703 - accuracy: 0.8 - ETA: 39s - loss: 0.6694 - accuracy: 0.80 - ETA: 39s - loss: 0.6693 - accuracy: 0.8 - ETA: 38s - loss: 0.671 - ETA: 37s - loss: 0.6662 - accuracy: 0. - ETA: 37s - loss: 0.6676 - accuracy:  - ETA:  - ET - ETA:  - ETA: 26s - loss:  - ETA: 22s - loss: 0.66 - ETA: 20s - loss: 0.6632 - accuracy: 0.80  - ETA: 17s - loss: 0.6638 - accuracy: - ETA: 17s - loss: 0.6642 - accuracy: 0.80 - ETA: 16s - loss: 0.6641 - a - ETA: 15s - loss: 0.6631 - accura - ETA: 15s - loss: 0.6633 - accuracy - ETA: 14s - loss: 0.6631 - accuracy: 0 - ETA: 14s - loss: 0.6630 - - ETA: 7s - los - ETA: 4s - l - ETA: 3s - l - ETA: 2s - loss: 0.662 - ETA: 2s - loss: 0.661\n",
      "Epoch 00015: val_accuracy improved from 0.80250 to 0.81270, saving model to my_best_model.epoch15-accuracy0.81.hdf5\n",
      "781/781 [==============================] - 57s 73ms/step - loss: 0.6614 - accuracy: 0.8066 - val_loss: 0.6608 - val_accuracy: 0.8127\n",
      "Epoch 16/75\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.6481 - accuracy: 0.8119 - ETA: 49s - loss: 0.6263 - accuracy:  - ETA: 49s - loss: 0.6271 - accuracy - ETA: 49s - loss: 0.6452 - accuracy: 0. - ETA: 48s - loss: 0.6350  - ETA: 48s - loss: 0.6366 - - ETA: - ETA: 4 - ETA: 39s - loss: 0.6502 - accuracy: 0.8 - ETA: 39s - loss: 0.6494 - acc - ETA: 38s - loss: 0.647 - ETA: 37s - loss: 0.6488 - accurac - - ETA: 33s - loss: 0.6524 - ETA: 32s - loss: 0.6490 - accuracy: 0. - ETA: 32s - loss: 0.6485 - accuracy: 0.81 - ETA: 32s - loss: 0.6482 - accuracy: 0. - ETA: 31s - ETA: 29s - loss:  - ETA: 27s - loss: 0.6457 - ETA: 23s - loss: 0.6441 - accuracy - ETA: 23s - loss: 0.643 - ETA: 21s - loss: 0.6452 - - ETA: 2 - ETA: 18s - loss: 0.6454  - ETA: 17s - loss: 0.6457 - a - ETA: 16s - loss: 0.6461 - accuracy: 0. - ETA: 15s - loss: 0.6463 - accura - ETA: 15s - ETA: 6s - loss: 0.6477 - accuracy: 0.81 - ETA:  - ETA: 5s - loss: 0.6476 - ac - ETA: 0s - loss:\n",
      "Epoch 00016: val_accuracy did not improve from 0.81270\n",
      "781/781 [==============================] - 56s 72ms/step - loss: 0.6481 - accuracy: 0.8119 - val_loss: 0.6872 - val_accuracy: 0.8053\n",
      "Epoch 17/75\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.6395 - accuracy: 0.8135 - ETA: 47s - loss: 0.6305 - - ETA: 46s - loss:  - ETA: 44s - loss: 0.6236 -  - ETA: 41s - loss: 0.6311 - accuracy:  - ETA: 40s - loss: 0.6371 - accur - ETA: 39s - loss: 0.6354  - ETA: 38s - loss: 0.6388 - accuracy: 0. - ETA: 38s - loss:  - ETA: 36s - loss: 0.6332 - accuracy: 0.8 - ETA: 36s - loss: 0.6348 - - ETA: 35s - loss: 0.6324 - accuracy - ETA: 34s - loss: 0.6328 - accuracy: 0. - ETA: 3 - ETA: 32s - loss: 0.6 - ETA: 30s - loss:  - ETA: 29s - loss: 0.6409 - accuracy: 0.81 - ETA: 29s - loss: 0.6403 - accuracy:  - ETA: 28s - loss: 0.6410 - accuracy: - ETA: 28s - loss: 0.6427 - accuracy:  - ETA: 27s - loss: 0.6414 - accuracy:  - ETA: 27s - loss: 0.6407 - accuracy: - ETA: - ETA: 24 - ETA: 13s  - ETA: 10s - loss: 0.63 - ETA: 9s - loss: 0.6390 - accu - ETA: 9s - loss: 0.6 - ETA: 8s - ETA: 7s - loss: 0.6396 - ac - E\n",
      "Epoch 00017: val_accuracy did not improve from 0.81270\n",
      "781/781 [==============================] - 56s 72ms/step - loss: 0.6395 - accuracy: 0.8135 - val_loss: 0.6964 - val_accuracy: 0.8011\n",
      "Epoch 18/75\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.6331 - accuracy: 0.8173 - ETA: 42s - loss: 0.6276 - accu - ETA: 41s - loss: 0.6266 - accuracy: 0. - ETA: 41s - lo - ETA: 30s - loss: 0.6264 - accuracy: 0.819 - ETA: 30s - loss: 0.6260 - accuracy - ETA: 30s - loss: 0.6265 - accura - ETA: 26s - loss: 0.6309 - accurac - ETA: 26s - loss: 0.6314 - ac - ETA: 25s - loss: 0.6311 - accuracy: 0.817 - ETA: 25s - loss: - ETA: 23s - loss: 0.6302 - accuracy: 0.81 - ETA: 23s - loss: 0.6304 - accuracy:  - ETA: 23s - loss: 0.6301 - - ETA: 21s - ETA: 19s -  - ETA: 17s - loss: 0.6323 - accuracy: 0.81 - ET - ETA: 15s - loss: 0.634 - ETA: 1s - loss: 0.6347 - accuracy: 0. - ETA: 1s - loss: 0.6346 - accuracy:  - ETA: 1s - loss: 0.6343 - accu - ETA: 0s - loss: 0\n",
      "Epoch 00018: val_accuracy did not improve from 0.81270\n",
      "781/781 [==============================] - 56s 72ms/step - loss: 0.6331 - accuracy: 0.8173 - val_loss: 0.6794 - val_accuracy: 0.8075\n",
      "Epoch 19/75\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.6208 - accuracy: 0.8219 - ETA: 51s - loss: 0.6166 - accuracy: 0. - ETA: 51s - loss: 0.6474 - accuracy: 0. - ETA: 50s - loss: 0.6356 - accuracy:  - ETA: 49s - loss: 0.6331 - accuracy:  - ETA: 49s - loss: 0.6226 - accuracy: 0.826 - ETA: 49s - loss: 0. - ETA: 47s - ETA: 45s - loss: 0. - ETA: 44s - loss: 0.6165 - accuracy: 0 - ETA: 43s - loss:  - ETA: 42s -  - E - ETA: 37s - loss: 0.6151 - accuracy: 0. - ETA: 37s - loss: 0 - ETA: 35s - loss: 0.6174 - ETA: 34s - loss: 0.6136 - ac - ETA: 33s - loss: 0.6179 - accuracy - ETA: 32s - loss: 0.6172 - accuracy: 0.8 - E - ETA: 29s - loss: 0.6186 - accu - ETA: 29s - loss: 0.6186 - a - ETA: 28s - l - ETA: 26s - loss:  - ETA: 24s - loss: 0.6211 - accura - ETA: 23s - loss: 0.6216 - accu - ETA: 23s - loss: 0.6211 - accuracy: 0 - ETA: 22s - loss: 0.62 - ETA: 21s - loss: 0.6194 - accuracy: - ETA: 20s - loss: 0.6185 - accura - ETA: 20s - loss: 0.6190 - accuracy: 0.82 - ETA: 20s - loss: 0.6191 - a - ETA: 19s - loss: 0.61 - ETA: 17s - loss: 0.6188 - accurac  - ETA: 14s - l - ETA: 3s - loss: 0.6 - ETA: 2s - loss: 0.6193 - accuracy: 0.82 - - ETA: 0s - loss: 0.6210 - accuracy: 0.8219\n",
      "Epoch 00019: val_accuracy did not improve from 0.81270\n",
      "781/781 [==============================] - 57s 72ms/step - loss: 0.6210 - accuracy: 0.8219 - val_loss: 0.6848 - val_accuracy: 0.8077\n",
      "Epoch 20/75\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.6098 - accuracy: 0.8247 - ETA: 47s - loss: 0.6310 - accuracy: - ETA: 47s - loss: 0.6327 - accuracy: 0.81 - ETA: 47s - loss: 0.6335 - ETA: 45s - loss: 0.6459 - accu - ETA: 44s - loss: 0.6341 - accuracy: 0.814 - ETA: 44s - loss: 0.6347 -  - E - ETA: 41s - loss: 0 - ETA: 39s - loss: 0.6245 - accur - ETA: 38s - loss: 0.6169 - accuracy: - ETA: 38s - loss: 0.6191 -  - ETA: 37s - loss: 0.6152 - - E - ETA - ETA: 24s - loss: 0 - ETA: 23s - loss: 0.6096 - accuracy: 0 - ETA: 22s - loss: 0.6103 - accuracy: - - ETA: 16s - loss: 0.6076 - accuracy: 0. - ETA: 16s - loss: 0.6071 - accuracy: 0.8 - ETA: 16s - loss: 0.6072 - accuracy  - ETA: - ETA: 2s - loss: 0.6078 - accu - ETA: 2s - loss: 0.6081 - accuracy - ETA: 2s - loss: 0.6083 - accuracy: 0.82 - ETA: 2s - loss: 0.6083 - ac - ETA: 1s - los - ETA: 0s - loss: 0.609\n",
      "Epoch 00020: val_accuracy did not improve from 0.81270\n",
      "781/781 [==============================] - 56s 72ms/step - loss: 0.6098 - accuracy: 0.8247 - val_loss: 0.7760 - val_accuracy: 0.7811\n",
      "Epoch 21/75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "781/781 [==============================] - ETA: 0s - loss: 0.6076 - accuracy: 0.8258 - ETA: 42s - loss: 0.6041 - accuracy: 0.82 - ETA: 41s - loss: 0.6033 - - ETA: 37s - los - ETA: 35s - loss: 0.6066 - accuracy: 0.8 - ETA: 35s - loss: 0.6065 - accuracy: 0.8 - ETA: 35s - loss: 0.6045 -  - ETA: 31s - loss: 0.6050 - accuracy: 0.8 - E - ETA: 28s - loss: 0.6054 - accuracy: - ETA: 28s - loss: 0.6051 - a - ETA: 27s - loss: 0.6060 - accuracy - ETA: 26s - loss: 0.6060 - ETA: 25s - loss: 0.6066 - accuracy: 0.8 - ETA: 25s - loss: 0.605 - ETA: 23s - loss: 0. - ETA: 22s  - ETA: 19s - loss: 0.6060 - accuracy: - ETA: 19s - loss: 0.6047 - accuracy: 0.82 - ETA: 19s - loss: 0.6047 - acc - ETA: 18 - ETA: 16s - loss: 0.6051 - accu - ETA: 1 - ETA: 6s - loss: 0 - ETA: 3s - - ETA: 0s - loss: 0.607\n",
      "Epoch 00021: val_accuracy improved from 0.81270 to 0.81910, saving model to my_best_model.epoch21-accuracy0.82.hdf5\n",
      "781/781 [==============================] - 57s 73ms/step - loss: 0.6076 - accuracy: 0.8258 - val_loss: 0.6544 - val_accuracy: 0.8191\n",
      "Epoch 22/75\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.5995 - accuracy: 0.8322 - ETA: 49s - loss: 0.5926 - accuracy: 0. - ETA: 49s - loss: 0.5912  - ETA: 44s - ETA: 41s - loss: 0.5953 - accuracy: 0.834 - ETA: 41s - loss: 0.5949 -  - E - ETA: 37s - loss: 0.5970 - accurac - ETA: 37s - loss: 0.5950 - accuracy: 0.83 - ETA: 37s - loss: 0.5948 - acc - ETA: 36s - loss: 0.5921 -  - ETA: 35s  - ETA: 33s - loss: 0.5932 - accuracy - ET - ETA: 21 - ETA: 18s - loss: 0.5959  - ETA: 17s - loss: 0.5957 - accu\n",
      "Epoch 00022: val_accuracy did not improve from 0.81910\n",
      "781/781 [==============================] - 57s 73ms/step - loss: 0.5995 - accuracy: 0.8322 - val_loss: 0.7021 - val_accuracy: 0.8076\n",
      "Epoch 23/75\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.5947 - accuracy: 0.8324 - ETA: 49s - ETA: 49s - loss: 0.5 - ETA: 47s - loss: 0.5891 - - ETA: 40s - loss: 0.5907 - accuracy: 0.83 - ETA: 40s - loss: 0.5906 - acc - ETA: 39s - loss: 0. - ETA: 37s - loss: 0.5892 - accuracy: 0. - ETA: 37s - loss: - ETA: 35s - loss: 0 - ETA: 33s - loss: 0.5866 - accuracy: 0 - ETA: 33s - loss: 0.5857 - accura - ETA: 32s - loss: 0.5854 - accuracy:  - ETA: 32s - loss: - ETA: 30s - loss: 0.5871 - ETA: 26s - loss - ETA: 24s - loss: 0.5872 - - ETA: 23s - loss: 0.5857 - accuracy:  - ETA: 23s - loss: 0.5863 - accuracy: 0.83 - ETA:  - ETA: 17s - loss: -  - ETA: 13s - loss: 0.5899 - accuracy - ETA\n",
      "Epoch 00023: val_accuracy did not improve from 0.81910\n",
      "781/781 [==============================] - 56s 72ms/step - loss: 0.5947 - accuracy: 0.8324 - val_loss: 0.6661 - val_accuracy: 0.8125\n",
      "Epoch 24/75\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.5894 - accuracy: 0.8349 - ETA: 49s - loss: 0.5617 - accuracy: 0.84 - ETA: 49s - loss: 0.5656 - accuracy: 0 - ETA: 49s - loss: 0.5709 - accu - ETA: 49s - loss: 0.5872 - accuracy: - E - ETA: 43s - loss: 0.5865 - accuracy: 0 - ETA: 43s - loss: 0.5875 - - ETA: 41s - loss: 0.5864 - accuracy - ETA: 38s - loss: 0 - ETA: 24s - loss: 0.5848 - accuracy:  - ETA: 24s - loss: 0.5841 - accur - ETA: 23s - loss: 0.5833 - accuracy: 0.83 - ETA: 23s - loss: 0.5833  - ETA: 22s - loss: 0.5846 - accu - ETA: 21s - loss: 0.5844 - accura - ETA: 20s - loss: 0.5857 - accura - ETA: 20s - l - ETA: 18s - loss: 0.5862 - accuracy: 0 - ETA: 17s - loss: 0.585 - ETA: 16s - loss: 0.5850 - accuracy: 0. - ETA: 16s - loss: 0.5845 - accuracy - ETA: 15s - lo - ETA: 13s - loss: 0.5856 - accuracy: 0.8 - ETA: 13s - loss: 0.5855 - accuracy: 0 - ETA: 13s - loss: 0.5859  - ETA: 12s - loss: 0.5871 - accuracy: 0.83 - ETA: 11s - loss: 0 - ETA: 10s - loss: 0.5870  - ETA: 2s - - ETA: \n",
      "Epoch 00024: val_accuracy did not improve from 0.81910\n",
      "781/781 [==============================] - 57s 73ms/step - loss: 0.5894 - accuracy: 0.8349 - val_loss: 0.6997 - val_accuracy: 0.8122\n",
      "Epoch 25/75\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.5798 - accuracy: 0.8366 - ETA: 49s - - ETA: 48s - loss: 0.5890 - ETA: 47s - loss: 0.576 - ETA: 45s - los - ETA: 44s - loss:  - ETA: 42s - l - ETA: 37s - loss: 0.5831 - ETA: 36s - loss: 0.5816 - accuracy: 0.836 - ETA: 36s - loss: 0.5822 - accur - ETA: 26s - loss: - ETA: 24s - loss: 0.5736 - accuracy: 0 - ETA: 24s - loss: 0.5732 - accuracy: 0. - ETA: 24s - loss: 0.5727 - acc - ETA: 23s - loss: - ETA: 21s - loss: 0.5734 - accurac - ETA: 20s - loss: 0.574 - ETA: 19s - loss: 0.5740 - ac - ETA: 18s - loss: 0.5744 - accuracy - ETA: 18s - loss: 0.5750 - accuracy: 0.837 - ETA: 17s - loss: 0.5750 - accuracy: 0.8 - ETA: 17s - loss: 0. - ETA: 16s - loss: 0.5746 - accura - ETA: 8s - loss: 0.5788 - accuracy:  - ETA: 8s - los - ETA: 7s - loss: 0.5784 - accuracy: 0. - ETA: 7s - loss: 0.5785 - accura - ETA: 0s - los\n",
      "Epoch 00025: val_accuracy improved from 0.81910 to 0.83460, saving model to my_best_model.epoch25-accuracy0.83.hdf5\n",
      "781/781 [==============================] - 57s 73ms/step - loss: 0.5798 - accuracy: 0.8366 - val_loss: 0.6129 - val_accuracy: 0.8346\n",
      "Epoch 26/75\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.5758 - accuracy: 0.8401 - ETA: 49s - loss: 0.6343 - accuracy: - E -  - ETA: 44s - loss: 0.5516 - accuracy - ETA: 43s - loss: 0.5489 - accu - ETA: 43s - loss: 0.5520 - accuracy: 0.84 - ETA: 42s - loss: 0.5509 - accuracy: 0. - ETA: 42s - loss: 0.5516 - accuracy: 0.84 - ETA: 42s -  - ETA: 40s - loss: 0.5564 - - ETA: 39s - loss: 0.5558 - accuracy: 0.848 - ETA: 39s - loss: 0 - ETA: 38s - loss: 0.5580 - accuracy: 0. - ETA: 37s - loss: 0.5609 - accurac - ETA: 37s - loss: 0.5630  - ETA: 33s - loss: 0.5670 - accuracy:  - ETA: 32s - loss: 0.5669 - accur - - ETA: 29s - loss: 0.5669 - accuracy: 0.84 - ETA: 29s - loss: 0.5667 - accuracy: 0. - ETA: 28s - loss: 0.5664 - accu  - ETA: 25s - loss: 0.570 - ETA:  - ETA: 21s - loss: 0.5718 - accuracy: 0.841 - ETA: 21s - loss: 0.5716 - accuracy: 0.842 - ETA: 21s - loss: 0.5716 - accuracy - ETA: 20s - loss: 0.5 - ETA: 19s - loss: 0.570 - ETA: 18s - loss: 0.5695 - accuracy: - ETA: 17s - loss: 0.5701 - accuracy: 0. - ETA: 17s - loss: 0.5700 - accuracy: 0.841 - ETA: 17s - loss: 0.5704 - ETA:  - ETA: 0s - loss: 0.5759 - accuracy: 0.\n",
      "Epoch 00026: val_accuracy did not improve from 0.83460\n",
      "781/781 [==============================] - 56s 72ms/step - loss: 0.5758 - accuracy: 0.8401 - val_loss: 0.6564 - val_accuracy: 0.8178\n",
      "Epoch 27/75\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.5708 - accuracy: 0.8416 - ETA:  - ETA: 45s - loss: 0.5702 - - ETA: 44s -  - ETA: 42s - loss: 0.5732 - accuracy: 0. - ETA: 42s - loss: 0.5760 - accuracy: - ETA: 41s - loss: 0.5751 - accuracy: 0.841 - ETA: 41s - loss: 0.5756 - accur - ETA: 41s - loss: 0.5752 - accuracy: 0.840 - ETA: 41s - loss: 0.5748  - ETA: 40s - loss: 0 - ETA: 38s - loss: - ETA: 34s - loss: 0.5727 - accurac - ETA: 33s - loss: 0.5741 - accuracy: 0.83 - ETA: 33s - loss:  - ETA: 31s - loss: 0.5768 - accurac - ETA: 25s - loss: 0.5741 - accuracy: - ETA: - ETA: 22s - loss: 0.5716 - - ETA: 21 - ETA: 15s - loss: 0.5698 - accuracy:  - ETA: 15s - loss: 0.570 - ETA: 14s - loss: 0.5707 - accur - ETA: 13s - loss: 0.5710 - accura - ETA: 12s - loss: 0.5699 - ETA: 11s - loss: 0.5704 - accuracy - ET - ETA: 9s - los - ETA: 5s - loss: 0.5705 - accura - ETA: 4s - loss: 0.5702 \n",
      "Epoch 00027: val_accuracy did not improve from 0.83460\n",
      "781/781 [==============================] - 56s 72ms/step - loss: 0.5708 - accuracy: 0.8416 - val_loss: 0.6264 - val_accuracy: 0.8278\n",
      "Epoch 28/75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "781/781 [==============================] - ETA: 0s - loss: 0.5631 - accuracy: 0.8453 - ETA: 48s - loss: 0.6326 - ETA: 48s - loss: 0.5631 - accuracy: 0 - ETA: 48s - loss: 0.5689 - accurac - ETA: 47s - l - ETA: 45s - loss: 0.5643 - - ETA: 41s - loss: 0.5724 - accuracy: 0 - ETA: 41s  - ETA: 39s - loss: 0.5690 - accu - ETA: 38s - loss: 0.5648 - accurac - ETA: 38s - loss: 0.5640 - accuracy:  -  - ETA: 32s - loss: 0.5560  - ETA: 31s - loss: - ETA: 29s - loss: 0.5565 - accu - ETA: 28s - loss: 0.5559 - accuracy: 0.846 - ETA: 28s - loss: 0.5556 - a - ETA: 24s - loss: 0 - ETA: 22s - loss: 0.5566 - - ETA: 21s - loss: 0.5562 - accuracy:  - ETA: 21s - loss: 0.5562 - accuracy: 0 - ETA: 21s - loss: 0.5562 - a - ETA: 20s - loss: 0.5574 - ETA:  - ETA: 10s - loss: 0.5612 - accuracy: - ETA: 10s - loss: 0.5598 - accuracy: - ETA: 9s - l - ETA: 8s - loss: 0.559 - ETA - ETA: 4s - loss: 0.5 - ETA: 3s - loss: 0.5631 - \n",
      "Epoch 00028: val_accuracy did not improve from 0.83460\n",
      "781/781 [==============================] - 56s 71ms/step - loss: 0.5631 - accuracy: 0.8453 - val_loss: 0.6198 - val_accuracy: 0.8318\n",
      "Epoch 29/75\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.5598 - accuracy: 0.8462 - ETA: 49s - l - ETA: 50s - loss: 0.5482 - accuracy: - ETA: 49s - loss: 0.5466 - accuracy:  - ETA: 49s - loss: 0.5451 - accuracy - ETA: 48s - loss: 0. - ETA: 46s - loss: 0.5445 -  - ETA: 45s - loss: 0.5375 - accuracy - ETA: 44s - loss: 0.5438 - - ETA: 43s - loss: 0.5459 - accuracy: 0.8 - ETA: 30s - loss: 0.5456 - accuracy: 0.85 - ETA: 30s - loss: 0.5457 - a - ET - ETA: 24s - loss:  - ETA - ETA: 19s - loss: 0.5531 - accuracy: 0.84 - ETA: 19s - loss: 0.5534 - ETA: 15s - lo - ETA: 13s - loss: 0.5551 - accuracy: 0.84 - ETA: 13s - loss: 0.5550 - accuracy: 0.846 - ETA: 13s - loss: 0.5552 - accuracy: 0.846 - ETA: 13s - loss: 0.5553 - - ETA: 12s - loss: 0.5558  - ETA: 11s - loss: 0.5562 - accuracy: 0.84 - E - ETA: 7s - loss: 0.5567 - accuracy: 0. - ETA: 7s - loss: 0.5569 - accura - ETA: 7s - l - ETA - ETA: 4s - loss: 0.5591 - accuracy:  - ETA: 4s - loss: 0.5 - ETA - E\n",
      "Epoch 00029: val_accuracy improved from 0.83460 to 0.83740, saving model to my_best_model.epoch29-accuracy0.84.hdf5\n",
      "781/781 [==============================] - 56s 72ms/step - loss: 0.5598 - accuracy: 0.8462 - val_loss: 0.6046 - val_accuracy: 0.8374\n",
      "Epoch 30/75\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.5532 - accuracy: 0.8493 - ETA: 40s - loss: 0.558 - ETA: 39s - loss: 0.5617 - accuracy:  - ETA: 38s - loss: 0.5619 - accu - ETA: 38s - loss: 0.5631 - accurac - ETA: 37s - loss: 0.5612 - accuracy: 0. - ETA: 37s - loss: 0.5602 -  - ETA: 33s - loss: 0.5557 - accuracy: 0. - ETA: 33s - loss: 0.5554 - accuracy: 0. - ETA: 32s - loss: 0.555 - ETA: 31s - loss: 0.556 - ETA: 30s - loss: 0.5517 - accuracy: 0 - ETA: 29s - loss: 0.550 - ETA: 25s - loss - ETA: 23s - loss: 0.5520 - accurac - ETA - ETA: 14s - loss: 0.5530 - accuracy: - ETA: 14s - loss: 0.5530 - ETA: 13s - loss: 0.5549 - a - ETA: 12s - loss: 0.55 - ETA: 10s - loss: 0. - E - ETA: 8s - loss: 0.553 - ETA: 7s - loss: 0.5530 - accuracy: 0.84 - ETA: 7s - loss: 0.5531 - accuracy - - ETA: 5s - loss: 0.5541  - ETA: 0s - loss: 0.5531 -  - ETA: 0s - loss: 0.5529 - accura - ETA: 0s - loss: 0.5531 - accuracy: 0.84\n",
      "Epoch 00030: val_accuracy did not improve from 0.83740\n",
      "781/781 [==============================] - 56s 72ms/step - loss: 0.5532 - accuracy: 0.8493 - val_loss: 0.6681 - val_accuracy: 0.8213\n",
      "Epoch 31/75\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.5462 - accuracy: 0.8526 - ETA: 51s - loss: 0.5828 - accuracy: 0.84 - ETA: 51s - loss: 0.5 - ETA: 48s - loss: 0.5519 - accuracy: 0.852 - ETA: 48s - loss: 0.5488 - accuracy: 0.8 - ETA: 48s - loss: 0.5543 - ac - ETA: 47s - loss: 0.5445 - accuracy - ETA: 46s  - ETA: 44s - loss: 0. - ETA: 43s - loss: 0.5434 - accuracy: 0.856 - ETA: 40s - loss: 0.5531 - accuracy: 0 - ETA: 39s - loss: 0.5523 - ETA: 38s - loss: 0.5532 - accuracy: 0. - ETA: 38s - loss: 0.5523 -  - ETA: 37s - lo - ETA: 32s - loss: 0.5517 - accuracy - ETA: 31s - los - ETA: 30s - loss: 0.5491 - accura - ETA: 29s - loss: 0.5468  - ETA: 28s - loss: 0.5457  - ETA: 24s - loss: 0.5500 - accuracy: 0. - ETA: 24s - loss: 0.5495 - - ETA: 22s - loss: 0.5501 - ac - ETA: 21s - loss: 0.5497 - ac - ETA: 21s - loss: 0.5492 -  - ETA: 19s - loss: 0 - ETA: 2s - loss: 0.5464 -  - ETA: 1s - loss: 0.5462 - accuracy:  - ETA: 1s - loss: 0.5465  - ETA: 0s - l\n",
      "Epoch 00031: val_accuracy did not improve from 0.83740\n",
      "781/781 [==============================] - 56s 72ms/step - loss: 0.5462 - accuracy: 0.8526 - val_loss: 0.6433 - val_accuracy: 0.8300\n",
      "Epoch 32/75\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.5438 - accuracy: 0.8524 - ETA: - ETA: 46s - loss - ETA: 45s - - ETA: 42s - loss: 0.528 - ETA: 41s - loss: 0.5291 - accuracy: 0.862 - ETA: 41s - los - ETA: 40s - loss: 0.5306 - accuracy:  - ETA: 39s - loss: 0.53 - E - ETA: 35s - loss: 0.540 - ETA: 34s - loss: 0.5444 - accuracy - ETA: 24s - loss: 0.5420 - accu - ETA: 23s - loss: 0.5415 - accuracy: 0. - ETA: 23s - loss: 0.5412  - ETA: 22s - loss: 0.5421 - accu - ETA: 21s - loss: 0.5421 - accuracy: - ETA: 20s - loss: 0.5424 - accurac - ETA: 20s - loss: 0.5419 - accuracy: 0.85 - ETA: 20s - loss: 0.5421 - accura - ETA: 19s - loss: 0.54 - ETA: 18s - loss: 0.5448 - accuracy - ETA: 17s - loss: 0.5440  - ETA: 16s - loss: 0.5446 - accuracy: 0.8 - ETA: 16s - loss: 0.545 - ETA: 14s - loss - ETA: 13s - loss: 0.5441 - accuracy:  - ETA: 12s - loss: - ETA: 8s - loss: 0.543 - ETA: 6s - loss: 0.5 - - ETA: 4s - loss: 0 - ETA: 1s - loss: 0.5447 - accuracy:  - ETA: 0s - loss:\n",
      "Epoch 00032: val_accuracy did not improve from 0.83740\n",
      "781/781 [==============================] - 56s 72ms/step - loss: 0.5438 - accuracy: 0.8524 - val_loss: 0.6491 - val_accuracy: 0.8262\n",
      "Epoch 33/75\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.5455 - accuracy: 0.8513 - ETA: 48s - loss: 0.5 - ETA: 49s - loss: 0.533 - ETA: 48s - loss: 0.5375 - ETA: 47s - loss: 0.5533 - accuracy:  - ETA: 46s - loss: 0.5545 - accuracy: 0. - ETA: 46s - loss: 0.5519 - accuracy: 0.845 - ETA: 46s - loss: 0.5515 - ETA: 45s - loss: 0.5 - ETA: 44s - loss: - ETA: 42s - loss: 0.5407 - accuracy: 0.85 - ETA: 42s - loss: 0.5410 - accuracy: 0.85 - ETA: 41s - loss: 0.5432 - accura - ETA: 41s - loss: 0.5407 - accuracy: 0.8 - ETA: 40s - loss: 0.5395 - accuracy: 0 - ETA: 40s - loss: 0.5394 - accuracy: 0 - ETA: 40s - loss: 0.5396 - accuracy: 0.851 -  - ET - ETA: 31s - loss: 0.5410 - accuracy: 0 - ETA: 31s -  - ETA: 29s - loss: 0.5399 - accuracy: 0.852 - ETA: 29s - loss: 0.5400 - accu - ETA: 28s -  - ETA: 26s - loss: 0.5 - ETA: 25s - loss: 0.5435 -  - ETA: 23s - loss: 0.5428 - accuracy: 0.851 - ETA: 23s - loss: 0.5428 - accuracy: 0 - ETA: 23s - loss: - ETA: 21s - loss: 0.5436 - acc  - ETA: 15s - loss: 0.5419 - accuracy: 0.8 - ETA: 14s - loss: 0.5419 - accu - ETA: 14s - loss: 0.5421 - accu - ETA: 13s - loss: 0.5423 -  - ETA - ETA: 9s - loss: 0.5427 - ac - ETA: 4s - loss: 0.5 - - E - ETA:  - ETA: 0s - loss: 0.5455 - accura\n",
      "Epoch 00033: val_accuracy did not improve from 0.83740\n",
      "781/781 [==============================] - 57s 72ms/step - loss: 0.5455 - accuracy: 0.8513 - val_loss: 0.6912 - val_accuracy: 0.8212\n",
      "Epoch 34/75\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.5390 - accuracy: 0.8541 - ETA: 46s - loss: 0.5157 - accuracy: 0. - ETA: 46s - loss: 0.5169 -  - ETA: 30s - ETA: 28s - lo - ETA: 20s - loss: 0.5364 - accuracy: 0.853 - ETA - ETA: 17s - loss: 0.5365 - ac - ETA: 17s - loss: 0.5366 - accuracy: 0. - ETA: 16s - loss: 0.5369 - accuracy: - ETA: - ETA: 13s - loss: 0.5370 - accuracy: 0 - ETA: 13s - loss: 0.5370 - accuracy: 0 - ETA:  - ETA: 7s - loss: 0.5365 - accuracy: \n",
      "Epoch 00034: val_accuracy did not improve from 0.83740\n",
      "781/781 [==============================] - 56s 72ms/step - loss: 0.5390 - accuracy: 0.8541 - val_loss: 0.5907 - val_accuracy: 0.8370\n",
      "Epoch 35/75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "781/781 [==============================] - ETA: 0s - loss: 0.5324 - accuracy: 0.8554 - ETA: 48s - loss: 0.5078 - a - ETA: 47s - loss: 0.5215 - accuracy: 0. - ETA: 46s - loss: 0.5172 - accuracy: 0.856 - ETA: 46s  - ETA: 4 - ETA: 40s - loss: 0.5270 - ETA: 38s - loss: 0.5285 - accu - ETA: 38s - loss: 0.5270 - accuracy - ETA: 37s - loss: 0.52 - ETA: 36s - loss: 0.5305 - accuracy: 0.  - ETA: 33s - loss: 0.5294 - ETA: 31s - loss: 0.5297  - ETA: 30s - loss: 0.5291 - accuracy:  - ETA: 30 - ETA: 27s - loss: 0.5316 - accura - ETA: 27s - loss: 0.5319 - accura - ETA: 26s - loss: 0.5302 - accuracy: - ETA: 26s - loss: 0 - ETA: 24s - loss: 0.5306 - accuracy - ETA: 23s - loss: 0.5 - ETA: 22s - loss: 0.5302 - accurac - ETA: 21s - loss: 0.52 - ETA: 20s - loss: 0. - ETA: 18s - loss: 0.5297 - accuracy - ETA: 18s - loss: 0.5304 - accuracy: 0.85 - ETA: 18s - loss: 0.5299 - accu - ETA: 17s - loss: 0.5291 - accuracy: - ETA: 17s - loss: - ETA: 15s - loss: 0.5293 - - ETA: 14s - loss: 0.5289 - accu -  - ETA: 4s - loss: 0.5338 -  - ETA: 0s - loss: 0.5324 - accura - ETA: 0s - loss: 0.5322 - accuracy - ETA: 0s - loss: 0.5322 - accu\n",
      "Epoch 00035: val_accuracy did not improve from 0.83740\n",
      "781/781 [==============================] - 56s 72ms/step - loss: 0.5324 - accuracy: 0.8554 - val_loss: 0.6418 - val_accuracy: 0.8305\n",
      "Epoch 36/75\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.5340 - accuracy: 0.8563 - ETA: 50s -  - ETA: 48s - loss: 0.5223 - accurac - ETA: 47s - loss: 0.5268 - accuracy: 0. - ETA: 47s - loss: 0.5255 - accuracy: 0.85 - ETA: 47s - loss: 0.5221 - accuracy: - ETA: 46s - loss: 0.5203 - accuracy: 0.858 - ETA: 46s - loss: 0 - ETA: 45s - loss: 0. - ETA: 43s -  - ETA: 41s - loss: 0.5242 - ETA: 40s - loss: 0.5299 - ac - ETA: 39s - loss: 0.5329 - accuracy: 0.8 - ETA: 39s - loss: 0.5320 - accuracy: 0.856 - ETA - ETA: 36s - loss: 0.5257 - accuracy: 0 - ETA: 36s - loss: 0.5261 - - - ETA: 32s -  - ETA: 30s - loss: 0.5304  - ETA: 29s - loss: 0.5317 - accu - ETA: 28s - loss: - ETA: 26s - loss: 0.5294 - accuracy: 0. - ETA: 26s - loss: 0.5284  - ETA: 25s - loss: 0.52 - ETA: 23s - loss: 0.5285 - accurac - ETA: 23s - loss: 0.5288 - accuracy:  - ETA: 22s - loss - ETA: 21s - loss: 0.5307 - accurac - ETA: 20s - loss: 0.5307 - accuracy: 0 - ETA: 20s - loss: 0.5312 - ac - ETA: 19s - loss: 0.5299 - accuracy: 0.857 - ETA: 19s - loss: 0.5300 - accur - ETA - ETA: 15s - loss: 0.5311 - accuracy:  - ETA: 15s - loss: 0 - ETA: 13s - loss: 0 - ETA: 12s - loss: 0. - ETA: 8s - loss: 0.5339 - accuracy - ETA: 8s - loss: 0.5341 - accuracy: 0. - ETA: 8s - loss: - ETA: 3s - l - ETA: 0s - loss: 0\n",
      "Epoch 00036: val_accuracy improved from 0.83740 to 0.84050, saving model to my_best_model.epoch36-accuracy0.84.hdf5\n",
      "781/781 [==============================] - 56s 72ms/step - loss: 0.5340 - accuracy: 0.8563 - val_loss: 0.5932 - val_accuracy: 0.8405\n",
      "Epoch 37/75\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.5256 - accuracy: 0.8588 - ETA: 51s - loss: 0.5272 - accuracy: 0.873 - ETA: 51s - loss: 0.5196 - acc - ETA: 48s - loss: 0.5341 - accuracy: 0.8 - ETA:  - ETA: 47s - loss: 0.5185 - accuracy:  - ETA: 46s - loss: 0.5145 - accura - ETA: 46s - loss: 0.5185 - accuracy: 0.862 - ETA: 45s - loss: 0.5173 - accuracy: 0.863 - ETA: 45s - loss: 0.5169 - accur - ETA: 45s - loss: 0.5185 - accuracy: 0 - ETA: 44s - loss:  - ETA: 43s - los - ETA: 41s - loss: 0.5190 - accurac - ETA: 40s - E - ETA: 32s - ETA: 30s - loss - ETA: 28s - loss: 0.5229 - ETA: 27s - loss: 0.5 - ETA: 26s -  - ETA: 24s - loss: 0.5238 - ac - ETA: 23s - loss: 0.5248 - accura - ETA: 22s - loss: 0.5233 - ETA: 21s - l\n",
      "Epoch 00037: val_accuracy improved from 0.84050 to 0.84430, saving model to my_best_model.epoch37-accuracy0.84.hdf5\n",
      "781/781 [==============================] - 56s 72ms/step - loss: 0.5256 - accuracy: 0.8588 - val_loss: 0.5959 - val_accuracy: 0.8443\n",
      "Epoch 38/75\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.5266 - accuracy: 0.8581 - ETA: 4 - ETA: 47s - loss: 0.5261 - accuracy:  - ETA: 46s - loss: 0.5317 - accurac - ETA: 46s  - ETA: 44s - loss: 0.5342 - a - E - ETA: - ETA: 38s - loss: 0.5230 - accuracy - ETA: 38s - loss: 0.5223 - accur - ETA: 37s - loss: 0.5210 - accuracy: 0 - ETA: 37s - loss: 0.5 - - ETA: 29s - loss: 0.5227 - accura - ETA: 29s - loss: 0.5237 - accuracy: 0.85 - ETA: 28s - loss: 0.5234 - ac - ETA: 22s - loss: 0.5243 - ac - ETA: 18s - loss: 0.5263 - accura - ETA: 1 - ETA: 15s - loss: 0.5258 - accuracy: 0.858 - ETA: 15s - loss: 0.5260 -  - ETA: 14s - loss: 0.5255 - accuracy: - ETA: 13s - loss: 0.5256 - accur - ETA: 2s - - ETA: 1s - l - ETA: 0s - loss: 0.5265 - accuracy - ETA: 0s - loss: 0.5264 - accu\n",
      "Epoch 00038: val_accuracy improved from 0.84430 to 0.84890, saving model to my_best_model.epoch38-accuracy0.85.hdf5\n",
      "781/781 [==============================] - 56s 72ms/step - loss: 0.5266 - accuracy: 0.8581 - val_loss: 0.5684 - val_accuracy: 0.8489\n",
      "Epoch 39/75\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.5210 - accuracy: 0.8604 - ETA: 52s - loss: 0.4843 - accur - ETA:  - ETA: 47s - loss: 0.5177 - accuracy: 0.86 - ETA: 4 - ETA: 39s - loss: 0.5123 - a - ETA: 38s - loss: 0.5117 - accuracy: 0. - ETA: 38s - loss: 0.5110 - acc - ETA: 37s - loss: 0.5117 - accuracy: 0.86 - ETA: 36s - loss: 0.5125 - a - ETA: 35s - loss: 0.5179 - accu - ETA: 35s - loss: 0.5195 - accura - ETA: 34s - loss:  - ETA: 32s - loss: 0.5213 - accu - ETA: 31s - loss: 0.5199 - accuracy: 0. - ETA: 31s - loss: 0.5194 - accura - ETA: 30s - loss:  - ETA: - ETA: 26s - loss: 0.5186 - accuracy: 0 - ETA: 26 - ETA: 2s - - ETA: 1s - loss: 0.5207 - accuracy: 0.86 - ETA: 1s - loss: 0.5208 - accuracy: 0. - ETA: 0s - l\n",
      "Epoch 00039: val_accuracy did not improve from 0.84890\n",
      "781/781 [==============================] - 56s 72ms/step - loss: 0.5210 - accuracy: 0.8604 - val_loss: 0.7025 - val_accuracy: 0.8211\n",
      "Epoch 40/75\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.5200 - accuracy: 0.8609 - ETA: 40s - loss: 0.5089 - ac - ETA: 39s - loss: 0.5085 - accuracy:  - ETA: 39s - loss: 0.5093 - a - ETA: 38s - loss: 0.5039 - accuracy: 0. - ETA: 37s - loss: 0.5056 - accuracy: 0 - ETA: 37s - loss: 0.5081 - a - - ETA: 33s - loss: 0.5116 - accurac - ETA: 33s - loss: 0.5120 - - ETA: 29s - loss: 0 - ETA: 24s - loss: 0.5136 - a - ETA: 20s - loss: 0.5129 - ac - ETA: 16s - loss: 0.5136 - accuracy: 0 - ETA: 16s - loss: 0.51 - ET - ETA: 0s - loss: 0.5198 - accuracy - ETA: 0s - loss: 0.5201 - accuracy: 0. - ETA: 0s - loss: 0.5202 - accuracy: 0.86 - ETA: 0s - loss: 0.5204 - accuracy - ETA: 0s - loss: 0.5202 - accuracy: 0.8608\n",
      "Epoch 00040: val_accuracy did not improve from 0.84890\n",
      "781/781 [==============================] - 57s 73ms/step - loss: 0.5202 - accuracy: 0.8608 - val_loss: 0.6554 - val_accuracy: 0.8306\n",
      "Epoch 41/75\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.5166 - accuracy: 0.8631 - ETA: 50s - los - ETA: 48s - loss: 0.5140 - ETA: 46s - ETA: 43s - loss: 0.4990 - a - ETA: 43s - loss: 0. - ETA: 41s - loss: 0.5130 - accur - ETA: 40s - loss: 0.5121 - accura - ETA: 40s - loss: 0.5110 - accuracy: 0.866 - ETA: 40s - loss: 0.5114 - accuracy: 0.866 - ETA: 40s - los - ETA: 35s - loss: 0.5090 - accuracy: - ETA: 34s - loss: 0.5078 -  - ETA: 30s - loss: 0.5116 - accuracy: 0. - ETA: 30s - loss: 0.511 - ETA: 29s - loss: 0. - ETA: 27s - loss: 0.5110 - accur - ETA: 26s - loss: 0.5103 - accuracy: - ETA: 26s - loss: 0.5105 - accuracy:  - ETA: 25s - loss: 0.5 - ETA: 24s - loss: 0.5129 - accuracy:  - ETA: 24s - loss: 0.5124 - - E - ETA: 20s - loss: 0.5132 - accuracy: 0.86 - - ETA: 4s - - ETA: 2s - loss: 0.5169  - ETA: 1s - loss: - ETA: 0s - loss: 0.5167 - accuracy - ETA: 0s - loss: 0.5169 - \n",
      "Epoch 00041: val_accuracy did not improve from 0.84890\n",
      "781/781 [==============================] - 56s 72ms/step - loss: 0.5166 - accuracy: 0.8631 - val_loss: 0.6550 - val_accuracy: 0.8246\n",
      "Epoch 42/75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "781/781 [==============================] - ETA: 0s - loss: 0.5121 - accuracy: 0.8639 - ETA: 49s - loss: 0.5260 - accuracy: 0. - ETA: 48s - loss: 0.5201 - accuracy: 0.8 - ETA: 48s - loss: 0.5216 - accuracy: 0.8 - ETA: 48s - loss: 0.5232 - accuracy: 0.862  - ETA: 44s - loss: 0.5075 - accuracy:  - ETA: 44s - loss: 0.5082 - accuracy: 0.86 - ETA: 44s - loss: 0.5080 - accuracy: 0.8 - ETA: 43s - loss: 0.5062  - ETA: 39s - ETA: 36s - lo - ETA: 34s - loss: 0.5030 - accuracy: 0.86 - ETA: 34s - loss: 0 - ETA: 33s - loss: 0 - ETA: 28s - loss - ETA: 26s - loss: 0.5112 - accuracy - ETA: 26s - l - ETA: 24s - loss: 0.5114 - a - ETA: 23s - loss: 0.5129 - accurac - ETA: 22s - - ETA: 20s - loss: 0.5141 - accuracy: 0. - ETA: 20s - loss: 0.5139 - accuracy:  - ETA: 19s - loss: 0.513 - ETA: 18s - loss: 0.5139 - accuracy: 0.8 - ETA: 18s - loss: 0.5148 - a - ETA: 17s - loss: 0.5150 - accuracy: 0.8 - ETA: 16s - loss: 0.5147 - accurac - ETA: 16s - loss: 0.5135 - accuracy: 0.86 - ETA: 16s - loss - ETA: 14s - lo - ETA: 9s - - ETA: 8s - loss: 0.5120 - accuracy: 0.86 - ETA: 8s - loss: 0.5120 - accuracy - ETA: 8s - loss: 0.5120 - ac - ETA: 6s - loss: 0.5126 - accuracy: 0.86 - ETA: 6s - loss: - ETA: 5s - loss: 0.5127 - accuracy:  - ETA: 5s - loss: 0 - ETA: 4s - loss: 0.5123 - accu - ETA: 4s - loss: 0.512 - ETA: 3s - loss: 0.5126 - ac\n",
      "Epoch 00042: val_accuracy did not improve from 0.84890\n",
      "781/781 [==============================] - 57s 72ms/step - loss: 0.5121 - accuracy: 0.8639 - val_loss: 0.6315 - val_accuracy: 0.8310\n",
      "Epoch 43/75\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.5077 - accuracy: 0.8655 - ETA: 49s - loss: 0.4872 - a - ETA: - ETA: 46s - loss: 0.5011 - acc - ETA: 45s - loss: 0.5000 - ac - ETA: 44s - loss: 0 - ETA: 42s - loss: 0.4995 - a - ETA: 41s - loss: 0.5008  - ETA: 40s - loss: 0.5005 - accura - ETA: 39s - loss: 0.5039 - accuracy:  - ETA: 39s - loss: 0.5042 - accur - ETA: 38s - loss: 0.5020  - ETA: 37s - loss: 0.5020 - accuracy: 0.8 - ETA: 37s - loss: 0.5021 - accuracy: 0.8 - ETA: 36s - loss: 0.5022 - accur - ETA: 36s - loss: 0.4999 - accuracy: 0.8 - ETA: 35s - loss: 0.5007 - accuracy: 0. - ETA: 35s - loss: 0.4987 - accuracy:  - ETA: 35s - loss: 0.4987 - accuracy - ETA: 34s - loss: 0.4993 - accuracy: 0.8 - ETA: 34s - loss: 0.4992 - accura - ETA: 33s - loss: 0.5024 - accur - ETA: 33s - loss: 0.5025 - accu - ETA: 32s - loss: 0.5041 - accur - ETA: 31s - loss: 0.5056 - accuracy:  -  - ETA: 25s - loss: 0.5077 - ETA: 21s - loss: 0.5088 - accur - ETA: 20s - loss: 0.5095 - accuracy: 0.865 - - ETA: 17s - loss: 0.5108 - ac - ETA: 16s - loss: 0.5108 - a - ETA: 15s - loss: 0.5 - ETA: 14s - loss: 0.508 - ETA: 13s - loss: 0.5087 - accuracy:  - ETA: 12s - loss: 0.5083 - accura - ETA: 12s - lo - ETA: 10s - loss: - ETA - ETA: 7s - los - ETA: 5s - loss: 0.5078 - ac - ETA: 5s - loss: 0.5077 - accura - E - ETA: 1s - loss: 0.5079 - accuracy: 0. - ETA: 1s - loss: 0.5079 - accu -\n",
      "Epoch 00043: val_accuracy did not improve from 0.84890\n",
      "781/781 [==============================] - 57s 73ms/step - loss: 0.5077 - accuracy: 0.8655 - val_loss: 0.6345 - val_accuracy: 0.8364\n",
      "Epoch 44/75\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.5054 - accuracy: 0.8659 - ETA: 47s - loss: 0.4842 - acc - ETA: 47s - loss: 0.4726 -  - ETA: 43s - loss: 0.4986 - accuracy: 0.8 - ETA: 42s - loss: 0.4971 - accura - ETA: 42s - loss: 0.4944 - accura - E - ETA: 36s - loss: 0.4966 - accurac -  - E - ETA: 27s - loss: 0.4972 - accuracy: 0.86 - ETA: 27s - loss: 0.4972 - accuracy: 0.867 - ETA: 26s - loss: 0.4976 - accuracy: 0. - - ETA: 2s - loss: 0.5055  - ETA: 1s - loss: 0 - ETA: 0s - loss: 0\n",
      "Epoch 00044: val_accuracy improved from 0.84890 to 0.85060, saving model to my_best_model.epoch44-accuracy0.85.hdf5\n",
      "781/781 [==============================] - 57s 73ms/step - loss: 0.5054 - accuracy: 0.8659 - val_loss: 0.5504 - val_accuracy: 0.8506\n",
      "Epoch 45/75\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.5038 - accuracy: 0.8671 - ETA: 37s - loss: 0.5069 - accu - ETA: 36s - loss: 0.5044 - accuracy:  - ETA: 36s - loss: 0.5030 - - ETA: 35s - loss: 0.5022 - - ETA: 34s - loss: 0. - ETA: 32s - loss: 0.5006 - accuracy: 0.8 - ETA: 32s - loss: 0 - ETA:  - ETA: 28s - loss: 0.5013 - accuracy: 0.86 - E - ETA: 22s - l - ETA: 3s - loss: 0 - ETA: 2s - loss: 0.5034 - accu - ETA: 2s - loss: 0.5034 - accuracy: 0.86 - ETA: 2s - loss: 0.503 - ETA: 1s - loss: 0.5031 - accu - ETA: \n",
      "Epoch 00045: val_accuracy did not improve from 0.85060\n",
      "781/781 [==============================] - 57s 73ms/step - loss: 0.5038 - accuracy: 0.8671 - val_loss: 0.6841 - val_accuracy: 0.8260\n",
      "Epoch 46/75\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.5005 - accuracy: 0.8682 - ETA: 50s - loss: 0.4607 - accuracy:  - ETA: 50s - loss: 0.4474 - accuracy:  - ETA: 49s - loss: 0.4514 - accuracy:  - ETA: 48s - loss: 0.4440 - accuracy: 0.8 - ETA: 48s - loss: 0.4415 - accuracy: 0.8 - ETA: 48s - loss: 0.4449 - accuracy: 0.89 - ETA: 48s - loss: - ETA: 47s - loss: 0.4726 - accuracy:  - ETA: 46s - loss: 0.4764 - accuracy: - ETA: 46s - loss: 0.4821 - accuracy: 0.87 - ETA: 46s - loss: - ETA: 44s - loss: 0.4743 - accuracy: 0 - - ETA: 41s - loss: 0.4831  - ETA: 40s - loss: 0.4832 - accura - ETA: 31s - loss: 0.4909 - accu - ETA: 30s - loss: 0.4907 - accuracy - ETA: 29s - loss: 0.4926 - a - ETA: 28s - loss: 0.4944 - acc - ETA: 27s - loss: 0.4936 - accura - ETA: 27s - loss: 0.4943  - ETA: 25s - loss: 0.496 - ETA: 24s - loss: 0.4960 - a - ETA: 23s - loss: 0.496 - ETA: 19s - loss: 0.4979 - accuracy: 0 - ETA: 19s - loss: 0.498 - ETA: 17s - loss: 0.4994 - - ETA: 16s - loss: 0.5004 - accura - ETA: 15s - - ETA: 13s - loss: 0.5002 - accuracy: 0.86 - ETA: 13s - loss: 0.5001 - accuracy: 0 - ETA: 13s - loss: 0.4995 - accuracy - ETA: 12s - loss: 0.4989 - accuracy - ETA: 12s - loss: 0.4990 - accuracy: 0. - ETA: 12s - loss: 0.4994 - accuracy:  - ETA: 11s - loss: 0.5000 - accuracy: 0.86 - ETA: 11s - loss: 0.5000 -  - ETA: 10s - loss: 0.5007 - accuracy: 0.867 - ETA: 10s -  - ETA: 7s - loss: 0.500 - ETA - ETA: 5s - loss: 0.4993 - accura - ETA: 5s - loss: 0.4993 -  - ETA: 4s - loss: 0.4998 - accu - ETA: 4s - loss: 0.4998 - accuracy: 0. - ETA: 4s - loss: 0.4998 - accuracy: 0.86 - ETA: 4s - loss: 0.5001 - accuracy - ETA: 4s - loss: 0.5001 -  - ETA: 0s - loss: 0.5002 - accuracy: 0.86 - ETA: 0s - loss: 0.5006 \n",
      "Epoch 00046: val_accuracy improved from 0.85060 to 0.85400, saving model to my_best_model.epoch46-accuracy0.85.hdf5\n",
      "781/781 [==============================] - 57s 72ms/step - loss: 0.5005 - accuracy: 0.8682 - val_loss: 0.5734 - val_accuracy: 0.8540\n",
      "Epoch 47/75\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.5002 - accuracy: 0.8697 - ETA: 48s - loss: 0.4636 - accuracy: 0.880 - ETA: 48s - loss: 0.4674 - a - ETA: 47s - lo - ETA: 45s - loss: 0. - ETA: 40s - loss: 0. - ETA: 35s - l - ETA: 33s - loss: 0.4893 - accuracy: 0.8 - ETA: 33s - loss: - ETA: 25s - loss: 0.4919 -  - ETA: 24s - loss: 0.4912 - accuracy: 0.87 - ETA: 24s - loss: 0.4911 - accuracy - ETA: 24s - loss: 0. - ETA: 22s - loss: 0.4916 - accuracy: 0. - ETA: 22 - ETA: 19s - loss: 0.4921 - accuracy: 0 - ETA: 19s - loss: 0.4925 - accuracy: 0.8 - ETA: 19s - loss: 0.4932 - accuracy: 0.872 - ETA: 19s - loss: 0.4930 - accu - ETA: 18s - loss: 0.4934 - - ETA - ETA: 12s - loss: 0.4988 - accuracy: 0 - ETA: 11s - loss: \n",
      "Epoch 00047: val_accuracy did not improve from 0.85400\n",
      "781/781 [==============================] - 56s 71ms/step - loss: 0.5002 - accuracy: 0.8697 - val_loss: 0.6124 - val_accuracy: 0.8411\n",
      "Epoch 48/75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "781/781 [==============================] - ETA: 0s - loss: 0.4952 - accuracy: 0.8700 - ETA: 49s - loss: - ETA: 48s - loss: 0.45 - ETA: 47s - loss: 0.4597 - accuracy - ETA: 46s - loss: 0.4662 - accurac - ETA: 46s - loss: 0.4629 - accuracy: 0.8 - ETA: 46s - loss: 0.4654 - a - ETA: 44s - loss: 0.4712 - acc - ETA: 44s - loss: 0.47 - ETA: 3 - ETA: 31s - loss: 0.4866 - accurac - ETA: 30s - loss: 0.4859 -  - ETA: 29s - loss:  - ETA: 28s - loss: 0.4898 - accuracy - ETA: 27s - los - ETA: 25s - loss: 0.4896 - accuracy: 0.87 - ETA: 25s - loss: 0.4894 - accurac - ETA: 25s - loss: 0.4901 - accuracy: 0.87 - ETA: 24s - loss - ETA: 23s - loss: 0.4899 - accuracy: 0.870 - ETA:  - ETA: 20s - loss: 0.4 - ETA: 19s - loss: 0.4 - ETA: 17s - loss: 0.4920 - accuracy:  - ETA: 17s - loss: 0.4923 - accuracy: - ETA: 16s - loss: 0.4926 - accuracy - ETA: 16s - loss: 0.4937 - accuracy - ETA: 15s - loss: 0.4940 -   - ETA: 9s - loss: 0.492 - ETA: 5s - loss: 0.4930 - accuracy - ETA: 5s - loss: 0.4928 -  - ETA: 4s - loss: 0.4930 - accuracy: 0.87 - ETA: 4s - l - ETA: 3s - ETA: 1s - loss: 0.4954 - ac - ETA: 0s - loss: 0 - ETA: 0s - loss: 0.4953 - accuracy: 0.\n",
      "Epoch 00048: val_accuracy did not improve from 0.85400\n",
      "781/781 [==============================] - 56s 72ms/step - loss: 0.4952 - accuracy: 0.8700 - val_loss: 0.6215 - val_accuracy: 0.8411\n",
      "Epoch 49/75\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.4912 - accuracy: 0.8716 - ETA: 48s - loss: 0.4609 - accura - ETA: 49s - loss - ETA: 48s - loss - ETA: 43s - loss: 0.4670 -  - ETA: 42s - loss: 0.4679 - accuracy: 0.8 - ETA: 42s -  - ETA: 40s - loss: 0.4676 - accuracy: 0.8 - ETA: 40s - loss: 0.4674 - accuracy: 0.8 - ETA: 40s - lo - ETA: 35s - loss:  - ETA: 33s - loss: 0.4748 - ac - ETA: 32s - l - ETA: 30s - loss: 0.4801 - accuracy: 0.875 - ETA: 30s - loss: 0.4800 - accuracy: 0 -  - ETA: 27s - loss: 0.4846 - accu - ETA: 26s - loss: 0.4855 - acc - ETA: 25s - loss: 0.4862 - accuracy: 0.873 - ETA: 25s - loss: 0.4862 - accur - ETA: 25s - - ETA: 9s - - ETA - ETA: 0s - loss: 0.4907 - accuracy - ETA: 0s - loss: 0.4\n",
      "Epoch 00049: val_accuracy did not improve from 0.85400\n",
      "781/781 [==============================] - 57s 73ms/step - loss: 0.4912 - accuracy: 0.8716 - val_loss: 0.7096 - val_accuracy: 0.8158\n",
      "Epoch 50/75\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.4940 - accuracy: 0.8704 - ETA: 49s - loss: 0. - ETA: 43s - loss: 0.4978 - accuracy: 0 - ETA: 42s - loss: 0.4995  - ETA: 41s - loss: 0.4949 - ac - E - ETA: 38s - loss:  - ETA: 33s - loss: 0.4911 - accu - ETA: 32s - loss: 0.49 - ETA: 31s - loss: 0.4894 - accuracy: 0.870 - ETA: 31s - loss: 0.4895 - a - ETA: 30 - ETA: 28s - loss: 0.4873 - a - ETA: 27s - loss: 0 - ETA: 25s - loss: 0.4872 - accuracy: 0.873 - ETA: 25s - loss: 0.4874 - accura - ETA: 24s - loss: 0.4888 - accuracy: -  - ETA: 18s - loss: 0.4927 - accuracy: - ETA: 18s - loss: 0.4930 - accuracy: 0.8 - ETA: 17s - loss: 0. - ETA: 16s - loss: 0.4939 - accuracy: 0.871 - ETA: 16s - loss: 0.4937 - - ETA: 15s - loss: 0.4926 - accuracy: 0 - ETA: 14s - loss: 0.4930  - ETA: 13s - loss: 0.4923 - accur - ETA: 12s - loss: 0.4934 - accu - ETA: 12s - loss: 0.4939 - accuracy:  - ETA: 11s - loss: 0.4943 - accuracy: 0.871 - ETA: 11s - loss: 0.4941 - accuracy: 0.87 - ETA: 11s - loss: 0.4941 - acc - ETA: 10s - loss: 0.4941 - accuracy: 0.871 - ETA: 10s - loss: 0.4939 - accuracy: 0 - ETA: 10s - loss: 0.49 - - ETA: 3s - loss: 0.4941 - accuracy: 0. - ETA: 3s - loss: 0.4943 - accuracy: 0. - ETA: 3s - - ETA: 2s -\n",
      "Epoch 00050: val_accuracy did not improve from 0.85400\n",
      "781/781 [==============================] - 56s 72ms/step - loss: 0.4940 - accuracy: 0.8704 - val_loss: 0.6739 - val_accuracy: 0.8358\n",
      "Epoch 51/75\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.4869 - accuracy: 0.8723 - ETA: 45s - loss: 0.4559 - ac - ETA: 44s - loss: 0.4602 - accu - ETA: 43s - loss: 0.4613 - accuracy: 0.88 - - ETA: 40s - loss: 0.4635 - accuracy: 0.880 - ET - ETA:  - ETA: 29s - loss: 0.4785 - accu - ETA: 28s - loss:  - ETA: 27s - loss: 0.4 - ETA: 25s - loss: 0.4800 - accuracy - ETA: 25s - loss: 0.4794 - accu - ETA: 24s - loss: 0.478 - ETA: 22s - loss: 0.4823 - ac - ETA: 21s - loss: 0.4819 - a - ETA: 20s - loss: 0.4834 - accuracy: 0 - ETA: 20s - loss: 0.4835 - accu - ETA: 19s - loss: 0.4826 -  - ETA: 18s - loss: 0.4829 - accuracy: - ETA: 18s - loss: 0.48 - ETA: 16s - loss: 0.4829 - accuracy: 0. - ETA: 16s - loss: 0.4837 - acc - ETA: 15s - loss: 0.4844 - accuracy: 0. - ETA: 15s - loss: 0.4841 -  - ETA: 14s - loss: 0.4847 - accuracy: - ETA: 10s - loss: 0.4869 - accuracy: 0.8 - ETA: 10s - loss: 0.4875 - accuracy: 0.8 - ETA: 10s - loss: 0.4 - ETA: 0s - loss: 0\n",
      "Epoch 00051: val_accuracy did not improve from 0.85400\n",
      "781/781 [==============================] - 57s 72ms/step - loss: 0.4869 - accuracy: 0.8723 - val_loss: 0.7126 - val_accuracy: 0.8169\n",
      "Epoch 52/75\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.4879 - accuracy: 0.87132- ETA: 51s - loss - ETA: 49s - loss: 0.4968 - accuracy: 0.86 - ETA: 49s - loss: 0.4965 - accuracy - ETA: 48s - loss: 0.49 - ETA: 46s - loss: 0.4975 - accuracy: 0.86 - ETA: 46s - loss: 0.4962 - accuracy: 0.867 - ETA: 46s - loss: 0.4979 - accuracy: 0.86 - ETA: 46s - loss: 0.4945 - accuracy: - ETA: 45s - loss:  - ETA: 44s - loss: 0.4916  - ETA: 40s - ETA: 38s - loss: 0.4910 - accuracy: 0.86 - ETA: 37s - loss: 0.4914 - accuracy: 0.86 - ETA: 37s - loss: 0.4906 - accura - ETA: 37s - loss: 0.4 - ETA: 35s - loss: 0.4879 - accuracy: 0.8 - ETA: 35s - loss: 0.4877 - accuracy - ETA: 34s - loss: 0.4873 - accuracy: 0.86 - ETA: 34s - loss: 0.48 - ETA: 33s - loss: 0.4872 - accurac - ETA: 32s - loss: 0.48 - ETA: 28s - loss: 0.4914 - ETA: 27s - loss: 0.4914 - accuracy: - ETA: 26s - loss: 0.4921 - accuracy:  - ETA: 26s - loss: 0.4912 - a - ETA: 25s - loss: 0.4890 - accur - ETA: 24s - loss: 0.4878 - accur - ETA: 23s - loss: 0.48 - ETA: 22s - loss: 0.4883 - acc - ETA: 21 - ETA: 19s - loss: 0.4893 - ETA: 17s - loss: 0.4894 - accuracy: 0.870 - ETA: 17s - loss: 0.4894 - accura - ETA: 17s - loss: 0.4892 - accuracy: 0 - ETA: 16s - loss: 0.4891 - accuracy: 0.870 - ETA: 16s - loss: 0.4892 - ac - ETA: 15s - loss: 0.4887 - accuracy: - ETA: 12s - loss: 0.4875 - acc - ETA: 11s - loss: 0.4879 - ETA: 10s - loss: 0.4878 - accuracy: 0.8 - ETA: 10s - loss: 0.4882 - accuracy: 0.871 - ETA: 9\n",
      "Epoch 00052: val_accuracy did not improve from 0.85400\n",
      "781/781 [==============================] - 57s 73ms/step - loss: 0.4879 - accuracy: 0.8713 - val_loss: 0.6106 - val_accuracy: 0.8449\n",
      "Epoch 53/75\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.4843 - accuracy: 0.8735 - ETA: 49s - loss: 0.5127 - - ETA: 46s - loss: 0.4741 - accuracy: 0 - ETA: 46s - loss: 0.4761 - accuracy: 0.875 - ETA: 46s - loss: 0.4758 - accuracy: 0.87 - ETA: 45s - loss: 0.4757 - acc - ETA: 45s - loss: 0.4759 - accuracy: 0. - ETA: 44s - loss: 0.4763 - accuracy: 0. - ETA: 44s - loss: 0.4768 - - ETA: 43s - loss: 0.4795 - accuracy: 0.87 - ETA: 43s - loss: 0.4791 - accuracy:  - ETA: 42 - ETA: 40s - loss: 0.4758 - accuracy: 0.8 - ETA: 40s - loss: 0.4747 - accuracy: - ETA: 39s - loss: 0.4752 - accura - ETA: 39s - loss: 0.4744 - accuracy: 0 - ETA: 38s - loss: 0.4740 - accuracy:  - ETA: 35s - loss: 0.4748 - ac - ETA: 34s - loss: 0.4757 - ac - ETA: 33s - loss: 0.4748 - accuracy: 0.876 - ETA: 33s - loss: 0.4746 - accurac - ETA: 32s - loss: 0.4752 - accuracy: 0.87 - ETA: 32s - loss: 0.4756 - - ETA: 31s - loss: 0.4764 - accuracy: 0.875 - ETA: 31s - loss: 0.4763 - accuracy:\n",
      "Epoch 00053: val_accuracy did not improve from 0.85400\n",
      "781/781 [==============================] - 56s 72ms/step - loss: 0.4843 - accuracy: 0.8735 - val_loss: 0.6191 - val_accuracy: 0.8350\n",
      "Epoch 54/75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "781/781 [==============================] - ETA: 0s - loss: 0.4831 - accuracy: 0.8747 - ETA: 51s - loss: 0.4806 - accuracy: 0.87 - ETA: 51s - ETA: 48s - loss: 0.4553 - accuracy: 0.88 - ETA: 48s - loss: 0. - ETA: 46s - - ETA: 44s - loss: 0.4643 - accura - ETA: 43s - loss: 0.4 - ETA: 42s - l - ETA: 40s - l - ETA: 38s - loss: 0.4670 - accuracy: 0. - ETA: 38s - loss: 0.4656 - accuracy: 0 - ETA: 38s - loss: 0.4666 - accuracy:  - ETA: 37s - loss:  - ETA: 35s -  - ETA: 30s - loss: - ETA: 29s - loss: 0.4758 - accuracy: 0.878 - ETA: 29s - loss: 0.4756 - accur - ETA: 28s -  - ETA: 26s - loss: 0.4778 - accur - ETA: 25s - loss: 0. - E - ETA: 21s - loss: 0.4803 - accuracy:  - ETA: 20s - loss: 0.4795 - accu - ETA: 19s - loss: 0.4806 - accuracy: 0.875 - ETA: 19s - loss: 0.4807 - accuracy: 0. - ETA: 19s - loss: 0.480 - ETA: 18s - loss: 0.4804 - acc - ETA: 17s - loss: 0.4808 - accuracy: 0.87 - ETA: 17s - los - ETA: 15s - loss: 0.4815 - acc - ETA: 14s - loss: 0.48 - ETA: 13s - loss: 0.4818 - accuracy: 0.875 - ETA: 13s - loss: 0.4816  - ETA: 11s - loss: 0.4823 - accura - ETA: 11s - loss: 0.4824 - accuracy - ETA: 10s - loss: 0.4828 - accura - ETA: 10s - loss: 0 - ETA: 0s - loss: 0.4829 - ac\n",
      "Epoch 00054: val_accuracy did not improve from 0.85400\n",
      "781/781 [==============================] - 57s 73ms/step - loss: 0.4831 - accuracy: 0.8747 - val_loss: 0.6173 - val_accuracy: 0.8459\n",
      "Epoch 55/75\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.4825 - accuracy: 0.8750 - ETA: 49s - loss: 0.5127 - - ETA: 48s - loss: 0.4967 - accuracy: 0.871 - ETA: 48s - loss: 0. - ETA: 47s - loss: 0.4839 - accuracy: 0.8 - ETA: 47s - loss: 0.4804 - accuracy: 0.8 - ETA: 46s - loss: 0.4791 - accuracy:  - ETA: 46s - loss: 0.4821 - accura - ETA: 45s - loss: 0.4858 - accur - ETA: 45s - loss:  - ETA: 43s - loss: 0.4930 - - ETA: 42s - loss: 0.4919 - accu - ETA: 41s - loss: - ETA: 40s - loss:  - ETA: 38s - loss: 0.4906 - accuracy: 0.870 - ETA: 38s - l - ETA: 36s - loss: 0.4885 - a - ETA: 35s - loss:  - ETA: 33s - loss: 0.4847 - accu - ETA: 33s - loss: 0.48 - ETA: 28s - loss: 0.4832 - acc - ETA: 27s - loss - ETA: 25s - loss: 0.4828 - acc - ETA: 25s - loss: 0.4825 - accuracy:  - ETA: 24s - loss: 0.4832 - accuracy: 0.87 - ETA: 24s - loss: 0.4 - ETA: 23s - l - ETA: 21s - loss: - ET - ETA: 13s - loss: 0.4815  - ETA: 12s - lo - ETA: 10s - loss: 0.4823 - accuracy:  - ETA: 10s - loss: 0.4821 - accurac - ETA: 8s - loss: 0.4819 - accura - ETA: 8s - loss: 0.4813 - accura - ETA: 7s - loss: 0.4809 - accuracy:  - ETA: 6s - loss: 0.4807 - accuracy: 0. - ETA - ETA: 4s - loss: 0.4803 - accu - ETA: 1s - loss: 0.4825 - ac - ETA: 0s - los\n",
      "Epoch 00055: val_accuracy did not improve from 0.85400\n",
      "781/781 [==============================] - 56s 72ms/step - loss: 0.4825 - accuracy: 0.8750 - val_loss: 0.5669 - val_accuracy: 0.8495\n",
      "Epoch 56/75\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.4769 - accuracy: 0.8765 - ETA: 49s - loss: 0.4574 - acc - ETA: 48s - loss: 0.4595 - accuracy: 0. - ETA: 41s - loss: 0.4775 - accuracy: 0.8 - ETA: 41s - loss: 0.4782  - ETA: 39s - loss: 0.4757 - accuracy: 0. - ETA: 39s - loss: 0. - ETA: 37s - loss: 0.4736 - accu - ETA: 37s  - ETA: 34s - loss: 0.4735 - accuracy - ETA: 34s - los - ETA: 32s - loss: 0.4759 - accuracy: 0.87 - ETA: 32s - loss: 0.4757 - accuracy: 0 - ETA: 31s - loss: 0.4773 - accuracy: 0 - ETA: 31s - loss: 0.4781 - accuracy: 0.8 - ETA: 31s - loss: 0.4764 -  - ETA: 30s - loss: 0.4762 - accuracy: 0.87 - ETA: 30s - loss: 0.4754 - accuracy: 0 - ETA: 29s - loss: 0.4754 - accuracy: 0.8 - ETA: 29s - loss: 0.4752 - accuracy: 0.8 - ETA: 29s - loss: 0.4751 - accur - ETA: - ETA - ETA: 20s - loss: 0.4755 - accuracy: 0.876 - ETA: 20s - loss: 0.4751 - accuracy: - ETA: 20s - loss: 0.47 - ETA: 18s - loss: 0.4759 - ac - ETA: 17s - loss: 0.4771 - accuracy: 0.876 - ETA:  - ETA: 15s - loss: 0.4769 - accuracy: 0.876 - ETA: 15s - loss: 0.4774 - accuracy: 0.876 - ETA: 15s - loss: 0.4 - ETA: 13s - l - ETA: 5s - loss: 0.4739 - ac - ETA: 1s - loss: 0.4757 - accura - ETA: 1s - loss: 0.4767 - accuracy:  - ETA: 1s - loss: 0 - ETA: 0s - loss: 0.4773 - accu\n",
      "Epoch 00056: val_accuracy did not improve from 0.85400\n",
      "781/781 [==============================] - 56s 71ms/step - loss: 0.4769 - accuracy: 0.8765 - val_loss: 0.6426 - val_accuracy: 0.8308\n",
      "Epoch 57/75\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.4748 - accuracy: 0.8774 - ETA: 49s - loss: 0.4752 - acc - ETA: 47s - loss: 0.4604 - accuracy: 0.88 - ETA: 47s - loss: 0.4602 - - ETA: 46s - loss: 0.4687  - ETA: 45s - loss: 0.4710 - accur - ETA: 44s - loss: 0.4789 - accuracy - ETA: 41s - - ETA: 39s - loss: 0.4736 - accuracy: 0 - ETA: 39s - loss: 0.4726 - accuracy - ETA: 38s - loss: 0.4705 - accuracy:  - ETA: 38s - loss: 0.4686 - accuracy: 0.8 - ETA - ETA: 35s - loss: 0.4689 - acc - ETA: 28s - loss: 0.469 - ETA: 27s - loss: 0.4708 - accuracy: - ETA: 27s - loss - ETA: 25s - - ETA: 23s - loss: 0.4737 - accu - ETA: 22s - loss: 0.4723 - ETA: 18s - loss: 0.4723 - accuracy: 0.8 - ETA: 18s - loss: 0.4731 - accuracy: 0.87 - ETA: 17s - ETA: 15s - loss: 0.4724 - accurac - ETA: 15s - loss: 0.4724 - - ETA: 0s - loss: 0.4748 - accuracy\n",
      "Epoch 00057: val_accuracy did not improve from 0.85400\n",
      "781/781 [==============================] - 56s 72ms/step - loss: 0.4748 - accuracy: 0.8774 - val_loss: 0.6262 - val_accuracy: 0.8395\n",
      "Epoch 58/75\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.4716 - accuracy: 0.8785 - ETA: 50s - loss: 0.4736 - ac - ETA: 49s - loss: 0.4787 - accurac - ETA: 48s - loss: 0.4690 - accuracy: 0. - ETA: 48s - loss: 0.4659 - a - ETA: 48s - loss: 0.4515 - accuracy: 0. - ETA: 48s - loss: 0.4544 - accu - ETA: 47s - loss:  - ETA: 45s - loss: 0.4689 - accuracy: 0.87 - ETA: 45s - loss: 0.4700  - ETA: 44s - loss: - ETA: 30s - loss: 0.4662 -  - ETA: 29s  - E - ETA: 24s - loss: 0.4607 - accur - ETA: 23s - loss: 0.4618 - accuracy: 0.882 - ETA: 23s - loss: 0.4619 - accuracy: 0. - ETA: 23s - loss: 0.4618 - accurac - ETA: 22s - loss: 0. - ETA: 21s - loss: 0.4666 - accuracy: 0.8 - ETA: 21s - loss: 0.4668 -  - ETA: 16s - loss: 0.4666 - accuracy: - ETA: 16s - loss: 0.4667 - accuracy: 0.8 - ETA: 16s - loss: 0.4669  - ETA: 15s - loss: 0.46 - ETA: 13s - loss: 0.4 - ETA: 12s - loss: 0.4676 - accur - ETA: 11s - loss: 0.46 - ETA: 10s - loss:  - ETA: 7s - loss: 0.4692 - accura - ETA: 7s - - ETA: 6s - loss: - - ETA: 4s - loss: 0.4704 - accuracy - ETA:  - ETA: 2s - loss: - ETA: 1s - loss: 0.4710 - accuracy:  - ETA: 1s - loss: 0.4713 - accura - E\n",
      "Epoch 00058: val_accuracy did not improve from 0.85400\n",
      "781/781 [==============================] - 57s 72ms/step - loss: 0.4716 - accuracy: 0.8785 - val_loss: 0.6181 - val_accuracy: 0.8442\n",
      "Epoch 59/75\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.4674 - accuracy: 0.8792 - ETA: 46s - loss: 0.4 - ETA: 44s - loss: 0.4513 - accur - ETA: 43s - loss: 0.4508 - accuracy:  - ETA: 43s - loss: 0.4501 -  - ETA: 42s - loss: 0.4530 - accuracy: 0.88 - ETA: 42s - loss: 0.4555 - accuracy - ETA: 41s - lo - ETA: 39s - - ETA: 34s - loss: 0.4587 - accuracy: 0 - ETA: 34s - loss: 0.4598 - acc - ETA: 33s - loss: 0.4613 - accuracy: 0 - ETA: 32s - loss: 0.4621 - accura - ETA: 29s - loss: 0.4624 - accuracy: 0.880 - ETA: 29s - loss: 0.4626 - accuracy: 0. - ETA: 28s - loss: 0.4620 - ac - ETA: 22s - loss: 0.4628 - accurac - ETA: 21s - loss: 0.4614 - accuracy: 0.880 - ETA: 21s - loss: 0.4611 - accurac - ETA: 20s - loss: 0.4608  - ETA: 19s - loss: 0.4601 - accura - ET - ETA: 16s - loss: 0.4618 - accuracy: 0.88 - ETA: 16s - loss: 0.4617 - accuracy: 0.8 - ETA: 16s - loss: 0.4619 - accuracy: 0.880 - ETA: 16s - loss: 0.4618 - accuracy: 0.8 - ETA: 15s - loss: 0.4617 - ac - ETA: 15s - loss: 0.4608 -  - ETA: 13s - loss: 0.4623 - accur - ETA: 13s - loss: 0.4622 - accura - ETA: 12s - loss: 0.4624  - ETA - ETA: 7s - loss: 0.4645 - accuracy: 0. - - ETA: 6s - loss: 0.464 - ETA: 5s - loss: 0.4650 -  - ETA:  - ETA: 1s - loss: 0.467 - ETA: 0s - loss: 0.4677 \n",
      "Epoch 00059: val_accuracy did not improve from 0.85400\n",
      "781/781 [==============================] - 56s 71ms/step - loss: 0.4674 - accuracy: 0.8792 - val_loss: 0.8374 - val_accuracy: 0.7913\n",
      "Epoch 60/75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "781/781 [==============================] - ETA: 0s - loss: 0.4717 - accuracy: 0.8800 - ETA: 50s - loss: 0.425 - ETA: 49s - loss: 0.4621 - ac - ETA: 48s - loss: 0.4598 - accura - ETA: 48s  - ETA: 45s - loss: 0.4673 - acc - ETA: 45s - loss: 0.4644 - accuracy - ETA: 44s - loss: 0.4642 - accuracy: 0.88 - ETA: 44s - loss: 0.4645 - accura - ETA: 37s - loss: 0.4695 - accuracy: 0 - ETA: 37s - loss: - ETA: 35s - ETA: 30s - loss: 0.4702 - accuracy: 0. - ETA: 30s - loss: 0.4694 - accuracy: 0 - ETA: 30s - loss: 0.4702 - accu - ETA: 26s - loss: 0.4687 - accuracy: 0 - ETA: 26s - loss: 0.468 - ETA: 24s - loss: 0.4689 - accur - ETA: 24s - loss: 0.4699 - accuracy:  - ETA: 23s - loss: 0.4701 - accuracy: 0 - ETA: 23s - loss: 0.4702 - acc - ETA: 22s - loss: 0.4700 - accuracy: 0.881 - ETA - ETA: 19s - loss: 0.4684 - acc - ETA: 18s - ETA: 16s - loss: 0.4730 - accuracy: 0 - ETA: 16s - loss: 0.4729 - accuracy - ETA: 15s - loss: 0.4728 - accu - ETA: 15s - loss: 0.4723 - accuracy: 0.88 - ETA: 14s - loss: 0.4719 - accu - ETA: 14s - loss: 0.4720 - accuracy:  - ETA: 13s - loss: 0.4720 - accura - ETA: 13s - loss: 0.4724 - accuracy - ETA: 12s - loss: 0.4720 - accur - ETA: 11s - loss: 0 - ETA: 8s - loss: 0.4726 - accuracy - ETA: 8s - l - ETA: 7s - los - ETA: 6s - loss: 0.472 - ETA: 5s - l - ETA: 4s - - ETA: 2s - loss: 0.4720  - ETA: 1s - loss: 0.4715 - accuracy: 0. - ETA: 1s - loss: 0.4715 - accuracy: 0. -\n",
      "Epoch 00060: val_accuracy improved from 0.85400 to 0.86510, saving model to my_best_model.epoch60-accuracy0.87.hdf5\n",
      "781/781 [==============================] - 57s 72ms/step - loss: 0.4717 - accuracy: 0.8800 - val_loss: 0.5360 - val_accuracy: 0.8651\n",
      "Epoch 61/75\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.4683 - accuracy: 0.8792 - ETA: 49s - loss: 0.4774  - ETA: 48s - loss: 0.4721 - accuracy: 0.87 - ETA: 4 - ETA: 46s - loss: 0.4701  - ETA: 44s - loss: 0.4673 - accuracy: - ETA: 44s - loss: 0.4661 - accu - ETA: 43s - loss: 0.46 - ETA: 42s - loss: 0.4632 - accuracy: 0.880 - ETA: 4 - - ETA: 37s - - ETA: 34s - loss: 0 - ETA: 33s - loss: 0.4643 - accuracy: 0.8 - ETA: 33s - loss: 0.4655 - acc - ETA: 32s - loss: 0.4656 -  - ETA: 31s - loss: 0.4648 - accur - ETA: 30s - loss: 0.4647 - accurac - ETA: 29s - loss: 0.4652 - acc - ETA: 28s - loss: 0.4666 - accuracy - ETA: 28s - loss: 0.4654 - accura - ETA: 27s - loss: 0.4661 - accuracy: 0.87 - ETA: 27s - loss: 0.4668 - accuracy - ETA: 27s - loss: 0.4670  - ETA: 25s - loss: 0.4657 -  - ETA: 24s - loss: 0.4663 - accuracy: 0.879 - ETA: 24s - loss: 0.4664 - accuracy:  - ETA: 24s - loss: 0. - ETA: 22s - loss: 0.4669 - accur - ETA: 22s - loss: 0.4673 - accuracy: 0. - ETA: 21s - loss: 0.4683 - accuracy:  - ETA: 21s - loss: 0.4687 - accuracy: 0 - ETA: 21s - loss: 0.4689 - accuracy: 0.879 - ETA: 21s - lo - ETA: 16s - loss: 0.4 - ETA: 6s - - ETA: 5s - - ETA: 4s - loss: 0 - ETA: 0s - loss: 0.4681 - \n",
      "Epoch 00061: val_accuracy did not improve from 0.86510\n",
      "781/781 [==============================] - 56s 72ms/step - loss: 0.4683 - accuracy: 0.8792 - val_loss: 0.7006 - val_accuracy: 0.8227\n",
      "Epoch 62/75\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.4687 - accuracy: 0.8790 - ETA: 45s - loss: 0.4470 - acc - - ETA: - ETA: 24s - loss - ETA: 23s - lo - ETA: 18s - loss:  - ETA: 16s - loss: 0.4643 - accura - ET - E - ETA: 1s - loss: 0.4680 - ac - ETA: 1s - los - ETA: 0s - loss: 0.4690 - accuracy\n",
      "Epoch 00062: val_accuracy did not improve from 0.86510\n",
      "781/781 [==============================] - 56s 72ms/step - loss: 0.4687 - accuracy: 0.8790 - val_loss: 0.5501 - val_accuracy: 0.8594\n",
      "Epoch 63/75\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.4624 - accuracy: 0.8824 - ETA:  - ETA: 40s - los - ETA: 38s - loss: 0.4498 - accura - ETA: 38s - loss: 0.4520 - accur - ETA: 37s - loss: 0.4533 - accuracy - ETA: 36s - loss: 0.4530 - accuracy:  - ETA: 36s - loss: 0.455 - ETA: 35s - loss: 0.4564 - accuracy: 0.88 - ETA: 34s - loss:   - ETA: 30s - loss: 0.4516 - accuracy: 0 - ETA: 30s - loss: 0.4521 - accuracy: 0 - ETA: 29s - los - ETA: 28s - loss: 0.4536 - accura - ETA: 27s - loss: 0.4514 - accuracy: 0.8 - ETA: 27s - ETA: 24s - loss: 0.4553 - accura - ETA: 24s - loss: 0.4555 - ETA: 22s - loss: 0 - ETA: 21s - loss: 0.4574 - accuracy: 0.8 - ETA: 21s - loss:  - ETA: 19s - loss: 0.46 - ETA: 18s - loss: 0.4603 -  - ETA: 17s - loss: 0.46 - ETA: 15s - loss: 0.4609 - accuracy: 0. - ETA: - ETA - ETA: 7s - loss: 0.4628 - ac - ETA: 6s - loss: 0.4626 - accura - ETA: 4s - loss: 0.4 - ETA: 4s - - ETA: 3s - l - ETA: 2s - loss: 0.4625 - accura - ETA: 1s - loss: 0.4626 - accuracy: 0.88 - ETA: 1s - loss: - ETA: 0s - los\n",
      "Epoch 00063: val_accuracy did not improve from 0.86510\n",
      "781/781 [==============================] - 56s 72ms/step - loss: 0.4624 - accuracy: 0.8824 - val_loss: 0.6571 - val_accuracy: 0.8373\n",
      "Epoch 64/75\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.4655 - accuracy: 0.8829 - ETA: 48s - loss: 0.4457 - ac - ETA: 49s - loss: 0.4463 - accuracy - ETA: 47s - loss: 0.4490 -  - ETA: 39s - loss: 0 - ETA: 37s - loss: 0.4622 - accuracy - ETA: 37s - loss: 0 - ETA: 35s - loss: 0.4614 - accuracy: 0.881 - ETA: 35s - loss: 0.4612 - ac - ETA: 34s - loss: 0.4623 - accuracy: 0.8 - ETA: 34s - loss: 0.4628 - accuracy - ETA: 27s - loss: 0.4644 - accuracy - ETA: 27s - loss: 0.4641 -  - ETA: 26s - loss - ETA: 24s - loss: 0.4637 - accuracy: 0.882 - ETA: 24s - loss: 0.4635 - ac - ETA: 2 - ETA: 21s - loss: 0.465 - ETA: 20s - loss: - ETA: 18s - loss: 0.4639 - accuracy: 0.883 - ETA: 18s - ETA: 16s - loss: 0.4648 - accurac - - ETA: 12s - loss: 0.4652 - - ETA: 11s - loss: 0.4651 - accuracy: 0.88 - ETA: 11s - loss: 0.46 - ETA: 8s - loss: - ETA: 6s - los - E - ETA: 3s - loss: 0.4 - ETA: 3s - loss: 0.4664 - ac - ETA: 2s - loss: 0.4661 - ac - E - ETA: 0s - loss: 0.4650 - accuracy: 0.88 - ETA: 0s - loss: 0.4 - ETA: 0s - loss: 0.4658 - accuracy: 0.88\n",
      "Epoch 00064: val_accuracy did not improve from 0.86510\n",
      "781/781 [==============================] - 57s 72ms/step - loss: 0.4655 - accuracy: 0.8829 - val_loss: 0.6005 - val_accuracy: 0.8437\n",
      "Epoch 65/75\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.4647 - accuracy: 0.8817 - ETA: 48s - loss: 0.4324 -  - ETA: 48s - - ETA: 44s - loss: 0.4406 - accuracy: 0. - ETA: 44s - loss: 0.4430 - accurac - ETA: 43s - loss: 0.4473 - accuracy:  - ETA: 42s - loss: 0.4466 - accuracy: 0.887 - ETA: 42s - loss: 0.4471 -  - ETA: 41s - loss: 0.4439 - accuracy: 0.888 - ETA: 41s - loss: 0.4445 - accuracy: 0 - ETA: 41s - loss: 0.4444 - accuracy: 0.88 - ETA: 41s -  - ETA: 39s - loss: 0.45 - ETA: 37s -  - ETA: 35s - loss: 0.4634 - accuracy: 0.882 - ETA: 35s - loss: 0.4637 - accura - ETA: 35s - loss: 0.4663 - acc - ETA: 34s - loss: 0.4632 - accuracy: - ETA: 33s - loss: 0 - ETA: 29s - loss: 0.4643 - accuracy: 0.88 - ETA: 29s - loss: 0.4639 - ETA: 27s - loss: 0.463 - ETA: 26s - loss: 0.4 - ETA: 25s - loss: 0.4629 - accuracy - ETA: 24s - loss: 0.4633 - accuracy: 0 - ETA: 24s - loss: 0.4624 - accu - ETA: 23s - loss: 0.4618 - accuracy:  - ETA: 23s - loss: 0.46 - ETA: 21s - loss: 0.4623 - accuracy: 0.8 - ETA: 21s - loss: 0.4623 - accuracy: 0.88 - ETA: 21s - loss: 0.4625 - ac - ETA: 20s - loss: 0.4633 - accuracy: 0. - ETA: 20s - loss: 0.4630 - accuracy: 0 - ETA: 19s - loss: 0. - ETA: 18s - loss: 0.4641 - accur - ETA: 17s - loss: 0.4641 - acc - ETA: 3s - loss: 0.4641 -  - ETA: 2s - loss: 0.4643 -  - ETA: 2s - loss: 0.4636 \n",
      "Epoch 00065: val_accuracy did not improve from 0.86510\n",
      "781/781 [==============================] - 56s 71ms/step - loss: 0.4647 - accuracy: 0.8817 - val_loss: 0.6633 - val_accuracy: 0.8299\n",
      "Epoch 66/75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "781/781 [==============================] - ETA: 0s - loss: 0.4587 - accuracy: 0.8824 - ETA: 50s - loss: 0.4323 - a - ETA: 48s - loss: 0 - ETA: 47s - loss: 0.4444 - accuracy: 0 - ETA: 47s - l - ETA: 45s - loss: 0.4393 - accur - ETA: 44s - loss:  - ETA: 42s - loss: 0.4419 - accur - ETA: 41 - ETA: 30s - loss: 0.450 - ETA: 28s - loss: 0.4502 - acc - ETA: 28s  - ETA: 22s - loss: 0.4544 -  - ETA: 21s -  - ETA: - ETA: 17s - loss: 0.4540 - accurac - ETA: 16s - loss: 0.455 - ETA: 12s - loss: 0.4565 - accuracy: 0.883 - ETA: 12s - loss: 0.4565 - accuracy: 0.88 - ETA: 12s - loss: 0.4565 - acc - ETA: 11s - l - ETA: 0s - loss: 0\n",
      "Epoch 00066: val_accuracy did not improve from 0.86510\n",
      "781/781 [==============================] - 56s 72ms/step - loss: 0.4587 - accuracy: 0.8824 - val_loss: 0.6347 - val_accuracy: 0.8394\n",
      "Epoch 67/75\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.4601 - accuracy: 0.8826 - ETA: 49s - loss: 0.4518 - accuracy:  - ETA: 49s - loss: 0.4418 - accuracy: - ETA: 49s - loss: 0.4363 - accur - ETA: 49s - loss: 0.4465 - accuracy: 0 - ETA: 49s - loss: 0 - ETA: 48s - loss: 0.4577 -  - ETA: 46s - loss: 0.4426 - accura - ETA: 46s - loss: 0.4 - ETA: 44s - loss: 0.4411 - accura - ETA: 43s - loss: 0.4445 - accuracy: 0 - ETA: 43s - loss: 0.44 - ET - ETA: 39s - los - ETA: 37s - loss: 0.4445 - accuracy: 0.8 - ETA: 37s - loss: 0.4 - ETA: 35s - loss: 0.4461 - accuracy - ETA: 35s - loss: 0.4449 - accuracy: 0. - ETA: 35s - loss: 0.4440 - accuracy: 0.8 - ETA: 34s - loss: 0.4441 - ac - ETA: 33s - loss: 0.4469 - accuracy:  - ETA: 33s - loss: 0.4482 - accuracy: 0.88 - ETA: 33s - loss: 0.4482 - accuracy: 0.88 - ETA: 33s - loss: 0.4480 - accu - ETA: 32s - loss: 0.4495 - - ETA: 31s - lo - ETA: 29s - loss: 0.4523 - accura - ETA: 28s - loss: 0.4517 - accuracy: 0 - ETA: 28s - loss: 0.4523 - accuracy: 0.885 - ETA: 28s - loss: 0.4529 - accura - ETA: 27s - loss: 0.4540 - accuracy: 0.8 - ETA: 27s - loss - ETA: 25s - loss: 0.4527 - accura - ETA: 25s - loss: 0.455 - ETA: 23s - loss: 0.4547 - - ETA: 22s - loss: 0.4559 - - ETA: 21s - loss: 0.4561 - accur - ETA: 20s - loss: 0.4572 - accura - ETA: 20s - loss: 0.4565 - accura - ETA: 19s - l - ETA: 17s - loss: 0.4585 - a - ETA: 16s - loss: 0.4582  - ETA: 15s - loss: 0.4582 - a - ETA: 14s  - ETA: 11s - loss: 0.4583 - accuracy - ETA: 11s - loss: 0.4586 - accuracy: 0. - ETA: 11s - loss: 0.458 - ETA: 6s - loss: 0.4607 - accu - ETA: 6s - loss: 0.4\n",
      "Epoch 00067: val_accuracy did not improve from 0.86510\n",
      "781/781 [==============================] - 56s 72ms/step - loss: 0.4601 - accuracy: 0.8826 - val_loss: 0.7101 - val_accuracy: 0.8205\n",
      "Epoch 68/75\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.4530 - accuracy: 0.8850 - ETA: 48s - loss: 0.4294 - accur - ETA: 49s - loss: 0.4407 - accuracy:  - ETA: 48s - loss: 0.4458 - accuracy: 0.885 - ETA: 48s - - ETA: 46s - loss: 0.4529 -  - ETA: 45s - loss: 0.4508 - accuracy - ETA: 45s - loss: 0.4506 - accuracy: - ETA: 41s - l - ETA: 36s - loss: 0.4477 - a - ETA: 35s - loss - ETA: 30s - loss: 0.4457 - a - ETA: 26s - lo - ETA: 24s  - ETA: 13s - loss: 0.4536 - accuracy: 0.88 - ETA:  - ETA: 11s - loss: 0.4528 - accur - ETA: 10s - loss: 0.4529 - accura - ETA: 9s - loss: 0.4530  - ETA: 9s - loss: 0.4541 -  - ETA: 8s - loss: 0.4539 -  - ETA: 8s - loss: 0.4539 - ac - ETA: 7s - loss: 0.4546 - accuracy: 0.88 - ETA: 7s - loss: 0 - ETA: 2s - loss: 0.4530 - accuracy - ETA: 2s - loss: 0.4530 -  - ETA: 1s - loss: 0.4530 - accu - ETA: 1s - loss: 0.4530 - accu - ETA: 1s - loss: 0.4 - ETA: 0s - loss: 0.4531 - accura\n",
      "Epoch 00068: val_accuracy did not improve from 0.86510\n",
      "781/781 [==============================] - 56s 71ms/step - loss: 0.4530 - accuracy: 0.8850 - val_loss: 0.5656 - val_accuracy: 0.8608\n",
      "Epoch 69/75\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.4561 - accuracy: 0.8840 -  - ETA: 48s - loss: 0.4318 - accuracy - ETA: 47s - loss: 0.4364 - accuracy:  - ETA: 46s - loss: 0.4376 - accuracy: 0.89 - ETA: 46s - loss: 0.4370 - accuracy: 0 - ETA: 46s - ETA: 44s - - ETA: 41s - loss: 0.4484 - accurac - ETA: 38s - loss: 0.4469 - accuracy:  - ETA: 38s - loss: 0.447 - ETA - ETA: 31s - loss: 0.4535 - accuracy: 0.88 - ETA: 31s - loss: 0.4529 - accura - ETA: - ETA: 27s - loss: 0.4538 - accuracy: - ETA: 27s - loss: 0.4544 - accuracy: 0.885 - ETA: 27s - loss: 0.45 - ETA: 25s - loss: 0.4540 - accuracy: 0.885 - ETA: 25s - loss: 0.4542 - accurac - ETA: 25s - loss: 0.4551 -  - ETA: 24s - los - ETA: 22s - loss: 0.4566 - accuracy: 0.8 - ETA: 22s -  - ETA: 20s - loss: 0.4555 - accurac - ETA: 19s - loss: 0.4562 - acc - ETA: 15s - \n",
      "Epoch 00069: val_accuracy did not improve from 0.86510\n",
      "781/781 [==============================] - 57s 72ms/step - loss: 0.4561 - accuracy: 0.8840 - val_loss: 0.7191 - val_accuracy: 0.8215\n",
      "Epoch 70/75\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.4551 - accuracy: 0.8833 - ETA: 52s - loss: 0.5203 -  - ETA: 51s - loss: 0.4975 -  - ETA: 49s - loss: 0.4730 - accura - ETA: 4 - ETA: 45s - loss: 0.4569 - accuracy: 0 - ETA: 45s - loss: 0.4581 - ac - ETA: 44s - loss: 0.4506 - ac -  - ETA: 40s - loss - ETA: 39s - loss: 0.4513 - accuracy - ETA: 35s - loss: 0.4573 - ETA: 34s - loss: 0.4565  - ETA: 33s - loss: 0.4546 - accuracy - ETA: 29s - loss: 0.4528 - accuracy: 0 - ETA: 29s - loss: 0.4538 - accuracy: 0.885 - ETA: 29s - loss: 0.4538 - accuracy:  - ETA: 28s - loss: 0.4532 - acc - ETA: 27s - loss: 0.4560 - accuracy: 0.88 - ETA: 27s - loss: 0.4562 - accurac - ETA: 27s - loss: 0.4558 - accuracy:  - ETA: 26s - loss: 0.45 - ETA: 25s - loss: 0.4581  - ETA: 21s - loss: 0.4555 - accu - ETA: 20s - loss: 0.4553 - accuracy: 0 - ETA: 20s - loss: 0.4552 - accu - ETA: 19s - loss: 0.4564 - accurac - ETA: 18s - loss: 0.4567 - accuracy - ETA: 18s - loss: 0.4554 - accur - ETA: 17s - loss: 0.4555 - accuracy: 0.8 - ETA: 17s - loss: 0.4556 - acc - E\n",
      "Epoch 00070: val_accuracy did not improve from 0.86510\n",
      "781/781 [==============================] - 56s 72ms/step - loss: 0.4551 - accuracy: 0.8833 - val_loss: 0.6584 - val_accuracy: 0.8326\n",
      "Epoch 71/75\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.4533 - accuracy: 0.8850 - ETA: 49s - loss: 0.4049 - accuracy - ETA: 49s - loss: 0.4152 - a - ETA: 47s - loss: 0.4187 - accuracy: 0 - ETA: 47s - - ETA: 45s - loss: 0.4333 - accu - ETA: 41s - loss: 0.4359 - a - ETA: 40s - loss: 0.4403 - accu - ETA: 39s - loss: 0.4445 - accuracy: 0.888 - ETA: 39s - loss: 0.444 - ETA: 38 - ETA: 35s - los - ETA: 34s - loss: 0.4513 - accuracy:  - ETA: 30s - loss: 0.4494 - accuracy: 0.88 - ETA: 30s - loss: 0.4485 - accura - ETA: 29s - loss: 0.4495 - accurac - ETA:  - ETA: 26s - loss: 0.4 - ETA: 25s - loss: 0.4532 - accuracy - ETA: 24s - loss: 0.4544  - ETA: 23s - loss: 0.4542 - accura - ETA: 23s - loss: 0.4543 - accuracy:  - ETA: 22s - loss: 0.4537 - accuracy: 0.88 - ETA: 22s - loss: 0 - ETA: 21s - loss: 0.4550 - accuracy:  - ETA:  - ETA: 18s - loss: 0.4523 - acc - ETA: 17s - loss: 0.4526 - accuracy:  - ETA: 17s - loss:  - ETA: 15s - loss: 0.4523  - ETA: 0s - loss: 0.4532 - accuracy:  - ETA: 0s - loss: 0.4531 - accuracy: 0. - ETA: 0s - loss: 0.4531 - accuracy\n",
      "Epoch 00071: val_accuracy did not improve from 0.86510\n",
      "781/781 [==============================] - 56s 71ms/step - loss: 0.4533 - accuracy: 0.8850 - val_loss: 0.6367 - val_accuracy: 0.8363\n",
      "Epoch 72/75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "781/781 [==============================] - ETA: 0s - loss: 0.4491 - accuracy: 0.8874 - ETA: 46s - loss: 0.4543 - acc - ETA: 45s - loss: 0.4559 - accuracy: 0. - E - ETA: 43s -  - ETA: 40s - loss: 0.4582 - accuracy: - ETA: 40s - loss: 0.4569 - accur - ETA: 39s - loss: 0.4558 - accurac - ETA: 39s - loss: 0.4569 - accuracy: - ETA: 35s - loss: 0.4524 - accuracy:  - ETA: 35s - loss: 0.4 - ETA: 33s - loss:  - ETA: 31s - loss: 0.4560 - acc - ETA: 31s - loss: 0.4552 - accuracy: 0.88 - ETA: 31s - loss: 0.4554 - ac - ETA: 30s - loss: 0.4548 - accura - ETA: 29s - loss: 0.4545 - accuracy: 0.88 - ETA: 29s - loss: 0.4545 - accura - ETA: 28s - lo - ETA: 26s - loss: 0.4513 - accuracy: - ETA: 26s - loss: 0.4523 - accura - ETA: 25s - loss: 0.45 - ETA: 24s - loss: 0.4505 - accurac - ETA: 23s - loss: 0.4502 - accuracy: 0.8 - ETA: 23s - loss: 0.4498 - accur - ETA: 19s - loss: 0.4492 - accur - ETA: 19s - loss: 0.4492 - a - ETA: 18s - loss: 0.4 - ETA: 16s - loss: 0.4487 - accuracy: 0.888 - ETA: 16s - loss: 0.4488 - a - ETA: 15s - loss: 0.4497 - accur - ETA: 0s - loss: 0.4490 \n",
      "Epoch 00072: val_accuracy did not improve from 0.86510\n",
      "781/781 [==============================] - 57s 72ms/step - loss: 0.4491 - accuracy: 0.8874 - val_loss: 0.6793 - val_accuracy: 0.8269\n",
      "Epoch 73/75\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.4489 - accuracy: 0.8868 - ETA: 47s - loss: 0. - ETA: 42s - loss: 0.4 - ETA: 41s - loss: 0.4376 - accuracy: 0. - - ETA: 38s - loss: 0.4405 - accuracy - ETA: 37s - loss: 0.4425 - accuracy: 0.88 - ETA: 37s - loss: 0.4424 - accu - ETA: 36s - loss - ETA: 35s - loss: 0.4399 - accuracy: 0 - ETA: 34s - loss: 0.4408 - accuracy: 0 - ETA: 34s - loss: 0.4402 - accuracy: 0.8 - ETA:  - ETA: 31s - loss: 0.4393 - accuracy: - ET -  - ETA: 26s - loss: 0.4454 - accuracy: - ETA: 25s - loss: 0.4458 - accuracy: 0.888 - ETA: 25s - los - ETA: 14s - loss: 0.4465 - ETA: 13s - loss: 0. - - ETA:  - ETA: 3s - loss: 0.4475  - ETA: 0s - loss: 0.4488 - ac\n",
      "Epoch 00073: val_accuracy did not improve from 0.86510\n",
      "781/781 [==============================] - 57s 73ms/step - loss: 0.4489 - accuracy: 0.8868 - val_loss: 0.5588 - val_accuracy: 0.8608\n",
      "Epoch 74/75\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.4443 - accuracy: 0.8886 - E - ETA: 34s - loss: 0.4423 - accuracy - ETA: 33s - loss: 0.4427 - a - ETA: 32s  - ETA: 30s - loss: 0.4421 - accuracy: 0.887 - ETA: 30s - loss: 0. - ETA:  - ET - ETA: 20s - loss: 0.4436 - accuracy - ETA: 20s - loss: 0.4431 - - ETA: 18s - loss: 0.4416 - accuracy: 0. - E - ETA: 1s - loss: 0.4451 - ac - ETA: 0s - loss: 0.4447 - \n",
      "Epoch 00074: val_accuracy did not improve from 0.86510\n",
      "781/781 [==============================] - 57s 73ms/step - loss: 0.4443 - accuracy: 0.8886 - val_loss: 0.8878 - val_accuracy: 0.7931\n",
      "Epoch 75/75\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.4458 - accuracy: 0.8882 - ETA: 4 - ETA: 44s - loss: 0.4333 - accurac - ETA: 43s - loss: 0.4327 - accura - ETA: 43s -  - ETA: 41s - loss: 0.4303 - accuracy: 0. - ETA: 40s - loss: 0. - ETA: 39s - loss: 0.4265 - accuracy: 0.8 - ETA: 38s - loss: 0.4268 - accuracy: 0.8 - ETA: 38s - loss: 0.4262 - acc - ETA: 37s - loss:  - E - ETA: 33s - loss: 0.4323 - ETA: 32s  - ETA: 30s - loss: 0.4303 - accuracy:  - ETA: 29s - loss: 0.4309 - acc - ETA: 28s - loss: 0.4312 - a - ETA: 27s - loss: 0.4360 - accuracy:  - ETA: 27s - loss: 0.4359 - a - ETA: 26s - loss: 0.4383 - accu - ETA: 25s - loss: 0.4401  - ETA: 24s - loss: 0.4397 - accuracy: 0.8 - ETA: 24s - loss: 0.4394 - accuracy:  - ETA: 23s - loss: 0.4396 - accuracy: 0.8 - ETA:  - ETA: 21s - loss: 0.4385 - accuracy:  - ETA: 20s - loss: 0.43 - ETA: 19s - loss: 0.4409 - accuracy: 0. - ETA: 19s - loss: 0.4407  - ETA: 18s -  - ETA: 16s - loss: 0.4 - ETA - ETA: 0s - loss:\n",
      "Epoch 00075: val_accuracy did not improve from 0.86510\n",
      "781/781 [==============================] - 56s 72ms/step - loss: 0.4458 - accuracy: 0.8882 - val_loss: 0.6363 - val_accuracy: 0.8388\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24a11dba0a0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(img_gen,\n",
    "          steps_per_epoch=steps,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, y_test),\n",
    "          callbacks=[checkpoint,tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 7780), started 10:43:18 ago. (Use '!kill 7780' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-d1a78a913b73586a\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-d1a78a913b73586a\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"model_rms_80ep.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(learning_rate=0.0005,decay=1e-6),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.3924 - accuracy: 0.9060 - ETA: 51s - loss: 0.4297 - - ETA: 50s - loss: 0.4249 - accuracy: 0.895 - ETA: 51s - loss: - ETA: 48s - loss: 0.4061 - accuracy:  - ETA: 48s - loss: 0.4034 - accuracy:  - ETA: 47s - loss: 0.4050 - accurac - ETA: 46s - loss: 0.4065 - accur - ETA: 45s - loss: 0.4042 - ac - ETA: 44s - loss: 0.4060 - accurac - ETA: 44s - loss: 0.4067 - - ETA: 36s - loss: 0.4010 - accura - ETA: 36s - loss: 0.3998 - ac - ETA: 35s - ETA: 32s - loss: 0.3970 - accuracy:  - ETA: 32s - loss: 0.3965 - accuracy:  - ETA: 32s - loss: 0.3964 - ETA: 30s - loss: - ETA: 29s - loss: 0.3951 - accuracy: 0.9 - ETA: 28s - loss: 0.3952 - accuracy: 0.9 - ETA: 28s - loss:  - ETA: 27s - loss: 0.3948 - accura - ETA: 26s - loss: 0.3940 - accuracy: 0 - ETA: 26s - loss: 0.3947 - accur - ETA: 25s - loss: 0.3949 - acc - ETA: 24s - loss: 0.39 - ETA: 23s - loss: 0.3947 -  - ETA: 22s - loss: 0.3954 - accuracy: 0. - ETA: 21s - loss: 0.3958 - accuracy: 0 - ETA: 21s - loss: 0.3968 - accu - ETA: 20s - loss: 0.3962 - accuracy:  - ETA: 20s - loss: 0.3958 - ac - ETA: 19s - loss: 0.3962 - accuracy: 0.905 - ETA: 19s - loss: 0.3965 - ETA: 17s - loss: 0.3955 - - ETA: 16s - loss: 0.3954 - accu - ETA: 15s - loss - ETA: 7s - loss: 0.3917 - accura - ETA: 7s - loss: 0.3919 - accuracy:  - ETA: 7s - - ETA: 4s - - ETA: 0s - loss: 0.392\n",
      "Epoch 00001: val_accuracy improved from 0.86510 to 0.86610, saving model to my_best_model.epoch01-accuracy0.87.hdf5\n",
      "781/781 [==============================] - 64s 73ms/step - loss: 0.3924 - accuracy: 0.9060 - val_loss: 0.5369 - val_accuracy: 0.8661\n",
      "Epoch 2/100\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.3779 - accuracy: 0.9094 - ETA: 49s  - ETA: 48s - loss - ETA: 46s - loss: 0.3590 - accur - ETA: 46s - loss: 0.3670 - ETA: 45s - loss: 0.3640 - a - ETA: 44s - loss: 0.3655 - accura - ETA: 43s - loss: 0.3676 - accuracy: 0.9 - ETA: 43s - loss: 0.3667 - ac - ETA: 42s - loss: 0.3688 - accuracy: 0.913 - ETA: 42s - loss: 0.3686 - acc - ETA: 41s - loss: 0.3720 - accuracy: 0. - ETA: 41s - loss: 0.3724 - accuracy: 0.9 - ETA: 41s - loss: 0.3724 - accu - ETA: 40s - loss: 0.3748 - accuracy: 0.9 - ETA: 39s - loss: 0.3742 - accuracy - ETA: 39s - loss: 0.3729 - accuracy: 0.91  - ETA: 36s - loss: 0.3754 - accuracy: - ETA: 35s -  - ETA: 33s - loss: 0.3772  - ETA: 32s  - ETA: 30s - loss: 0.3777 - accuracy: 0.9 - ETA: 30s - loss: 0.3 - ETA: 28s - loss: 0.3760 - accuracy:  - ETA: 22s - loss: 0.3757 - accur - ETA: 21s - loss: 0.3755 - - ETA: 20s  - ETA: 18s - loss: 0 - ETA: 16s - loss: 0.3780 - accuracy - ETA: 16s - loss: 0.3782 - accurac - ETA: 15s - ETA: 13s - loss: 0.3764 - accuracy: 0.910 - ETA: 13s - loss: 0.3762 - accuracy: 0.91 - ETA: 13s - ETA: 3s - loss: 0.3768 - accuracy - ETA: 3s - loss: 0.3769  - ETA: 2s - loss: 0.3766 - accuracy:  - ETA: 2s - loss: 0.3770 - accuracy: 0. - - ETA: 0s - loss: 0.3\n",
      "Epoch 00002: val_accuracy improved from 0.86610 to 0.86860, saving model to my_best_model.epoch02-accuracy0.87.hdf5\n",
      "781/781 [==============================] - 56s 72ms/step - loss: 0.3779 - accuracy: 0.9094 - val_loss: 0.5410 - val_accuracy: 0.8686\n",
      "Epoch 3/100\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.3743 - accuracy: 0.9111 - ETA: 47s - loss: 0.3593 - - ETA: 46s - loss: 0.3619 - accuracy: 0.917 - ETA: 46s - loss: 0.3616 - accuracy: - ETA: 45s - loss: 0.3651 - accuracy: 0.91 - ETA: 45s - loss: 0.363 - ETA: 44s - loss: 0.3665 - accu -  - - ETA: 29s - loss: 0.3695 - accuracy:  - ETA: 28s - loss: 0.3700 - accuracy: 0.9 - ETA: 28s - loss: 0.3696 - accuracy: 0 - ETA: 28s - loss: 0.3698 - a - ETA: 27s - loss: 0.3708 - accuracy: 0. - ETA: 27s - loss: 0.3707 - accuracy: - ETA: 26s - loss: 0.3708 - accurac - ETA: 26 - ETA: 23s - loss: 0.3699 - accura - ETA: 23s - loss: 0.3704 - accuracy: 0.913 - ETA: 23s - ETA: 20s - loss: 0.3 - ETA: 19s - loss: 0.3704 - accuracy: - ETA: 18s - loss: 0.3706 - - ETA: 17s - - ETA: 15s - loss: 0.37 - ETA - ETA: 0s - loss: 0.3743  - ETA: 0s - loss: 0.3744 - accuracy: 0.91\n",
      "Epoch 00003: val_accuracy improved from 0.86860 to 0.87640, saving model to my_best_model.epoch03-accuracy0.88.hdf5\n",
      "781/781 [==============================] - 57s 73ms/step - loss: 0.3743 - accuracy: 0.9111 - val_loss: 0.5113 - val_accuracy: 0.8764\n",
      "Epoch 4/100\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.3708 - accuracy: 0.9117 - ETA: 50s - loss: 0.4052 - accuracy: 0 - ET - ETA: 47s - loss - ETA: 46s - loss: 0.3722 - accuracy: 0.91 - ETA: 46s - loss: 0.3717 - accu - ETA: 45s - loss: - ETA: 43s - loss: 0.3730 - accuracy: 0.9 - ETA: 43s - l - ETA: - ETA: 38s - loss: 0.3660 - accur - ETA: 38s - los - ETA: 36s - los - ETA: 34s - loss: 0.3698 - accuracy: 0 - ETA: 34s - loss: 0.3702 - accurac - ETA: 33s - loss: 0 - ETA: 31s - loss: 0.3682 - - ETA: 27s - loss: 0.3709 - accuracy: 0.91 - ETA: 27s - loss: 0.3705 - accuracy: 0 - ETA: 27s - lo - ETA: 25s - loss: 0 - ETA: 23s - loss: 0.3701 - accuracy - ETA: 23s - los - ETA: 21s - loss: 0.3687 - ETA: 20s - loss: 0.3687 - accuracy: 0.91 - ETA: 20s - loss: 0.369 - ETA: 15s - loss: 0.3687 - accuracy: 0.911 - ETA: 15s - loss: 0.3686 - accuracy: - ETA: 15s - loss: 0.3687 - accurac - ETA: 14s - loss: 0.3692 - - ETA: 13s - loss - - ETA: 9s - loss: - ETA: 8s - loss: 0.3688 - accuracy:  - ETA: 8s - loss: 0.3688 - accuracy:  - ETA: 8s - loss: 0.3693  - ETA: 7s - los - ETA: 2s - l - ETA: 1s - - ETA: 0s - loss: 0.3708 - accuracy: 0. - ETA: 0s - loss: 0.3708 - accuracy: 0.\n",
      "Epoch 00004: val_accuracy did not improve from 0.87640\n",
      "781/781 [==============================] - 56s 72ms/step - loss: 0.3708 - accuracy: 0.9117 - val_loss: 0.5041 - val_accuracy: 0.8746\n",
      "Epoch 5/100\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.3648 - accuracy: 0.9140 - ETA: 48s - los - ETA: 43s - loss: 0.3607 - accuracy: 0.915 - ETA: 43s - loss: 0.3607 - accuracy: 0 - ETA: 42s - loss: 0.3596 - accurac - ETA: 42s - loss: 0.3595 - accuracy: 0.916 - ETA: 42s - loss: 0.3585 - accuracy: 0.916 - ETA: 42s - loss: 0.3599 - accura - ETA: 41s - loss: 0.3599 - accuracy: 0.916 - ETA: 41s - loss: 0.3590 - accu - ETA: 40s - loss: 0.3589  - ETA: 39s - loss: 0.3577 - accuracy: 0.9 - ETA: 39s - loss: 0.3576 - accuracy: 0.91 - ETA: 39s - loss: 0.3575 - - ETA: 38s - loss: 0.3578 - accuracy - ETA: 37s - loss: 0.3585 - ac - ETA: 36s - loss: 0.3562 - ac - ETA: 32s - loss: 0.3556 - accur - ETA: 19s - loss: 0.3618 - accura - ETA: 19s - loss: 0.3616 - accurac - ETA: 18s - loss: 0.3612 - accurac - ETA: 18s - loss: 0.3617 - a - ETA: 17s - loss:  - ETA: 15s - loss: 0.3629 - a - ETA: 14s - loss: 0.3634 - ac - ETA: 13s - loss: 0.3645 - accura - ETA: 12s - loss: 0.36 - ETA: 11s - loss: 0.364 - ETA: 5s - loss: 0.3657 - accuracy - ETA - ETA: 4s - loss: 0.3660 - accuracy: 0.91 - - E - ETA: 1s - loss: 0.3652 - accuracy - ETA: 1s - loss: 0.3652 - accuracy:  - ETA: 0s - loss: 0.3651 - accuracy: 0. - ETA: 0s - loss: 0.3648 - accura - ETA: 0s - loss: 0.3646 - ac\n",
      "Epoch 00005: val_accuracy improved from 0.87640 to 0.87680, saving model to my_best_model.epoch05-accuracy0.88.hdf5\n",
      "781/781 [==============================] - 56s 72ms/step - loss: 0.3648 - accuracy: 0.9140 - val_loss: 0.5044 - val_accuracy: 0.8768\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "781/781 [==============================] - ETA: 0s - loss: 0.3594 - accuracy: 0.9139 - ETA: 47s - loss: 0.3704 - - ETA: 46s - loss - ETA: 44s - loss: 0.3546 - accuracy: - ETA: 44s - loss:  - ETA: 42s - loss: 0.3503 - a - ETA: 41s - loss: 0.3477 - - ETA: 40s - l - ETA: 39s - loss: 0.3540 - acc - ETA: 38s - loss: 0.3567 - accura - ETA: 37s - loss: 0.3560 - accurac - ETA: 37s -  - ETA: 34s - loss: 0.3612 - accuracy: 0.913 - ETA: 34s - loss: 0.3614  - ETA: 33s - loss: - ETA: 31s - loss: 0.3605 - accu - ETA: 31s - loss: 0.3596 - accur - ETA: 30s - loss: 0.3580 - accuracy: 0. - ETA: 30s - loss: 0.3582 - ac - ETA: 29s - loss: 0.3583 - accuracy: - ETA: 28s - loss: 0.3574 - accura - ETA: 28s - loss: 0.3575 - accurac - ETA: 27s - loss: 0.3593 - accuracy: 0.914 - E - ETA: 19s - loss: 0.3587 - accuracy: 0.91 - ETA: 18s - loss: 0.3588 - accuracy: 0.91 - ETA: 18s - loss: 0.3588 - accuracy - ETA: 18s - loss:  - ETA: 16s - loss: 0.359 - ETA: 15s - loss: 0.3593 - accuracy - ETA: 14s - loss: 0.3594 - accurac - ETA: 14s - loss - ETA: 12s - loss: 0.3599 - accur - ETA: 11s - loss: 0.359 - ETA - ETA: 5s - loss: 0.3606 - accuracy:  - ETA: 4s - loss: - ETA: 3s - loss: 0.3609  -\n",
      "Epoch 00006: val_accuracy improved from 0.87680 to 0.88080, saving model to my_best_model.epoch06-accuracy0.88.hdf5\n",
      "781/781 [==============================] - 57s 72ms/step - loss: 0.3594 - accuracy: 0.9139 - val_loss: 0.5079 - val_accuracy: 0.8808\n",
      "Epoch 7/100\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.3591 - accuracy: 0.9132 - ETA: 50s - loss: 0.3775 - accu  - ETA: 4 - ETA: 44s - loss: 0.3580 - accur - ETA: 43s - loss: 0.3597 - accuracy: 0.916 - ETA: 43s - loss: 0.3593 - accuracy:  - ETA: 43s - loss: 0.3577 - accuracy: 0 - ETA: 42s - loss: 0.3585 - accur - ETA: 42s - los - ETA: 37s - loss: 0.3553 - ac - ETA: 36s - loss: 0.3547 - accur - ETA: 35s - loss: 0.3543 - accuracy: - ETA: 35s - loss: 0.3535 - a - ETA: 34s -  - ETA: 32s - ETA: 30s - loss: 0.3573 - accuracy: - ETA: 29s - loss: 0.3580 - - ETA: 28s - loss: 0.3581 - accuracy: 0.91 - ETA: 28s  - ETA: 23s - loss: 0.3582 - accuracy: 0. - ETA: 22 - ETA: 20s - loss: 0.3572 - accuracy: 0.9 - ETA: 20s - loss: - ETA: 18s - lo - ETA: 16s - loss: 0.3567 - accurac - ETA: 1 - ETA: 13s - loss: 0.3580 - accuracy: 0.91 - ETA: 13s - loss: 0.3578 - accuracy: 0.9 - ETA: 13s - loss: 0.3580 - accur - ETA: 12s - loss: 0.3584 -  - ETA: 11s - loss: 0.3583 - accuracy: 0 - ETA: 11s - loss: 0.3581 - accuracy: 0. - ETA: 11s - loss: 0.3581 - ac - ETA: 10s - loss - - ETA: 6s - loss: 0.3585  - ETA: 1s - - ETA: 0s - loss: 0.3590 - accuracy: 0. - ETA: 0s - loss: 0.3591 - accuracy: \n",
      "Epoch 00007: val_accuracy improved from 0.88080 to 0.88120, saving model to my_best_model.epoch07-accuracy0.88.hdf5\n",
      "781/781 [==============================] - 56s 72ms/step - loss: 0.3591 - accuracy: 0.9132 - val_loss: 0.4797 - val_accuracy: 0.8812\n",
      "Epoch 8/100\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.3538 - accuracy: 0.9142 - ETA: 49s - loss: 0.3471 - accuracy: 0.9 - ETA: 49s - loss: 0.3437 - accuracy: - ETA: 48s - loss: 0.3379 - accu - ETA: 47s - loss: 0.3354 - accu - ETA: 46s - loss: 0.3380 - accuracy:  - ETA: 46s - loss: 0.3397 - ac - ETA: 45s - loss: 0.3401 - accuracy:  - ETA: 44s - loss: 0.3405 - ac - ETA - ETA: 41s - loss: 0.3487 - - ETA: 40s - loss: 0.3500 - accuracy: 0. - ETA: - ETA: 37s - loss: 0.3488 - accu - ETA: 34s - loss: 0.3494 - accuracy - ETA: 33s - loss: 0.3491 - accuracy: - ETA: 33s - loss: 0.3486 - accuracy: 0.91 - ETA: 33s - loss: - ETA: 31s - loss: 0.3501 - ac - ETA: 30s - loss: 0.3493 - accuracy - ETA: 29s - loss: 0.3489 - accurac - ETA: 29s - loss: 0.3492 - accuracy: 0.916 - ETA: 29s - loss: 0.3490 - accuracy: 0.91 - ETA: 29s - loss: 0.3492 - accuracy:  - ETA: 28s - loss: 0.3499 - accuracy: 0.916 - ETA: 28s - loss: 0.3497  - ETA: 27s - loss: 0.3492 - ETA: 26s - loss:  - ETA: 24s - loss: 0.3499 - accura - ETA: 23s - loss: 0.3499 - accu - ETA: 23s - loss: 0.3503 - - ETA: 22s - loss: 0. - ETA: 20s - loss: 0.3511 - accuracy: 0 - ETA: 20s - loss: 0.351 - ETA: 18s - loss: 0.3513 - ac - ETA: 17s - loss: 0.3503 - accuracy: - ETA: 11s - loss: 0.3518 - accuracy: 0.91 - ETA: 11s - loss: 0.3520 - - ETA: 10s - loss: 0.35 - ETA: 5s - loss: 0.3519 - accuracy: 0.91 - ETA: 5s - loss: 0.3519 - accuracy:  - ETA: 4s - loss: 0.3 - ETA: 4s - loss: 0.3518 - accuracy: 0. - ETA: 4s - ETA: 1s - loss: 0.3522 - accuracy: 0.91 - ETA: 1s - loss: 0.3522 - ac - ETA: 1s - loss: 0.3528 - accu - ETA: 0s - loss: 0.352\n",
      "Epoch 00008: val_accuracy did not improve from 0.88120\n",
      "781/781 [==============================] - 56s 71ms/step - loss: 0.3538 - accuracy: 0.9142 - val_loss: 0.5883 - val_accuracy: 0.8573\n",
      "Epoch 9/100\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.3563 - accuracy: 0.9137 - ETA: 49s - loss: 0.3762 - accuracy: 0.9 - ETA: 49s - loss: 0.3487 - accuracy: 0. - ETA: 48s - loss: 0.3573 - accuracy: 0. - ETA: 49s - loss: 0.3461 - accuracy: - ETA: 49s - loss: 0.3323 - accur - ETA: 48s -  - ETA: 46s - loss: 0.3601 -  - ETA: 45s - loss: 0.3576 - ac - ETA: 44s - loss: 0.3561 - accu - ETA: 43s - loss: 0.3543 - accuracy: 0.914 - ETA: 43s - loss: 0.3556 - accuracy: 0.91 - ETA: 43s - loss: 0.3546 - accu - ETA: 42s - loss: 0.3537 - accuracy:  - ETA: 42s - loss: 0.3552 - accur - ETA: 41s - loss: 0.3539 - acc - ETA: 40s - loss: - ETA: 39s - loss: 0 - ETA: 37 - ETA: 35s - loss: 0.3588 - accuracy: 0.91 - ETA: 35s - loss: 0.3585 - accuracy: - ETA: 34s - loss: 0.3591 - accuracy: - ETA: 34s - loss: 0.3583 - a - ETA: 33s - loss: 0.3583 - accuracy: 0.913 - ETA: 33s - lo - ETA: 31s - loss: - ETA: 29s - loss: 0.3583 - accuracy:  -  - ETA: 23s - loss: 0.3590 - accuracy:  - ETA: 23s - loss: 0.3592 -  - ETA: 22s - loss: 0.3582 - a - ETA: 21s - loss: 0.3578 - accuracy: 0.91 - ETA: 21s - loss: 0.3575 - accu - ETA: 20s - loss: 0.3559 - ac - ETA: 19s - lo - ETA: - ETA: 15s - loss: 0.3558 - accura - ETA: 11s - loss: 0.3562 - accuracy: - ETA: 11s - loss: - ETA: 9s - loss: 0.3557  - ETA: 9s - loss: 0.3552 - accuracy:  - ETA: 8s - loss: 0.3556 - accuracy: 0. - ETA: 8s - loss: 0.3 - ETA: 7s - loss: 0.3555 - accuracy:  - ETA: 7s - loss: 0.3552 - accu - ETA: 7s - loss: 0 - ETA: 6s - l - ETA: 5s - los - ETA: 4s - loss: 0.3560 -  - E\n",
      "Epoch 00009: val_accuracy did not improve from 0.88120\n",
      "781/781 [==============================] - 56s 71ms/step - loss: 0.3563 - accuracy: 0.9137 - val_loss: 0.5152 - val_accuracy: 0.8750\n",
      "Epoch 10/100\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.3531 - accuracy: 0.9137 - ETA: 49s - loss: 0.3246 - accuracy: 0.9 - ETA: 49s - loss: 0.32 - ETA: 49s - loss: 0.3515 - accuracy: 0 - ETA: 49s - loss: 0.3543 - accuracy: - ETA: 48s - loss: 0.3568 - acc - ETA: 47s - loss - ETA: 46s - loss: 0.3515 - accura - ETA: 45s - loss: 0.3503 - accuracy: 0. - ETA: 44s - loss: 0.3499 - accuracy: 0.91 - ETA: 44s - loss: 0.3516 - accuracy:  - ETA: 44s - loss: 0.3510 - accuracy:  - ETA: 43s - loss: 0.3501 - accuracy: 0.917 - ETA: 43s - loss: 0.3505  - ETA: 42s - loss: 0.3514 - accur - ETA: 41s - loss: 0.3514 -  - ETA: 40s - loss: 0. - ETA: 36s - loss: 0.3494 - accuracy: 0. - ETA: 35s - loss: 0.3481 - a - ETA: 34s - loss: 0.3490 - accuracy - ETA: 34s - loss: - ETA: 29s - loss: 0.3491 - accuracy: 0. - ETA: 29s - loss: 0.3489 - accura - ETA: 29s - loss: 0.3476 - accura - ETA: 28s - loss: 0.3479 - a - ETA: 27s - loss: 0.3477 - accu - ETA: 26s - loss: 0.3472 - ac - ETA: 25s - loss: 0.3474 - accuracy - ETA: 25s - loss: 0.3479 - accuracy: - ETA: 24s - loss: 0.3482 - accura - ETA: 24s - loss: 0.3497 - accuracy: 0.91 - ETA: 23s - loss: 0.3495 - accurac - ETA: 23s - loss: 0.3491 - accuracy: - ETA: 22s - loss: 0.3493 - accur - ETA: 22s - loss: 0.35 - ETA: 20s - loss: 0.3 - ETA: 19s - loss: 0.3513 - accuracy: 0.913 - ETA: 19s - loss: 0.3511 - accuracy: 0.913 - ETA: 19s - loss: 0.3512 - ETA: 17s - loss: 0.3507 - accuracy: 0.91 - ETA: 17s - loss: 0.3505 - accu - ETA: 17s - loss: 0.3506 - accuracy: 0.9 - ETA: 16s - loss - ETA: 15s - loss: 0\n",
      "Epoch 00010: val_accuracy did not improve from 0.88120\n",
      "781/781 [==============================] - 56s 72ms/step - loss: 0.3531 - accuracy: 0.9137 - val_loss: 0.6417 - val_accuracy: 0.8374\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "781/781 [==============================] - ETA: 0s - loss: 0.3465 - accuracy: 0.9151 - ETA: 51s - loss: 0.3191 - accuracy: 0.9 - ETA: 50s - loss: 0.3199 - accurac - ETA: 50s - loss: 0.33 - ETA: 48s - loss: 0.3331 - a - ETA: 47s - loss: 0.3324 - accuracy: 0 - ETA: 46s - loss: 0.3326 - accuracy: - ETA: 46s - loss: 0.3341 - accu - ETA: 45s - loss: 0.3305 - ETA: 44s - loss: 0.3342 - accuracy - ETA: 43s - loss: 0.3357 - accuracy: 0.91 - ETA: 43s - loss: 0.3362 - accuracy: 0 - ETA: 43s - lo - ETA: 41s - loss: 0.3304 - accuracy: 0.92 - ETA: 41s - loss: 0.3305 - accuracy: 0. - ETA: 41s - loss: 0.33 - ETA: 36s - loss:  - ETA: 35s - loss:  - ETA: 33s - loss: 0.3435 - accuracy: 0.9 - ETA: 33s - loss: 0.3440 - a - ETA: 26s - loss: 0.3441 - accu - ETA: 25s - loss: 0.3 - ETA: 24s - loss: 0.3440 - accura - ETA: 23s - loss: 0.3447 - accuracy: 0.9 - E - ETA: 20s - loss: 0.3448 - accuracy - ETA: 20s - loss: 0.3451 - accuracy:  - ETA: 19s - loss: 0.3453 - accuracy: 0. - ETA: 19s - loss: 0.3454 - accuracy:  - ETA: 19s - loss: 0.3448 - accuracy: 0.916 - ETA: 18s - loss: 0.3447 - accuracy: 0.9 - ETA: 18s - loss: 0.3449 - acc - ETA: 17s - loss: 0.3445 - ETA: 16s - loss: 0.3439 - accuracy: 0.91 - ETA: 16s - loss: 0.3436 - accuracy: - ETA: - ETA: 10s - loss: 0.3441 - acc - E - ETA: 7s - ETA: 5s - loss: 0.344 - ETA: 5s - loss: 0.3440 - accuracy - E - ETA: 0s - loss: 0.3465 - accuracy: 0.91 - ETA: 0s - loss: 0\n",
      "Epoch 00011: val_accuracy did not improve from 0.88120\n",
      "781/781 [==============================] - 56s 72ms/step - loss: 0.3465 - accuracy: 0.9151 - val_loss: 0.4966 - val_accuracy: 0.8766\n",
      "Epoch 12/100\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.3471 - accuracy: 0.91708- ETA: 49s - loss: 0.3367 - accuracy: 0. - ETA: 50s - ETA: 48s - l - ETA: 43s - loss: 0.3392 - accuracy: 0 - ETA: 42s - loss: 0.3373  - ETA: 41s - loss: 0.3368 - accu - ETA: 41s - loss: 0.3372 - accuracy: 0.922 - ETA: 41s - loss: 0.3380 - accurac - ETA: 40s - loss: 0.3385 - accuracy: 0. - ETA: 40s - loss: 0.3383 - ac - ETA: 39s - loss: 0.3415 - accuracy:  - ETA: 38s - lo - ETA: 36s - ETA: 34s - loss: 0.3438 - ETA: 33s - loss: 0.3459 - accuracy:  - ETA: 32s - loss: 0.3458 - accuracy - ETA: 32s - loss: 0.3473 - accuracy:  - ETA: 26s - loss: 0.3474 - accuracy: 0.9 - ETA: 26s - loss: 0.3474 - accura - ETA: 25s - loss: 0.3479 - accuracy: 0.9 - ETA: 25s - loss: 0.3476 - acc - ETA: 24 - ETA: 22s - loss: 0.3474 - accuracy: - ETA: 21s - loss: 0.3476 -  - ETA: 20s - loss: 0.34 - ETA: 19s - loss: 0 - ETA: 17s - loss: 0.3483 - accuracy: - ETA: 17s - loss: 0.3480 - accuracy - ETA: 16s - loss: 0.3480 - accuracy - ETA: 16s - loss: 0.3481 - accur - ETA: 15s -  - ETA: 13s - loss: 0.3475 - accura - ETA: 12s - loss: 0.3475 - accuracy - ETA: 3s - loss: 0.346 - ETA: 3s - loss: - ETA: 2s - loss: 0.3471 - ac - ETA: 0s - loss: 0.3470 - accuracy\n",
      "Epoch 00012: val_accuracy did not improve from 0.88120\n",
      "781/781 [==============================] - 56s 72ms/step - loss: 0.3471 - accuracy: 0.9170 - val_loss: 0.5735 - val_accuracy: 0.8603\n",
      "Epoch 13/100\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.3488 - accuracy: 0.9143  - ETA: 48s - loss - ETA: 49s - loss: 0.3558 - ac - ETA: 47s - ETA: 45s - loss: 0.3528 - accurac - ETA: 42s - loss: 0.3438 -  - ETA: 35s - loss: 0.3447 - accu - ETA: 34s - loss: 0.3447 - acc - ETA: 33s - loss: 0.3449 - accuracy - ETA: 33s - loss: 0.3458 - ac - ET - ETA: 29s - loss: 0.3487 - accuracy: 0. - ETA: 29s - loss: 0.3492 - accur - E - ETA:  - ETA: 23s - loss: 0.3492 - accuracy: 0 - - ETA: 20s - loss: 0.3503 - acc - ETA: 19s - loss: 0.3494 - ac - ETA: 18s - loss: 0.3494 - accuracy: 0.9 - ETA: 18s - loss: 0.3496 - accuracy: 0.914 - ETA: 18s - los - ETA: 16s - loss: 0.3494 - accurac - ETA: 16s - loss: 0.3493 - accuracy - ETA: 15s - loss: 0.3486 - accuracy: 0.9 - ETA: 15s - loss: 0.3486 - accuracy: 0. - ETA: 15s - loss: 0.3485 - - ETA: 14s - loss: 0.3488 - accuracy - ETA: 13s - loss: 0.3493 - accuracy - ETA: 13s - loss: 0.3489 - accuracy: 0 - ETA: 12s - los - ETA: 10s - loss: 0.3485 - accuracy: 0. - ETA - ETA: 8s - loss: 0.3490 - accuracy: 0.91 - ETA: 8s - loss: 0.349 - ETA: 8s - loss: 0.3498 - accura - ETA:  - ETA: 6s - loss: 0.3497 - ac - ETA: 6s - loss: 0.3496 - accuracy: 0.91 - ETA: 4s - loss: 0.3491 - accuracy - ETA: 4s - loss: 0.3492 - accura - ETA: 4s - loss: 0.3493 - accuracy: 0. - ETA: 4s - loss: 0.3491 - accuracy: 0.91 - ETA: 4s - loss: 0.3491 - accuracy: 0. - ETA: 3s - loss: 0.3490 - accura - ETA: 3s - loss: 0.3492 - accuracy: 0. - ETA: 3s - ETA: 0s - loss: 0.3484 - accuracy: 0.91 - ETA: 0s - loss: 0 - ETA: 0s - loss: 0.3491 - accuracy: 0.9142\n",
      "Epoch 00013: val_accuracy did not improve from 0.88120\n",
      "781/781 [==============================] - 56s 72ms/step - loss: 0.3491 - accuracy: 0.9142 - val_loss: 0.4997 - val_accuracy: 0.8804\n",
      "Epoch 14/100\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.3489 - accuracy: 0.9166 - ETA: 45s - loss: 0.3429 -  - ETA: 29s - loss: 0.3429 - ETA: 28s - loss: 0.3410 - accur - ETA: 27s - loss - ETA: 25s - loss: 0 - ETA: 24s - - ETA: 22s - loss: 0.3410 - accurac - ETA: 21s - loss: 0.3406 - accuracy: 0.9 - ETA: 21s - loss: 0.3409 - accuracy - ETA: 20s - loss: 0.3415 - accuracy:  - ETA: 20s - loss: 0.3415 - accur - ETA: 19s - loss: 0.3422  - ETA: 18s - loss: 0.3428 - accurac - ETA: 17s - loss: 0.3434 - accuracy: - ETA: 17s - loss: 0.3437 - accur - ETA: 16s - loss: 0.3444 - acc - ETA: 15s - loss: 0.3439 - accuracy: - ETA: 15s - loss: 0.3442 - accuracy:  - ET - ETA: 12s - loss - ETA: 1 - ETA: 9s - loss: 0.3469 - accura - ETA: 8s - loss: 0.3471 - accuracy - ETA: 8s - loss: 0.3 - ETA: 7s - loss: 0.3473 - accu - ETA:  - ETA: 6s - los - ETA: 3s - loss: 0 - ETA: 2s - loss: - ETA: 0s - loss: 0.3488 - accuracy:  - ETA: 0s - loss: 0.3488 - accuracy: 0.91 - ETA: 0s - loss: 0.3488 - accuracy:  - ETA: 0s - loss: 0.3490 - accuracy: \n",
      "Epoch 00014: val_accuracy did not improve from 0.88120\n",
      "781/781 [==============================] - 56s 72ms/step - loss: 0.3489 - accuracy: 0.9166 - val_loss: 0.5744 - val_accuracy: 0.8551\n",
      "Epoch 15/100\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.3410 - accuracy: 0.91530- ETA: 49s - loss: 0.3355 - accurac - ETA: 49s - loss: 0.3320 - accuracy: 0.9 - ETA: 4 - ETA: 46s - ETA: 41s - loss: 0.3339 - - ETA: 40s - loss: 0.3339 - accuracy: - ETA: 39s - loss: 0.3334 - - ETA: 38s - loss: 0. - ETA: 37s - loss: 0.3340 - accur - ETA: 36s - loss: 0.3347 - accuracy: 0. - ETA: 36s - loss: 0.3356  - ETA: 35s - loss: 0.3387 - accuracy: 0.917 - ETA: 34s - loss: 0.3382 -  - ETA: 33s  - ETA: 31s - loss: 0.3422 - accuracy: 0. - ETA: 31s - loss: 0.3415 - accuracy: 0.9 - ETA: 31s - loss: 0.3411 - - ETA: 30s - loss: 0.340 - ETA: 28s - loss: 0.3420 - accurac - ETA: 28s - loss: 0.3416 - accurac - ETA: 27s - loss: 0.3403 - accuracy: 0 - ETA: 27s - loss: 0.3   - ETA: 20s - loss: 0.3365 - accura - ETA: 19s - loss: 0.3368 - accurac - ETA: 19s - loss: 0.3371 - accurac - ETA: 18s - loss: 0.3368 - accurac - ETA: 17s - loss: 0.3368 - accuracy: 0. - ETA: 17s - loss: 0.3365 - acc - ETA: 16s - loss: 0.3368 - accura - ETA: 16s - loss: 0.3373 - accuracy:  - ETA: 15s - loss: 0.33 - ETA: 14s - loss: 0.3 - ETA: 12s - loss: 0.3376 - accu - ETA: 12s - loss: 0. - ETA: 10s - loss: 0.3373 - accurac - ETA: 9s - loss - ETA: 9s - loss: 0.3383 - accuracy: 0.91 - ETA: 8s - loss: 0.3383 - accuracy: 0. - ETA: 8s - loss: 0.3382  - ETA: 8s - loss: 0.3383 - accuracy: 0.91 - ETA: 8s - loss: 0.3382 - accu - ETA: 3s - loss: 0.3400 - accuracy: 0.91 - ETA: 3s - loss: - ETA: 2s - loss: 0.3404  - ETA:  - ETA: 0s - loss: 0\n",
      "Epoch 00015: val_accuracy did not improve from 0.88120\n",
      "781/781 [==============================] - 56s 71ms/step - loss: 0.3410 - accuracy: 0.9153 - val_loss: 0.5195 - val_accuracy: 0.8710\n",
      "Epoch 16/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "781/781 [==============================] - ETA: 0s - loss: 0.3363 - accuracy: 0.91915- ETA: 46s - loss: 0.3007 - accuracy:  - ETA: 46s - loss: 0.3025 - accuracy: 0.933 - ETA: 46s - loss: 0.3033 - accuracy:  - ETA: 46s - loss: 0.3028 - accuracy: 0 - ETA: 46s - loss: 0.3070 - ETA: 45s - loss: 0.3098 - a - ETA: 44s -  - ETA: 42s - loss: 0.3139 - accuracy: 0. - ETA: 41s - loss: 0.3122 - accuracy: 0.9 - ETA: 41s - loss: 0.3140 - accura - ETA: 40s - l - ETA: 36s - loss: 0.3205 - accuracy: 0. - ETA: 35s - loss: 0.3212 - accuracy: 0.924 - ETA: 35s - loss: 0.3212 - accuracy: - ETA: 35s - loss: 0.3213 - ac - ETA: 34s - loss: 0.3258 - accuracy: - ETA: 33s - loss: 0.3254 - accuracy: 0.922 - ETA: 33s - loss: 0.3257 - accuracy: 0.9 - ETA: 33s - loss: 0.325 - ETA: 32s - loss: 0.3273 - accuracy: 0.9 - ETA: 32s - loss: 0.3276 - accuracy: 0. - ETA: 32s - loss: 0.3273 - accuracy: 0 - ETA: 31s -  - ETA: 29s - loss: 0.3 - ETA: 28s - loss: 0.3291 -  - ETA: 27s - loss: 0.3292 - accuracy: 0.9 - ETA: 27s - loss: 0.3291 - accuracy: 0.921 - ETA: 26s - loss: 0.3292  - ETA: 25s - loss: 0 - ETA: 24s - loss: 0.3304 - accuracy: 0. - ETA: 23s - loss: 0.3304 - - ETA: 22s - loss: 0.3312  - ETA: 21s - loss: 0.3312 - accuracy: 0.9 - ETA: 21s - loss: 0.3317 -  - ETA: 20s - loss: 0.3322 - accur - ETA: 19s - - ETA: 14s - loss - ETA: 1 - ETA: 10s - loss: 0.3316 - accuracy:  - ETA: 10s - loss: 0.3324 - accuracy: 0.9 - ETA: 9s - loss - ETA: 9s - loss: 0.3330  - ETA: 6s - loss: 0.3341 - ac - ETA: 2s - loss: 0.3367 - accuracy:  - ETA: 1s - loss: 0.3367 -  - ETA: 1s - loss: 0.3369 - accuracy - ETA: 1s - loss: 0.3369  - ETA: 0s - loss: 0.3369 \n",
      "Epoch 00016: val_accuracy did not improve from 0.88120\n",
      "781/781 [==============================] - 56s 72ms/step - loss: 0.3363 - accuracy: 0.9191 - val_loss: 0.5310 - val_accuracy: 0.8694\n",
      "Epoch 17/100\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.3386 - accuracy: 0.9187 - ETA: 47s - loss: 0.3325 - accuracy: - ETA: 47s - loss: 0.3332 - accu - ETA: 47s - loss: 0.3 - ETA: 45s - l - ETA: 43s - loss: 0.3371 - accuracy: 0.921 - ETA: 43s - loss: 0.3371 - accuracy: 0.92 - ETA: 43s - loss: 0.3373 - accu - ETA: 42s - loss: 0.3349 - acc - ETA: 41s - loss: 0.3365 - ac - ETA: 40s - loss: 0.3375 - accuracy: 0.9 - ETA: 40s - loss: 0.3357 - accurac - ETA: 37s - loss: 0.3385 -  - ETA: 36s - loss: 0.3361 - ac - ETA: 35s - loss: 0.3371 -  - ETA: 31s - loss: 0.3353 - ac - ETA: 30s - loss: 0.3362 - accura - ETA: 29s - loss: 0.3363 - accuracy: - ETA: 29s - loss: 0.3363 - - ETA: 28s - loss: 0.3357 - accurac - ETA: 27s - los - ETA: 25s - loss: 0.3361 - accuracy: 0.92 - ETA: 25s - lo - ETA: 23s - loss: 0.3354 - accuracy: - ETA: 23s - loss: 0.3353 - accuracy: 0.9 - ETA: 22s - loss: 0.3352 - accuracy:  - ETA: 22s - loss: 0.3352 - accuracy: - ETA: 22s - loss: - ETA: 14s - loss: 0.3354 - acc - ETA: 13s - loss: 0.3369 - accuracy: 0. - ETA: 13s - los - ETA: 11s - loss: 0.3367 - ac - ETA - ETA: 8s - loss: 0.3366  - ETA: 5s - loss: 0.3365 - accuracy:  - ETA: 5s - loss: 0.3370 - accura - ETA: 4s - los - ETA: 4s - loss: 0.3379 - accura - ETA: 3s - loss: 0.3382 -  - ETA: 3s - loss: 0.3384 - accuracy: 0. - ETA: 3s - loss: - ETA: 2s - loss: 0 -\n",
      "Epoch 00017: val_accuracy did not improve from 0.88120\n",
      "781/781 [==============================] - 56s 72ms/step - loss: 0.3386 - accuracy: 0.9187 - val_loss: 0.5128 - val_accuracy: 0.8783\n",
      "Epoch 18/100\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.3396 - accuracy: 0.9175 - ETA: 49s - lo - ETA: 47s - loss: 0.3380 - accuracy: 0. - ETA: 47s - loss: 0.3378 - accuracy: 0.9 - ETA: 47s - loss: 0.3375 - accura - ETA: 46s - loss: 0.3452  - ETA: 45s  - ETA: 43s - loss: 0.3282 - acc - ETA: 42s - loss: 0.3237 - accuracy: 0.926 - ETA: 42s - loss: 0.3242 - accurac - E - ETA: 39s - loss: 0.3291 - ETA: 35s - loss: 0.3314 - accuracy: 0.92 - ETA: 35s - loss: 0.3310 - accuracy:  - ETA: 34s - loss: 0.3326 - ac - ETA: 34s - loss: 0.3322 - ac - ETA: 33s - loss: 0 - ETA: 31s - loss: 0.3340 - accuracy: 0. - ETA: - ETA: 28s - loss: 0.3358 - ETA: 27s - loss: 0 - ETA: 26s - loss: 0.3358 - - ETA: 24s - loss: - ETA: 20s - loss: 0.3362 - accu - ETA: 19s - loss: 0.3360 - acc - ETA: 18s - loss: 0.3362 - accuracy:  - ETA: 18s - loss: 0.3360 - ETA: 16s - loss: 0.3359 - accuracy: 0.9 - ETA: 16s - loss: 0. - ETA: 15s - loss: 0.3354 - accura - ETA: 14s - loss: 0.3362 - accurac - ETA: 14s - loss: 0.3357 - accuracy: 0 - ETA: 13s - loss: 0.3364 - accuracy: 0.919 - ETA: 13s - loss: 0.3 - ETA: 12s - los - ETA: - ETA: 8s - loss: 0.3381 - accuracy: 0.91 - ETA: 8s - loss: 0.3383 - accuracy: 0.91 - ETA: 3s - loss: 0.3398 - accu - ETA: 2s - loss: 0.3400 - accu - ETA: 2s - los - ETA: 1s - los - ETA: 0s - loss: 0.3398 - accu\n",
      "Epoch 00018: val_accuracy did not improve from 0.88120\n",
      "781/781 [==============================] - 56s 72ms/step - loss: 0.3396 - accuracy: 0.9175 - val_loss: 0.5214 - val_accuracy: 0.8665\n",
      "Epoch 19/100\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.3370 - accuracy: 0.9180 - ETA: 47s - ETA: 45s - loss: 0.3263 - accuracy: 0.92 - ETA: 45s - loss: 0.3295 - accuracy: 0. - ETA: 45s - loss - ETA: 43s - loss: 0.3245 - acc - ETA: 42s - loss: 0.3245 - accuracy: 0.92 - ETA: 42s - loss: 0.3239 - - ETA: 41s - loss: 0.3223 - accu - ETA: 40s - loss: 0.3258 - accuracy: 0 - ETA: 40s - loss: 0.3250 - ac - ETA: 39s - loss: 0.3242 - accuracy - ETA: 39s - loss: 0.3223 - accuracy: 0.9 - ETA: 3 - ETA: 36s - loss: 0. - ETA: 29s - loss: 0.3309 - accu - ETA: 28s - loss: 0.3297 - ETA: 21s - loss: 0.3324 - accuracy: 0. - ETA: 20s - loss: 0.3327 - accuracy: 0 - ETA: 20s - loss: 0.33 - ETA: 19s - loss: 0.3327 - accuracy: 0.91 - ETA: 19s - loss: 0.3328 - acc - ETA: 18s - - ETA: 16s - loss: 0. - ETA: 14s - loss: 0.3337 - accuracy: 0 - ETA: 14s - loss: 0.333 - ETA: 13s - loss: 0.3344 - accur - ETA: 12s - - ETA: 10s - loss: 0.3353 - acc - ETA: 9s - loss: 0.3355 - accuracy: 0.91 - ETA: 9s - - ETA: 4s - loss: 0.3374 - accuracy:  - ETA: 4s - loss: 0.3377 - accuracy - ETA:  - ETA: 2s - loss: 0.3 - ETA: 1s - l - ETA: 0s - loss: 0.3374 - accuracy: 0.91 - ETA: 0s - loss: 0.3374 - accuracy: 0. - ETA: 0s - loss: 0.3\n",
      "Epoch 00019: val_accuracy did not improve from 0.88120\n",
      "781/781 [==============================] - 55s 71ms/step - loss: 0.3370 - accuracy: 0.9180 - val_loss: 0.6476 - val_accuracy: 0.8369\n",
      "Epoch 20/100\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.3362 - accuracy: 0.9166 - ETA: 48s - loss: 0.3080 - accuracy: 0 - ET - ETA: 46s - loss: 0.3092 - accu - ETA: 45s - loss: 0.3137 - accuracy:  - ETA: 45s - loss: 0.3121 - accuracy: 0. - ETA: 45s - loss: 0.3113  - ETA: 44s - l - ETA: 42s - loss: 0.3192 - accuracy: 0.922 - ETA: 42s - loss: 0.3 - ET - ETA: 38s - loss: 0.3220 - ac - ETA: 37s - loss: 0.3220 - ac - ETA: 36s - loss: 0.3232 - accuracy: 0.921 - ETA: 36s - loss: 0.32 - ETA: 35s - loss: 0.3230 - accuracy: 0.9 - ETA: 35s - loss: 0.3223 - accuracy: - ETA: 34s - lo - ETA: 32s - loss: 0.3244 - accuracy:  - ET - ETA: 29s - loss: 0.328 - ETA: 28s - loss: 0.3286 - accuracy: 0.91 - ETA: 28s - loss: 0.3 - ETA: 26 - - ETA: 18s - loss: 0.3321 - accuracy - ETA: 18s - loss: 0.3320 - accuracy: 0 - ETA: 18s - loss: 0.3318 - - ETA: 13s - loss: 0.3336 - accuracy: 0. - ETA: - ETA: 7s - loss: 0.3346 - accuracy:  - ETA: 7s - loss: 0.3346 - accu - ETA: 7s - l - ETA: 0s - loss: 0.3363 - accuracy - ETA: 0s - loss: 0.3362 - accuracy: 0.91\n",
      "Epoch 00020: val_accuracy did not improve from 0.88120\n",
      "781/781 [==============================] - 56s 72ms/step - loss: 0.3362 - accuracy: 0.9166 - val_loss: 0.6534 - val_accuracy: 0.8409\n",
      "Epoch 21/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "781/781 [==============================] - ETA: 0s - loss: 0.3369 - accuracy: 0.9183 - ETA: 51s - loss: 0.3138 - accuracy: 0 - ETA: 51s - los - ETA: 48s - loss: 0.3153 - ac - ETA: 47s - loss: 0.3165 - accuracy: 0.92  - ETA: 44s - loss - ETA: 42s - loss: 0.3223 - ETA: 38s - loss: 0.3227 - accurac - ETA: 37s - loss: 0.32 - ETA: 36s - loss: 0.3238 - ac - ETA: 35s - loss: 0.3245 - accuracy: 0 - ETA: 35s - loss - ETA: 33s - loss:  - ETA: 28s - loss: 0.3288 -  - ETA: 27s - loss: 0.3310 - acc - ETA: 26s - loss: 0.3306 -  - ETA: 25s - loss: 0.3311 - accuracy - ETA: 25s - loss: - ETA: 23s - loss: 0.3338 - accuracy: 0 - ETA: 23s - loss: 0.3343 - ac - ETA: 22s - loss: 0.3349 - accuracy: - ETA: 21s - loss: 0.3357 - accuracy: 0. - ETA: 21s - loss: 0.3354 - accuracy: - ETA: - ETA: 12s - loss: 0.3350 - accurac - ETA: 12s - loss:  - ETA: 0s - loss: 0.3370 - accura\n",
      "Epoch 00021: val_accuracy did not improve from 0.88120\n",
      "781/781 [==============================] - 55s 71ms/step - loss: 0.3369 - accuracy: 0.9183 - val_loss: 0.5763 - val_accuracy: 0.8615\n",
      "Epoch 22/100\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.3378 - accuracy: 0.9168 - ETA: 46s - l - ETA: 43s - loss: 0.33 - ETA: 42s - loss: 0.3314 - accuracy: 0. - ETA: 42s - l - ETA: 40s - loss: 0 - ETA: 38s - loss: 0.3305 - accuracy: 0.9 - ETA: 38s - loss: 0.3299 - accuracy: - ETA: 37s - loss: 0.3299 - accuracy: 0 - ETA: 37s - l - ETA: 35s - loss: 0.3282 - accu - ETA: 34s - loss: 0.3283 - accuracy: 0.9 - ETA:  - ETA: 32s - loss - ETA: 30s - loss: 0.3307 - accuracy: 0. - ETA: - ETA: 27s - loss: 0.3302 - accurac - ETA: 27s - loss: 0.3323 - accuracy: 0.919 - ETA: 27s - loss: 0.3324 - accur - ETA: 26s - loss: 0.3324 -  - ETA: 25s -  - ETA: 23s - loss: 0.3321 - accuracy: 0.9 - ETA: 22s - loss: 0 - ETA: 18s - loss: 0.3 - ETA: 17s - loss: 0.3333 - ETA: 15s -  - ETA: 13s - loss: 0.3356 - - ETA: 12s - loss: 0.3366 - a - ETA: 11s - loss: 0.3362 - accuracy - ETA: 11s  - ETA: 7s - loss: 0.3375 - ac - E - - ETA - ETA: 0s - loss: 0.3375 - accuracy: 0.91 - ETA: 0s - loss: 0.337\n",
      "Epoch 00022: val_accuracy did not improve from 0.88120\n",
      "781/781 [==============================] - 56s 71ms/step - loss: 0.3378 - accuracy: 0.9168 - val_loss: 0.5278 - val_accuracy: 0.8672\n",
      "Epoch 23/100\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.3345 - accuracy: 0.9186 - ETA: 46s - loss: 0.3298 - accu - ETA: 45s - loss: 0.3282 - ac - ETA: 36s - loss: 0.3232 - accuracy: 0.922 - ETA: 36s - loss: 0.32 - ETA: 34s - loss: 0.3253 -  - ETA: 33s - loss: 0.3237 - a - ETA: 32s - loss: 0.3269 - accuracy:  - ETA: 32s - loss: 0.32 - ETA: 31s - loss: 0. - ETA: 29s - loss: 0.3294  - ETA: 28s - loss: 0.3288 - accuracy: 0.9 - ETA: 28s - loss: 0.3290 - accuracy: - ETA: 27s - loss: 0.330 - ETA: 26s - loss: 0.3306 - acc - ETA: 25s - loss: 0.3296 - accura - ETA: 25s - loss: 0.328 - ETA: 23s - loss - ETA: 22s - loss: 0.3314 -  - ETA: 20s - loss: 0.3323 - accura - ETA: 20s - loss: 0.3332 - accuracy: 0.920 - ETA: 20s - loss - ETA: 18s - loss: 0.3327 - accurac - ETA: 17s - loss: \n",
      "Epoch 00023: val_accuracy did not improve from 0.88120\n",
      "781/781 [==============================] - 56s 71ms/step - loss: 0.3345 - accuracy: 0.9186 - val_loss: 0.5042 - val_accuracy: 0.8761\n",
      "Epoch 24/100\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.3277 - accuracy: 0.9211 - ETA: 48s - loss: 0.3305 - accuracy: 0 - ETA: 48s - loss: 0.3497 - accuracy:  - ETA: 48s - loss: 0.3497 - accurac - ETA: 47s - loss: 0.3346 - accuracy - ETA: 47s - loss: 0.3323 - ETA: 46s - loss: 0.3249 - accuracy: 0.92 - ETA: 46s - loss: 0.325 - ETA: 45s - loss: 0.319 - ETA: 44s - loss: 0.3214 - accuracy: 0.9 - ETA: 44s - loss: 0.3240 - accuracy: 0.926 - ETA: 44s - loss: 0.3240 - accuracy - ETA: 43s - loss: 0.3197 - accuracy: 0 - ETA: 43s - loss: 0.3197 - acc - ETA: 39s - loss: 0.3260 - accu - ETA: 38s - loss: 0.3 - ETA: 37s - loss: 0. - ETA: 35s - loss: 0 - ETA: 33s - loss: 0.3259 - accuracy - ETA: 33s - loss: 0.3257 - accuracy: 0.9 - ETA: 33s - loss: 0 - ETA: 31s - loss: 0.3267 - accuracy: 0. - ETA: 31s - loss: 0.3260 - accuracy: 0 - ETA: 31s  - ETA: 28s -  - ETA: 26s - loss:  - ETA: 25s - loss: 0.3234 - acc - ETA: 24s - loss: 0.3240 - accuracy: 0.922 - ETA: 24s - loss: 0.3239 - accuracy: 0.9 - ETA: 24s - lo - ETA: 22 - ETA: 19s - loss: 0.3247 - accuracy: 0.9 - ETA: 19s - loss: 0.3252 - accuracy: 0.92 - - ETA: 16s - loss: 0.3257 - a - ETA: 15s - ETA: 13s - loss: 0.3264 - accuracy: 0.9 - ETA: 13s - loss: 0.3263 - accuracy: 0.921 - ETA: 13s - loss: 0.3263 - accuracy: 0. - ETA: 12s - loss - ETA: 11s - loss: 0.3 - ETA: 8s - loss: 0.3267 - ac - ETA: 7s - loss: 0.3269 - accura - ETA: 7s - loss: 0.3264 - accu - ETA: 5s - loss: 0.3259 - accuracy: 0. - ETA: 5s - l - ETA: 4s - loss: 0.3272 - accuracy: 0. - - ETA: 3s - loss: 0.3269  - ETA: 2s - loss: 0.3270 - accuracy: 0.92 - ETA: 2s - - ETA: 1s - loss: 0.3 - ETA: 0s - loss: 0.3279 \n",
      "Epoch 00024: val_accuracy did not improve from 0.88120\n",
      "781/781 [==============================] - 56s 72ms/step - loss: 0.3277 - accuracy: 0.9211 - val_loss: 0.5567 - val_accuracy: 0.8664\n",
      "Epoch 25/100\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.3280 - accuracy: 0.9198 - ETA: 48s - loss: 0.3177 - accuracy: 0.922 - ETA: 48s - los - ETA: 48s - loss: 0 - ETA: 46s - loss - ETA: 44s - loss: 0.3323 - accuracy: 0. - ETA: 44s - loss: 0.33 - ETA: 43s - loss: 0.3336 - accuracy:  - ETA: 42s - loss: 0.3341 - accuracy: - ETA: 42s - loss: 0.3353 - accu - ETA: 41s - loss: 0.3360 - accur - ETA: 40s - loss: - ETA: 39s - loss: 0.3325 - acc - ETA: 38s - loss: 0.3322 - accuracy: 0. - ETA: 37s - loss: 0.3313 - accuracy: - ETA: 37s - loss: - ETA: 35s - loss: 0.33 - ETA: 34s - loss: 0.3309 -  - ETA: 33s - ETA: 25s - loss: 0.3279 - accuracy: 0.91 - ETA: 24s - loss: 0.3280 - accu - ETA: 24s - loss: 0.3276 - ETA: 22s - loss: 0 - ETA: 21s - loss: 0.3272 - a - ETA: 11s - loss: 0.3271 - accuracy: 0.92 - ETA: 11s - - ETA: 9s - loss: 0.3276 -  - ETA: 9s - l - ETA: 8s - loss: 0.3284 - accuracy - ETA: 7s - loss: 0.3 - ETA: 7s - loss: 0.3279 - ac - ETA: 6s - loss: 0.3273  - ETA: 6s - loss: 0.327 - ETA: 5s - ETA: 1s - loss: 0 - ETA: 0s - loss: 0.3278 \n",
      "Epoch 00025: val_accuracy did not improve from 0.88120\n",
      "781/781 [==============================] - 56s 72ms/step - loss: 0.3280 - accuracy: 0.9198 - val_loss: 0.5350 - val_accuracy: 0.8694\n",
      "Epoch 26/100\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.3291 - accuracy: 0.9195 - ETA: 49s - ETA: 47s - loss: 0.3205 - accuracy: 0. - ETA: 47s - loss: 0.320 - ETA:  - ETA: 43s - loss: 0.3206 - accuracy: 0.91 - ETA: 43s - loss: 0.3216 - accuracy: - ETA: 42s - lo - ETA: 40s - loss: 0.3204 - accuracy: - ETA: 40s - loss: 0.3211 -  - ETA: 39s - loss: 0 - ETA: 37s - loss: 0.3256 - acc - ETA: 36s - loss: 0.3263 - accuracy: 0. - ETA: 36s - loss: 0.3263 - accuracy:  - ETA: 36s - loss: 0.3255 - accu - ETA: 35s - loss: 0.3244 - accuracy: 0. - ETA: 35s - loss: 0.3237 - - ETA:  - ETA: 31s - loss: 0.3237 - accuracy: 0.920 - ETA: 31s - loss: 0.3237 - accuracy:  - ETA: 31s - loss: 0.3249 - ac - ETA: 30s - loss - ETA: 28s - loss: 0.3255 - accurac - ETA: 27s - loss: 0.3263 - accuracy: 0.9 - ETA: 27s - loss: 0.3263 - ac - ETA: 26s - loss: 0.3288 - accuracy: 0.91 - ETA: 26s - loss: 0.3287 - accura - ETA: 25s - loss: 0.3279 - accuracy: - ETA: 25s - loss: 0.32 - ETA: 24s - loss: 0.3273 -  - ETA: 23s - loss: 0 - ETA: 21s - loss: - ETA: 19s - loss: 0.3259 - accuracy: 0 - ETA: 19s - loss: 0.3261 - accuracy: 0.9 - ETA: 19s - loss: 0.3259 - accuracy - ETA: 18s - loss: 0.3259 - - ETA: 17s -  - ETA: 15s - loss: 0.32 - ETA: 14s - loss: 0.326 - ETA: 12s - loss: - ETA: - ETA:  - ETA - ETA: 6s - loss: - ETA: 1s - loss: 0 - ETA: 0s - loss: 0.3289 - accuracy - ETA: 0s - loss: 0.3\n",
      "Epoch 00026: val_accuracy did not improve from 0.88120\n",
      "781/781 [==============================] - 56s 71ms/step - loss: 0.3291 - accuracy: 0.9195 - val_loss: 0.5759 - val_accuracy: 0.8646\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "781/781 [==============================] - ETA: 0s - loss: 0.3306 - accuracy: 0.9192 - ETA: 48s - loss: 0.3 - ETA: 47s - loss: 0.3139 - accuracy: 0.92 - ETA: 47s - loss: 0.3194 - accuracy: 0.9 - ETA: 47s - loss: 0.3177 - accuracy: 0.9 - ETA: 46s - ETA: 44s - loss: 0.3160 - accu - ETA: 43s - loss: 0.3183 - accuracy: 0 - ETA: 43s - loss: 0.3195 - accuracy: 0.920 - ETA: 43s - loss: 0.3210 - accuracy: 0 - ETA: 43s - loss: 0.3194 - accu - ETA: 42s - loss: 0.31 - ETA: - ETA: 39s - lo - ETA: 37s - loss: 0.3223 -  - ETA: 35s - loss: 0.3218 - accuracy: - ETA: 3 - ETA: 33s - loss: 0.3225 - accuracy: 0.9 - ETA: 32s - loss: 0.3228 - accuracy: 0. - ETA: 32s - loss: 0.3226 - accura - ETA: 31s - loss: 0.3240 - accuracy: 0. - ETA:  - ETA: 29s - loss: 0 - ETA: 27s - loss: 0.3254 - accuracy:  - ETA: 27s - loss: 0.3261 - - ETA: 26s - loss: 0. - ETA: 24s - loss: 0.3256 - accuracy: 0. - ETA: 24s - loss: 0.3253 - accuracy: 0 - ETA: 24s - loss: 0.3264 - accuracy: - ETA: 23 - ETA: 21s - loss: 0.3287 - accuracy: 0.9 - ETA: 21s - - ETA: 19s - loss: 0.3288 - accuracy: 0.9 - ETA: 18s - loss: 0.3289 - - ETA: 17s - loss: 0.3291 - ac - ETA: 16s - loss: 0.3291  - ETA: 15s - loss: 0.3291 - accur - ETA: 14s - loss: 0.3291 - accuracy: 0.91 - ETA: 14s - loss: 0.3291 - accuracy: 0.9 - ETA: 14s - loss: 0.3289 - acc - ETA: 13s - loss: 0.3293 - accuracy: 0.91 - ETA: 13s - loss: 0.3 - ETA: 8s - loss: 0.3310 - accuracy: 0. - ETA: 5s - l - ETA: 2s - loss: 0.3317 - accu - ETA: 2s - loss: 0.3314 - accura - ETA: 1s - loss: 0.3314 - accuracy: 0.91 - ETA:  - ETA: 0s - loss: 0.3309 - accuracy - ETA: 0s - loss: 0.3308 - ac\n",
      "Epoch 00027: val_accuracy did not improve from 0.88120\n",
      "781/781 [==============================] - 56s 71ms/step - loss: 0.3306 - accuracy: 0.9192 - val_loss: 0.5215 - val_accuracy: 0.8772\n",
      "Epoch 28/100\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.3264 - accuracy: 0.9201 - ETA: 46s - loss: 0.3252 - ETA: 47s - lo - ETA: 46s - loss: 0.3324 - accuracy:  - ETA: 46s - loss: 0.3 - ETA: 44s - loss: 0.3201 - accuracy: 0. - ETA: 44s - lo - ETA: 42s - loss: 0.3206  - ETA: 41s - loss: 0.3151 - a - ETA: 40s - loss: 0.3163 - accu - ETA: 39s - loss: 0.3175 - accuracy: 0. - ETA: 39s - loss: 0.3195 - a - ETA: 38s - loss: 0.3205 - accuracy: 0.92 - ETA: 38s - loss: 0.3206 - ETA: 36s - loss: 0.3212 - accur - ETA: 36s - loss: 0.322 - ETA: 34s - loss: 0.3233 - accura - ETA: 34s - loss: 0.3227 - - ETA: - ETA: 30s - loss: 0.3227 - accuracy - ETA: 30s - loss: 0.3232 - accurac - ETA: 29s - loss: 0.3 - ETA: 28s - loss: 0.3247 - a - ETA: 27s - loss - ETA: 25s - loss: 0.3236 - a - ETA: 24s - loss: 0.323 - ETA: 23s - los - ETA: 21s - loss: 0.32 - ETA: 17s - loss: 0.3226 - accuracy: 0.922 - ETA: 17s - loss: 0.3 - ET - ETA: - ETA: 6s - - ETA: 5s - loss: 0.3255 -  - ETA: 4s - loss: 0.3259 - accuracy - ETA: 4s - los - ETA: 3s - loss: 0.3263  - ETA: 2s - loss: 0.326 - ETA: 2s - loss: 0\n",
      "Epoch 00028: val_accuracy did not improve from 0.88120\n",
      "781/781 [==============================] - 55s 70ms/step - loss: 0.3264 - accuracy: 0.9201 - val_loss: 0.5480 - val_accuracy: 0.8650\n",
      "Epoch 29/100\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.3301 - accuracy: 0.9190 - ETA: 46s - loss: 0.3203 -  - ETA: 45s - loss: 0.3204 - accuracy:  - ETA: 45s - loss: 0.3213 - accuracy - ETA: 44s - loss: 0.3250 -  - ETA: 43s - loss: 0.327 - ETA:  - ETA: 37s - loss: 0.3308 - accu - ET - ETA: 31s  - ETA: 29s - loss: 0.3292 - accuracy:  - ETA: 28s - loss: 0.32 - ETA: 27s - loss:  - ETA: 25s - loss: 0.3284 - accu - ETA: 24s - loss: 0.3278  - ETA: 23s - loss: 0.3266 - accuracy: 0.920 - ETA: 23s - loss: 0.3265 - accuracy: 0.92 - ETA: 23s - loss: 0.3262 - accuracy: 0. - ETA: 23s - loss: 0.3260 - accuracy: 0.92 - ETA: 23s - lo - ETA: 21s - lo - ETA: 19s - loss: 0.3278 - accuracy:  - ETA: 18s - loss: 0.3280 - accuracy - ETA: 15s - loss: 0.3294 - accuracy: 0. - ETA: 15s - loss:  - ETA: 13s - loss: 0.3299 - accuracy: - ETA: 13s - loss: 0.3296 - accuracy - ETA: 12s - loss: 0.3298 - accuracy: 0.9 - ETA: 12s - loss: 0.3298 - accu - ETA: 11s - loss: 0.3297 - accuracy - ETA:  - ETA: 6s - loss: 0.3297 - accu - ETA: 5s - ETA: 0s - loss: 0.3302 - \n",
      "Epoch 00029: val_accuracy did not improve from 0.88120\n",
      "781/781 [==============================] - 56s 71ms/step - loss: 0.3301 - accuracy: 0.9190 - val_loss: 0.5324 - val_accuracy: 0.8663\n",
      "Epoch 30/100\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.3262 - accuracy: 0.9207 - ETA: 49s - loss: 0.3306 - accuracy: 0.92 - - ETA: 46s - loss: 0.3254 - accur - ETA: 43s - loss: 0 - ETA - ETA: 39s - loss: 0.3216 - accu - ETA: 38s - loss: 0.3211 - accuracy: 0 - ETA: 37s - loss: 0.3221 - accuracy: 0.921 - ETA: 37s - loss: 0.3219 - accuracy: 0 - ETA: 37s - loss: 0.3210 - accuracy: 0. - ETA: 3 - ETA: 34s - loss: 0.319 - ETA: 33s - loss: 0.3186 - accuracy - ETA: 33s - loss: 0.3197 - accuracy: 0.92 - ETA: 32s - loss: 0.3195 - accuracy: 0.92 - ETA: 32s - loss: 0.3195 - ac - ETA: 31s - loss: 0.3206 - accuracy: 0.9 - ETA:  - ETA: 29s - loss: 0.3211 - accuracy:  - ETA: 28s - loss: 0.3204 - accuracy: 0. - ETA: 28s - loss: 0.3200  - ETA: 27s - loss: 0.3194 - accur - ETA: 26s - loss: 0.3198 - ac - ETA: 25s - loss: 0.3194 - accuracy: 0.923 - ETA: 25s - loss: 0.3 - ETA: 24s - loss: 0.3200 - accuracy: 0.923 - ETA: 24s - - ETA: 22s - loss: 0.3 - ETA: 20s - loss: 0.3224 - accur - ETA: 20s - - ETA: 17s - loss: 0.3241 - ac - ETA: 17s - loss: 0.3248 - accu - ETA: 16s - loss: 0.3248 - accuracy:  - ETA: 15s - loss: 0.3246 - accuracy:  - E - ETA: 12s - loss: 0.3233 - ETA: 11s - loss: 0.3238 - accuracy: 0.9 - ETA: 11s - loss: 0.3238 - acc - ETA: 10s -  - ETA: 7s - loss: - ETA: 6s - loss: 0.3260 - accuracy: 0. - ETA: 6s - loss: 0.3262 - accu - ETA: 6s - loss: 0.3263  - ETA: 5s - loss: 0.3258 -  - ETA: 5s - loss: 0.3263 - accu - ETA: 4s - loss: 0.3261 - ac - ETA: 4s - loss: 0.326 - ETA: 2s - loss: 0.325 - ETA: 1s - loss: 0.3264 - accuracy: 0. - ETA: 1s - loss: 0.326 - ETA: 0s - l\n",
      "Epoch 00030: val_accuracy did not improve from 0.88120\n",
      "781/781 [==============================] - 56s 71ms/step - loss: 0.3262 - accuracy: 0.9207 - val_loss: 0.4833 - val_accuracy: 0.8800\n",
      "Epoch 31/100\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.3258 - accuracy: 0.9197 -  - ETA: 46s - loss: 0.3041 - ac - ETA: 45s - loss: 0.3092 - ac - ETA: 44s - loss: 0.3113 - accuracy: - ETA: 44s - loss: 0.3139 - - ETA: 42s - loss: 0.3171 - accura - ETA: 42s - loss: 0.3168 - accuracy: 0. - ETA: 41s - loss: 0.3172 - accuracy - ETA: 41s - loss: 0.3160 - accuracy: 0.92 - ETA: 41s - loss: 0.3166 - accuracy:  - ETA: 40s - loss: 0.3154 - accuracy: 0.9 - ETA: 40s - loss - ETA: 39s - loss: 0 - ETA: 37s - loss: 0.3219 - accu - ETA - ETA: 34s - loss: 0 - ETA: 32s - loss: 0.3249 - a - ETA: 31s - ETA: 29s - loss: 0.3246 - accurac - ETA: 28s - loss: 0.32 - ETA: - ETA: 25s -  - ETA: 23s - loss: 0.3236 - accuracy: 0 - ETA: 22s - loss: 0.3231 - accurac - ETA: 22s - l - ETA: 20s - loss: 0.3231 - accuracy: 0.9 - ETA: 19s - loss: 0.3239 - accuracy: 0.920 - ETA: 19s - loss: 0.3239 - acc - ETA: 16s - l - ETA: 1s - ETA: 0s - loss: 0.325\n",
      "Epoch 00031: val_accuracy did not improve from 0.88120\n",
      "781/781 [==============================] - 57s 73ms/step - loss: 0.3258 - accuracy: 0.9197 - val_loss: 0.6009 - val_accuracy: 0.8530\n",
      "Epoch 32/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "781/781 [==============================] - ETA: 0s - loss: 0.3287 - accuracy: 0.9199 - ETA: 41s - loss: 0.3242 - accuracy: - ETA: 40s - loss: 0.324 - ETA: 39s - loss: 0.3208 - accuracy: 0.922 - ETA: 39s - loss: 0.3208 - acc - ETA: 34s - loss: 0.3199 - accuracy: 0 - ETA: 34s - loss: 0.3205 - accurac - ETA: 33s - loss: 0.3206 - accuracy: 0. - ETA: 33s - loss: 0.3203 - accur - ETA: 26s - loss: 0.3240 - accuracy: 0. - ETA: 26s - loss: 0. - ETA: 24s - loss: 0.3241 - a - ETA: 20s - loss: 0.3238 - accuracy: - ETA: 20s - loss: 0.3239 - accuracy: 0.92 - ETA: 19s - loss: 0.3238 - accuracy - ETA: 19s - loss: 0.3242 - accu - ETA: 18s - loss: - ETA: 16s - loss: 0.3254 - accuracy:  - ETA: 16s - loss: 0.3255 - accuracy: 0.92 - ETA: 16s - loss: 0.3254 - - ETA: 14s - loss: 0.3249 - accuracy: 0. - ETA: 14s - loss: 0.3249 - ETA: 13s - loss: 0.3255 - accu - ETA: 12s - ETA: 1\n",
      "Epoch 00032: val_accuracy did not improve from 0.88120\n",
      "781/781 [==============================] - 57s 73ms/step - loss: 0.3287 - accuracy: 0.9199 - val_loss: 0.5421 - val_accuracy: 0.8663\n",
      "Epoch 33/100\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.3234 - accuracy: 0.9214 - ETA: 47s - loss: 0.3 - ETA: 45s - loss: 0.3089 - ETA: 44s - loss: 0.3113 - accuracy:  - ETA: 44s - loss: 0.3118 - accuracy:  - ETA: 43s - loss: 0.309 - ETA: 42s - loss: 0.3083 - accuracy: 0.9 - ETA: 42s - loss: 0.3088 - a - ETA: 41s - loss: 0.3107 - accuracy: 0.924 - ET - ETA: 38s - loss: 0.3115 - accurac - ETA: 38s - lo - ETA: 36s - loss: 0.3125 - accuracy: - ETA: 36s - loss: 0.3 - ETA: 34s - loss: 0.3146 - accuracy: 0.924 - ETA: 34s - loss: 0.3146 - - - ETA: 22s - loss: 0.3162 - accura - ETA: 21s - loss: 0.3165 - accuracy: 0 - ETA: 21s - loss: 0.3168 - accuracy: 0. - ETA: 21s - loss: 0.3169 - accuracy: 0.923 - ETA: 20s - loss: 0.3168 - accuracy: 0.92 -  - ETA: 18s - loss: 0.3178 - accuracy: 0. - ETA:  - ETA: 15s - loss: 0.3184 - accuracy: 0.923 - ETA: 15 - ETA: 12s - loss: 0.31 - ET - ETA: 0s - loss: 0.3232 - accura - ETA: 0s - loss: 0.3232 - accuracy - ETA: 0s - loss: 0.3233 - accuracy: 0.\n",
      "Epoch 00033: val_accuracy did not improve from 0.88120\n",
      "781/781 [==============================] - 56s 72ms/step - loss: 0.3234 - accuracy: 0.9214 - val_loss: 0.5859 - val_accuracy: 0.8622\n",
      "Epoch 34/100\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.3220 - accuracy: 0.9228 - ETA: 43s - loss: 0.3162 - ac - ETA: 42s - loss: 0.317 - ETA: 41s - loss: 0.3158 - accurac - ETA: 40s - loss: 0.3152 - accuracy: 0. - ETA: 40s - loss: 0.3153 - accuracy: - ETA: 39s - loss: 0.3157 - accuracy: 0. - ETA: 39s - loss: 0.3167 - - ETA: 29s - los - ETA: 27s - loss: 0.3158 - accuracy: - ETA: 27s - loss: 0.3161 - accuracy: - ETA: 26s - loss: 0.3167 - accuracy: 0 - ETA: 26s - loss: 0.3176 - a  - ETA: 22s - loss: 0 -  - ETA: 18s - loss: 0.3210 - accuracy: - E - ETA: 3s - - ETA\n",
      "Epoch 00034: val_accuracy did not improve from 0.88120\n",
      "781/781 [==============================] - 56s 72ms/step - loss: 0.3220 - accuracy: 0.9228 - val_loss: 0.5132 - val_accuracy: 0.8720\n",
      "Epoch 35/100\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.3232 - accuracy: 0.9205 - ETA: 48s - loss: 0.3282 - accuracy: 0.92 - ETA: 48s - loss: 0.3300 - accu - ETA: 48s - loss: 0.3361 - accuracy: 0.917 - ETA: 47s - loss: 0.3364 - ac - ETA: 47s - loss: 0. - ETA: 42s - loss: 0.3271 - accura - ETA: 42s - loss: 0.3218  - ETA: 41s - loss: 0.3220 - ac - ETA: 40s - loss: 0.3198 - accuracy: - ETA: 39s - l - ETA: 37s - loss: 0.3220 - accu - ETA: 36s - loss: 0.3205 - ETA: 35s - ETA: 33s - loss: 0 - ETA: 32s - loss: 0.3171 - ac - ETA: 31s - loss: 0.3 - ETA: 29s - loss: 0.3187 - accuracy: 0.9 - ETA: 29s - loss: - ETA: 27s - loss: 0.3189 - accuracy: 0.921 - ETA: 27s - loss: 0.31 - ETA: 26s - loss: 0.3188 - acc - ETA:  - ETA: 17s - loss: 0.3197 - accuracy: 0.921 - ETA: 17s - loss: 0.3196 - a - ETA: 16s - loss:  - ETA: 11s  - ETA: 8s - loss: 0.3229 - accu - ETA: 7s - loss: 0.3 - - ETA: 0s - loss: 0.3232 - accuracy: 0.\n",
      "Epoch 00035: val_accuracy did not improve from 0.88120\n",
      "781/781 [==============================] - 55s 71ms/step - loss: 0.3232 - accuracy: 0.9205 - val_loss: 0.5299 - val_accuracy: 0.8702\n",
      "Epoch 36/100\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.3226 - accuracy: 0.9212 - ETA: 49s - loss: 0.2935 - acc - ETA: 48  - ETA: 43s - loss: 0.3184 - a - ETA: - ETA: 40s - loss: 0.3220 - accura - ETA: 39s - loss: 0.3212 - accu - ETA: 35s - loss: 0.3201 - - ETA: 31s - loss: 0.3202 - accuracy: 0.9 - ETA: 31s - loss: 0.320 - ETA: 30s - loss: 0.3222  - ETA: 28s - loss: 0.3217 - accur - ETA: 28s - loss: 0.3207 - accura - ETA: 27s - loss: 0.3206 - accurac - ETA: 26s - loss: 0.3208 -  - ETA: 25s - loss: 0.3208 - accuracy: 0.921 - ETA: 25s - loss: 0.3209 -  - ETA: 24s - loss: 0.3213 - accuracy: 0.92 - ETA: 24s - loss: 0.3210 - accuracy: 0.9 - ETA: 24s - loss: 0.3211 -  - ETA: 2 - ETA: 21s - loss: 0.3222 - accuracy: 0. - ETA: 20s - loss: 0.3225 -  - ETA: 19s - loss: 0.3227 - a - ET - ETA: 16s - loss: 0.3212 - accur - ETA: 15s - loss: 0.3215 - accuracy: 0.921 - ETA: 15s - loss: 0.3214 - accuracy: 0.92 - ETA: 15s - loss: 0.3218 - accuracy - ETA: 6s - loss: 0.322\n",
      "Epoch 00036: val_accuracy did not improve from 0.88120\n",
      "781/781 [==============================] - 56s 71ms/step - loss: 0.3226 - accuracy: 0.9212 - val_loss: 0.5178 - val_accuracy: 0.8734\n",
      "Epoch 37/100\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.3165 - accuracy: 0.9218 - ETA: 49s - los - ETA: 47s - loss: 0.3102  - ETA: 46s - loss: 0.3015 - accuracy:  - ETA: 46s - loss: 0.3012 - accuracy: 0 - ETA: 46s - loss: 0.3018 - accur - ETA: 45 - ETA: 43s - loss: 0.3036 - accuracy: 0. - ETA: 43s - loss: 0.3044 - accuracy: 0.9 - ETA: 42s - loss: 0.3052 - accuracy:  - ETA: 42s - loss: 0.30 - ETA: 41s - loss: 0.3105 - accuracy: 0.92 - ETA: 40s - loss: 0.3111 - accurac - - ETA: 37s - loss: 0.3154 - accuracy: 0.921 - ETA: 37s - lo - ETA: 35s - loss: 0.3162 - accuracy: 0.9 - ETA: 35s - loss: 0.3159 - - ETA: 34s - loss: 0.3129 - accuracy:  - ETA: 34s - loss: 0.3143 - accu - ETA: 33s - loss: 0.3150 - accur - ETA: 32s - loss: 0.3163 - accuracy: 0. - ETA: 32s - loss: 0.3161 - accur - ETA: 31s - loss: 0.3154 - accuracy:  - ETA: 31s - loss: 0.3158 - accuracy: - ETA: 30s - loss: 0.3155 - accuracy: 0. - ETA: 30s - loss: 0.3152 - accura - ETA: 29s - loss:  - ETA: 28s - loss: 0.3161 - accuracy: 0.922 - ETA: 28s - loss: 0.3161 - accurac  - ETA: 24s - l - ETA: 22s - loss: 0.3187 - accur - ETA: 22s - loss: 0.3181 - accuracy: 0. - ETA: 21s - loss: 0.3175 - accuracy: 0 - ETA: 2 - ETA: 19s - loss: 0.3163  - ETA: 17s - loss: 0.31 - ETA: 16s - loss: 0.3158 - accuracy:  - ETA: 16s - loss: 0.31 - ETA: 14s - loss: 0.3169 - accuracy: - ETA: 14s - l - ETA: 12s - loss - ETA: 10s - loss: 0 - ETA: 9s - los - ETA: 7s - loss: 0.3162 - accuracy: 0. - ETA: 6s - loss: 0 - ETA: 6s - loss: 0.3166  - ETA: 5s - los - ETA: 4s - loss: 0.3160 - accura - ETA: 4s - loss: 0.3157 - accuracy: 0. - E\n",
      "Epoch 00037: val_accuracy improved from 0.88120 to 0.88380, saving model to my_best_model.epoch37-accuracy0.88.hdf5\n",
      "781/781 [==============================] - 56s 72ms/step - loss: 0.3165 - accuracy: 0.9218 - val_loss: 0.4947 - val_accuracy: 0.8838\n",
      "Epoch 38/100\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.3187 - accuracy: 0.9223 - ETA: 51s - los - ETA: 49s - loss: 0.2868 - acc - ETA: 48s - loss: 0.2849 - accuracy: - ETA: 47s - loss: 0.2903 -  - ETA - ETA: 43s - loss: 0.2940 - ac - ETA: 39s -  - ETA: 31s  - ETA: 28s - loss: 0.3089 -  - ETA: 27s - loss: 0.3 - ETA: 26s - l - ETA: 24s - loss: 0.3114 - accuracy: 0.924 - ETA: 24s - loss: 0.3120 - accuracy: 0.924 - ETA: 24s - loss: 0.3118 - accuracy: 0.92 - ETA: 24s - lo - ETA: 22s - loss: 0.3123 - accurac - ETA: 21s - loss: 0.3 - ETA:  - ETA: 6s - loss: 0.3186 - ac - ETA: 6s - los - ETA: 5s - los - ETA: 4s - - ETA: 0s - loss: 0.3182 - accu - ETA: 0s - loss: 0.3187 - accuracy: 0.9223\n",
      "Epoch 00038: val_accuracy did not improve from 0.88380\n",
      "781/781 [==============================] - 55s 71ms/step - loss: 0.3187 - accuracy: 0.9223 - val_loss: 0.5315 - val_accuracy: 0.8690\n",
      "Epoch 39/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "781/781 [==============================] - ETA: 0s - loss: 0.3182 - accuracy: 0.9237 - ETA: 48s - loss: 0.2896 -  - ETA: 47s - loss: 0.2910 - accuracy: 0.93 - ETA: 47s - loss: 0.2924 - -  - ETA: 43s - loss: 0.3008 - accuracy:  - ETA: 42s - loss: 0.3014 -  - ETA: 41s - loss: 0.3048 - accuracy: 0.929 - ETA: 41s - loss: 0.3046 - accuracy: 0. - ETA: 41s - loss: 0.3049 - accuracy:  - ET - ETA: 38s  - ETA: 36s - loss: 0.3094 - accurac - ETA: 33s - loss: 0.3100 - accu - ETA: 32s - loss: 0.3100 - accuracy: 0 - ETA: 32s - loss: 0 -  - ETA: 21s - loss: 0.3151 - accuracy: 0.92 - ETA: 21s - loss: 0.3149 - accuracy: 0. - ETA: 21s - l - ETA: 19s - l - ETA: 17s - loss: 0.3149 - accuracy - ETA: 17s - loss: 0.3148 - accuracy: 0.9 - ETA: 16s - loss: 0.3151 - ETA: 15s - loss: 0.3153 - accuracy:  - ETA: 15s - loss:  - ETA: 13s - loss: 0.3165 - accur - ETA: 12s - loss: 0.3165 -  - ETA: 11s - los - ETA: 10s  - ETA: 8s - loss: 0.3170 - ac - ETA:  - ETA:  - ETA:  - ETA: 2s - loss: 0.3180 - accura - ETA: 1s - l - ETA: 0s - loss: 0\n",
      "Epoch 00039: val_accuracy did not improve from 0.88380\n",
      "781/781 [==============================] - 55s 71ms/step - loss: 0.3182 - accuracy: 0.9237 - val_loss: 0.4887 - val_accuracy: 0.8815\n",
      "Epoch 40/100\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.3174 - accuracy: 0.9225 - ETA: 49s - loss: 0.3161 - accuracy: - ETA: 48s - loss: 0.2903 - accuracy: 0 - ETA: 48s - loss: 0.2872 - accuracy: 0.930 - ETA: 48s - loss: 0.2837 - accuracy: 0.93 - ETA: 48s - loss: 0.2894 - accuracy: 0. - ETA: 48s - loss: 0.3016 - ac - ETA: 47s - loss: 0.3090 - a - ETA: 46s - loss: 0.3258 - a - ETA: 45s - loss: 0.3327 - accuracy: - ETA: 45s - loss: 0.3291 - accuracy:  - ET - ETA: 42s - loss: 0.3181 - accuracy:  - ETA: 42s - loss: 0.3164 - accuracy: 0.922 - ETA: 42s - loss: 0.3167 - accuracy: 0.921 - ETA: 42s - loss: 0.3161 - accura - ETA: 41s - lo - ETA: 36s - loss: 0.3120 - accuracy: 0 - ETA: 36s - loss: 0.312 - ETA: 35s - loss: 0.3136 - accuracy - ETA: 34s - loss: 0.3147 - accura - ETA: 34s - loss: 0.3140 - ac - ETA: 33s - loss: 0.31 - ETA: 31s - loss: 0.3133 - accuracy: - ETA: 31s - loss: 0.3132 -  - ETA: 30s - loss: 0.3149 - accuracy:  - ETA: 30s - loss: 0.3154 - accur - ETA: 29s -  - ETA: 24s - loss: 0. - ETA: 22s - loss: 0.3125 - accuracy: 0.9 - ETA: 22s - loss: 0.3120  - ETA: 21s - loss: 0.3133 - accuracy: 0.9 - ETA: 21s - loss: 0.313 - ETA: 19s - loss: 0.3130 - accura - ETA: 19s - loss: 0.3124 - - ETA: 18s - loss: 0.3124 - accuracy: 0.92 - ETA: 18s - loss: 0 - ETA: 16s - loss:  - ETA: 14s - loss: 0.3142 - acc - ETA: 14s - loss: 0.3139 - accuracy: 0. - ETA: 13s - l - ETA: 11s - loss: 0.3146 - accuracy - ETA: 11s - loss: 0.3146 - accuracy: 0.92 - ETA: 11s - loss: 0.3144 - accur - ETA: 10s - loss: 0.3148 - accuracy: 0.92 - ETA: 10s - loss: 0.3 - ETA: 3s - loss: 0 - ETA: 2s - loss: 0 - ETA: 2s - loss: 0.3171 - accuracy: 0. - ETA: 2s - loss: 0.3170 - accura - ETA: 1s - loss: 0.3169 - accuracy: 0.92 - E - ETA: 0s - loss: 0.3174 - accura\n",
      "Epoch 00040: val_accuracy did not improve from 0.88380\n",
      "781/781 [==============================] - 56s 71ms/step - loss: 0.3174 - accuracy: 0.9225 - val_loss: 0.5626 - val_accuracy: 0.8647\n",
      "Epoch 41/100\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.3191 - accuracy: 0.9223 - ETA: 50s - loss: 0.3098  - ETA: 50s - loss: 0.2985 - accuracy: 0.92 - ETA: 50s - loss: 0.3009 - accuracy - ETA: 49s - loss: 0.3130 - accuracy: 0.9 - ETA: 49s - loss: 0.3 - ETA: 48s -  - ETA: 45s - loss: 0.3121  - ETA: 44s - loss: 0.3100 - accur - ETA: 43s - loss: 0.3097 - accurac - ETA: 42s - loss: 0.3097 - accuracy: 0.92 - ETA: 42s - loss: 0.3094 - - ETA: 41s - loss: 0.3073 - accuracy: 0.92 - ETA: 41s - loss: 0.3079 - accuracy: 0.92 - ETA: 41s - loss: 0.3078 - accu - ETA: 40s - loss: 0. - ETA: 35s -  - ETA: 30s - loss: 0.3136 - accuracy: 0.9 - ETA: 30s - loss: 0.3135 - accuracy: 0.92 - ETA: 30s - loss: 0.3139 - accuracy: 0. - ETA: 30s - loss: 0.3139 - accura - ETA: 29s - loss:  - ETA: 27s - loss: 0.3152 - accuracy: 0 - ETA: - ETA: 24s - loss: 0.3142 - accur - ETA: 24s - loss: 0.3134 - accurac - ETA: 23s - loss: 0.3136  - ETA: 22s - loss: 0.3133 - accurac - E - ETA: 19s -  - ETA: 14s - loss: 0.3148 - acc - ETA: 13s - loss: 0. - ETA: 11s - loss: 0.3134 - - E - ETA: 8s - loss: 0 - ETA: 8s - loss: 0.3149 - accuracy - ETA: 7s - los - ETA: 4s - loss: 0.3184 - accuracy:  - ETA: 3s - ETA: 2s - loss: - ETA: 2s - - ETA: 0s - loss: 0.3181 - ac - ETA: 0s - loss: 0.3183 - \n",
      "Epoch 00041: val_accuracy did not improve from 0.88380\n",
      "781/781 [==============================] - 55s 71ms/step - loss: 0.3191 - accuracy: 0.9223 - val_loss: 0.5155 - val_accuracy: 0.8752\n",
      "Epoch 42/100\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.3215 - accuracy: 0.9215 - ETA: 50s - loss:  - ETA: 48s - loss: 0.3277 - accurac - ETA: 48s - l - ETA: 45s - loss: 0.3232 - accur - ETA: 45s - loss: 0.3214 - acc - ETA: 44s - loss: 0.3209 - accuracy - ETA: 43s - loss: 0.3215 - a - ETA: 42s - loss: 0.3193 - accuracy: 0 - ETA: 42s - loss: 0.3179 - ETA: 41s - loss:  - ETA: 39s - loss: 0.3235 - accuracy: 0.920 - ETA: 39 - ETA: 37s - loss: 0.3240 - accura - ETA: 36s - loss: 0.3227 - accuracy: 0.92 - ETA: 36s - loss: 0.3240 - accuracy: 0.9 - ETA: 36s -  - ETA: 34s - loss: 0.323 - ETA: 32s - loss: 0.3213 - accuracy: 0.922 - ETA: 32s - loss: 0 - ETA: 31s - loss: 0.3202 - accurac - ETA: 30s - loss: 0.3196 - accurac - ETA: 29s - loss: 0.3195 - accuracy: 0.922 - ETA: 29s - loss: 0.3193 - accuracy: - ETA: 29s - loss: 0.3182 - a - ETA: 28s - loss: 0.3187 - accuracy: 0. - ETA: 25s - - ETA: 23s - loss: 0.3222 - accuracy: - ETA: 22s - loss - ETA: 21s - loss: 0.3221 - accuracy: 0 - ETA: 20s - loss: 0.3217 - accuracy - ETA: 20s - ETA: 18s - loss: 0.3229  - ETA: 16s - loss: 0.3221 - accuracy: 0.92 - ETA: 16s - loss: 0.3221 - accuracy: 0.\n",
      "Epoch 00042: val_accuracy improved from 0.88380 to 0.88430, saving model to my_best_model.epoch42-accuracy0.88.hdf5\n",
      "781/781 [==============================] - 56s 72ms/step - loss: 0.3215 - accuracy: 0.9215 - val_loss: 0.4577 - val_accuracy: 0.8843\n",
      "Epoch 43/100\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.3159 - accuracy: 0.9222 - ETA: 50s - loss: 0.3101 - accuracy:  - ETA: 50s - loss: 0.3114 - accuracy: - ETA: 50s - loss: 0.3184 - accuracy: 0.9 - ETA: 49s - loss: 0.3142 - accuracy: 0.923 - ETA: 49s - loss: 0.3152 - ETA: 47s - loss: 0.3130 - a - ETA: 46s - loss: 0.3123 - accurac - ETA: 45s - loss: 0.3163 - accuracy: 0. - ETA: 45s - loss: 0.3162 - accuracy: 0.921 - ETA: 45s - loss: 0.3171 - accura - ETA: 44s - loss: 0 - ETA: 43s - loss: - ETA: 41s - loss: 0 - ETA: 40s - loss: 0.3171 - acc - ETA: 36s - loss: 0.3151 - acc - ETA: 35s - loss: 0.3143 - accurac - ETA: 34s - loss: 0.3130 - accu - ETA: 3 - ETA: 31s - loss: 0.3146 - accuracy: 0.921 - ETA: 31s - l - ETA: 29s - loss: 0.3143 - accuracy: 0.92  - ETA: 23s - loss: 0.3115 - accuracy - ETA: 23s - loss: 0.3119 - ETA: 22s - loss: 0.3122 - accuracy - ETA: 18s - loss: 0.3131 - accuracy:  - ETA: 18s - lo - ETA: 16s - loss: 0.3142 - a - ETA: 15s - loss: 0.315 - ETA: 14s - loss: 0.3136 - - ETA: 13s - loss: 0.3140 - accuracy: 0. - ETA: 12s - loss: 0.3142 - accuracy: 0.922 - ETA: 12s - loss: 0.3140 - accur - ETA: 12s - loss: 0.3138 - ac - ETA: 11s - lo - ETA: 8s - loss: 0.3144 - accuracy:  - ETA: 7s - ETA:  - ETA: 4s - loss: - ETA:  - ETA: 2s - loss: 0.315 - ETA: 1s - loss: 0.3162 - accura - ETA: 1s - loss: 0.3159 - accu - ETA: 0s - loss: 0.3158 - accura - ETA: 0s - loss: 0.3159 \n",
      "Epoch 00043: val_accuracy did not improve from 0.88430\n",
      "781/781 [==============================] - 55s 71ms/step - loss: 0.3159 - accuracy: 0.9222 - val_loss: 0.5096 - val_accuracy: 0.8787\n",
      "Epoch 44/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "781/781 [==============================] - ETA: 0s - loss: 0.3130 - accuracy: 0.9247 - ETA: 49s - loss: 0.2770 - accu - ETA: 48s - loss: 0.2978  - ETA: 47s - loss: 0. - ETA: 46s - loss: 0.3005  - ETA: 45s - loss: 0.2954 - accuracy: 0.9 - ETA: 44s - -  - ETA: 34s - loss: 0.3038 - acc - ETA: 33s - los - ETA: 32s - loss: 0.3040 - acc - ETA: 31s - loss: 0.3053 - accur - ETA: 30s - loss: 0.3049 - accuracy: 0 - ETA: 30s - loss: 0.3048 - accura - ETA: 29s - loss: 0.3058 - accuracy: 0. - ETA: 29s - - ETA: 27s - loss: 0.3054 - ETA: 26s - loss: 0.3052 - accuracy: 0.9 - ETA: 25s - loss: 0.3060 - accurac - ETA: 25s - loss: 0.3059 - accuracy: 0.92 - ETA: 25s - loss: 0. - ETA: 23s - loss: 0.3060 - accuracy: 0. - ETA: 23s - loss: 0.3058 - accuracy:  - ETA: 22s - loss: 0.3055 - accuracy: 0 - ETA: 22s - loss: 0.3058 -  - ETA: 21s - loss: - ETA: 19s - loss: 0.3086 - accurac - ETA: 19s - ETA: 14s - loss: 0.3103  - ETA: 12s - loss: 0 - ETA: 11s - loss: 0.3113 - accuracy - ETA: 10s - loss: 0.3112 - accuracy: 0.925 - ETA: 10s - loss: 0.3112 - a - E - E\n",
      "Epoch 00044: val_accuracy did not improve from 0.88430\n",
      "781/781 [==============================] - 56s 72ms/step - loss: 0.3130 - accuracy: 0.9247 - val_loss: 0.5781 - val_accuracy: 0.8609\n",
      "Epoch 45/100\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.3134 - accuracy: 0.9243 - ETA: 50s - loss: 0.2994 - accuracy - ETA: 49s - loss: 0. - ETA: 48s - loss: 0.3091 - ac - ETA: 47s - loss: 0.3088 - accura - ETA: 46s - loss: 0.3064 - accuracy: 0.9 - ETA: 46s - loss: 0.3071 - accuracy: 0.920 - ETA: 46s - loss: 0.3071 - acc - ETA: 45s - loss: 0.3135 - accuracy: 0. - ETA: 45s - loss:  - ETA: 43s - loss: 0.3064 - accuracy: 0.921 - ETA: 43s - loss: 0.3066 - accuracy: 0. - ETA: 42s - loss: 0.3054 - accuracy:  - ETA: 42s - loss: - ETA: 40s - loss: 0.3101 -  - ETA: 39s - loss: 0.3085 - a - E - ETA: 36s - loss: 0.3098 - accurac - ETA: 35s - loss: 0.3086 - ac - ETA: 34s - loss: 0.3091 -  - ETA: 33s - loss: 0.3076 - ac - ETA: 32s - loss: 0.3086 - accuracy - ETA: 32s - loss: 0.3086 - accuracy: 0 - ETA: 31s - loss: 0.3090 - accuracy: 0. - ETA: 31s - loss: 0.3089 - accuracy: 0.9 - ETA: 31s - los - ETA: 29s - loss: 0.3130 - - ETA: 28s - loss: 0.3128 - accura - ETA: 27s - loss: 0.3141 - accuracy: 0. - ETA: 27s - loss: 0.3136 - ETA: 26s - loss: 0.3143 - ac - ETA: 25s - loss: 0.3137 - accuracy: 0.923 - ETA: 25s - loss: 0.3135 - accuracy: 0. - ETA: 24s - los - ETA: 23s - loss: 0.3128 - accuracy: 0.92 - ETA: 22s - loss - ETA: 21s - loss: 0.3129 - accu - ETA: 20s - loss: 0.3 - ETA: 18s - loss: 0.3136 - a - - ETA: 15s  - ETA: 12s - l - ETA: 6s - loss: 0.3133 - accuracy: 0.92 - ETA: 5s - loss: 0.3134 - accuracy - ETA: 5s - loss: 0.3134 - accuracy: 0.92 - ETA: 5s - loss: 0.313 - ETA: 3s - los - ETA: \n",
      "Epoch 00045: val_accuracy did not improve from 0.88430\n",
      "781/781 [==============================] - 56s 72ms/step - loss: 0.3134 - accuracy: 0.9243 - val_loss: 0.5684 - val_accuracy: 0.8638\n",
      "Epoch 46/100\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.3135 - accuracy: 0.9248 - ETA: 50s - loss: - ETA: 49s - loss: 0.3383 - accuracy: 0.921 - ETA: 49s - loss: 0.3373 - accuracy: - ETA: 48s - loss: 0.3267 - accuracy: 0.92 - ETA: 48s - loss: 0.3201 - accuracy: 0. - ETA: 48s - loss: 0.3153 - accurac - ETA: 47s - - ETA: 44s - loss: 0.3 - ETA: 43s - loss: 0.302 - ETA: 42s - loss: 0.3026 - accuracy: 0.929 - ETA: 41s - loss: 0.3028 - accuracy: 0. - ETA: 41s - loss: 0.3033 - accura - ETA: 41s - loss: 0.3057 - accura - ETA: 40s - loss: 0.3093 - accuracy: 0 - ETA: 37s - loss: 0.3079  - ETA: 36s - loss: 0.3093 - accuracy: 0 - ETA: 36s - loss: 0.3100 - accuracy:  - ET - ETA: 33s - loss: 0.3099 - accuracy: 0.92 - ETA: 33s - loss: 0.3106 - accuracy: - ETA: 29s - loss: 0.3104 - accuracy: - ETA: 29s - loss: 0.310 - ETA: 27s - loss: 0.3106 - accuracy: 0.92 - ETA: 27s - loss: 0.3103 - accuracy: 0.92 - ETA: 27s - loss: - ETA: 25s - loss: 0.3104 - accuracy: 0.925 - ETA: 25s - l - ETA: 23s - loss: 0.3120 - accuracy: 0. - ETA: 23s - loss: 0.3121 - accura - ETA:  - ETA: 17s - loss: 0.314 - ETA: 16s - loss: 0.3148 - accuracy - ETA: 15s - loss: 0.3153 -  - ETA: 14s -  - ETA: 12s \n",
      "Epoch 00046: val_accuracy did not improve from 0.88430\n",
      "781/781 [==============================] - 56s 71ms/step - loss: 0.3135 - accuracy: 0.9248 - val_loss: 0.5751 - val_accuracy: 0.8619\n",
      "Epoch 47/100\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.3142 - accuracy: 0.9244 - ETA:  - ETA: 47s - loss: 0.311 - ETA: 46s - loss: 0.3124 - accurac - ETA: 45s - loss: 0.3096 - accura - ETA: 44s - loss: 0.31 - ETA:  - ETA: 35s - loss: 0.3142 - acc - ETA: 34s - loss: 0.3132 - accu  - ETA: 31s - loss: 0.3099 - - ETA: 29s - loss: 0.3105 - accurac - ETA: 29s - loss: 0.3116 - acc - ETA: 28s - loss: 0.3128 - accura - ETA: 27s - loss: 0.3130  - ETA: 26s - loss: 0.315 - ETA: 22s - loss:  - ETA: 11s - loss: 0.3123 - ac - ETA: 10s - loss: 0.3119 - accura - ETA: 10s - l - ETA: 4s - loss: 0 - ETA:  - ETA: 2s - loss: 0.3132 - accura - ETA: 2s - ETA: 1s - loss: 0.3140 - accuracy - ETA: 1s\n",
      "Epoch 00047: val_accuracy did not improve from 0.88430\n",
      "781/781 [==============================] - 56s 72ms/step - loss: 0.3142 - accuracy: 0.9244 - val_loss: 0.5843 - val_accuracy: 0.8602\n",
      "Epoch 48/100\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.3100 - accuracy: 0.92521- ETA: 49s - loss: 0.2902 - - ETA: 48s - loss: 0.2999 - accurac - ETA: 47s - loss: 0.2935 - accurac - ETA: 47s - loss: 0.2978 - accuracy: 0.9 - ETA: 46s - loss: 0.2975 -  - ETA: 45s -  - ETA: 38s - loss:  - ETA: 33s - loss: 0.3032 - accura - ETA: 32s - loss: 0.3032 - accuracy - ETA: 32s - loss: 0.3037 - ac - ETA: 31s - loss: 0.3045 - accuracy: - ETA: 31s - loss: 0.3050 - accuracy: 0 - ETA: 30s - loss: 0.3058 - accuracy: - ETA: 30s - loss: 0.3062 - accuracy: - ETA: 29s - loss: 0.3060 - accuracy:  - ETA: 29s - loss: 0. - ETA: 27s - loss: 0.3078 - accuracy: 0.925 - ETA: 27s - loss: 0.3081 - accuracy: 0 - ETA: 27s -  - ETA: 25s - loss: 0.308 - ETA: 21s - loss: 0.3084 - accura - ETA: 20s - loss: 0.3083 - accuracy: 0 - ETA: 20s - loss: 0.3091  - ETA: 19s - loss: 0.3087 - ETA: 17s - l - E - E - ETA: 7s - loss: 0.310 - ETA: 3s - loss: 0.3099 - accuracy: 0.92 - ETA: 3s - los - ETA: 2s - loss: 0.3100 - ac - ETA: 2s - loss: 0 - ETA: 1s - loss: 0.3105 - accu - ETA: 1s - loss: 0.3 - ETA: 0s - loss: 0.3101 - accuracy:  - ETA: 0s - loss: 0.3102 - accuracy: \n",
      "Epoch 00048: val_accuracy did not improve from 0.88430\n",
      "781/781 [==============================] - 56s 72ms/step - loss: 0.3100 - accuracy: 0.9252 - val_loss: 0.5470 - val_accuracy: 0.8696\n",
      "Epoch 49/100\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.3103 - accuracy: 0.92431- ETA: 51s - loss: 0.2794 - accuracy - ETA: 50s - loss: 0.30 - ETA: 48s - loss: 0.3215 - accuracy - ETA: 48s - loss: 0.3284 - accuracy: - ETA: 47s - loss: 0.3300 - ETA: 46s - loss: 0.3213 - accuracy: - ETA: 45s - loss:  - ETA: 44s - loss: 0.3127  - ETA: 42s - loss: 0.3100 -  - ETA:  - ETA: 39s - loss: 0.3118 - accuracy: 0 - ETA: 39s  - ETA: 37s - loss: 0.3 - ETA: 32s - l - E - ETA: 27s - loss: 0.3066 - accuracy: 0.9 - ETA: 27s - loss: 0.3070 - ac - ETA: 26s -  - ETA: 21s - loss: 0.308 - ETA: 20s - loss: 0.3079 - accuracy:  - ETA: 20s - loss: 0.3080 - accura - ETA: 16s -  - ETA: 14s - loss: 0.3105 - accuracy - ETA: 14s - loss: 0.3103 - accuracy: 0.924 - ETA: 13s - loss: 0.3103 - acc - ETA: 13s - loss: 0.3107 - - ETA: 8s - ETA: 5s - l - ETA - ETA: 3s - loss: 0.3105  - ETA: 2s - loss: 0.3106  - ETA: 2s - los - ETA: \n",
      "Epoch 00049: val_accuracy did not improve from 0.88430\n",
      "781/781 [==============================] - 56s 72ms/step - loss: 0.3103 - accuracy: 0.9243 - val_loss: 0.5320 - val_accuracy: 0.8716\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "781/781 [==============================] - ETA: 0s - loss: 0.3131 - accuracy: 0.9241 - ETA: 50s - loss: 0.2945 - ac - ETA: 49s - loss: 0.3114 - accuracy: 0.927 - ETA: 49s - loss: 0.3130 - accuracy: 0. - ETA: 48s - loss: 0.3092 - accuracy: 0.928 - ETA: 4 - ETA: 45s - loss: 0.3054 - accuracy: 0 - ETA: 45s - loss: 0.3075 - accu - ETA: 44s - loss: 0.3118 -  - - ETA: 35s - loss: 0.3084 - ac - ETA: 34s - loss: 0.3081 - accuracy: 0.926 - E - ETA: 31s - loss: 0.3097 - - ETA: 30s - loss: 0.3095 - - ETA:  - ETA: 23s - loss: 0.3124 - acc - ETA: 23s - loss: 0.3127  - ETA: 22s - loss: 0.3118 - accu - ET - ETA: \n",
      "Epoch 00050: val_accuracy did not improve from 0.88430\n",
      "781/781 [==============================] - 56s 72ms/step - loss: 0.3131 - accuracy: 0.9241 - val_loss: 0.5662 - val_accuracy: 0.8607\n",
      "Epoch 51/100\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.3101 - accuracy: 0.9258 - ETA: 40s - loss: 0.3097 - accuracy - ETA:  - ETA: 36s - loss: 0.3108 - accurac - ETA: 36s - los - ETA: 33s - loss: 0.3119 - accur - ETA: 33s - loss: 0. - ETA: 31s - loss: 0.31 - ETA: 29s - loss: 0.3116 - ETA: 28s - loss: 0.3094 - accu - ETA: 27s - ETA: 25s - loss: 0.3087 - accuracy: 0 - ETA: 24s - loss: 0.3084 - accura - ETA: 24s - loss: 0.3081 - accuracy: 0 - ETA: 23s - loss: 0.3080 - ac - ETA: 19s  - ETA: 17s - loss: 0.3072 - acc - ETA: 1 - ETA: 14s - loss: 0.3 - ETA: 12s - loss: 0.30 - ETA: 11s - loss: 0.3087 - accuracy: 0.925 - ETA: 11s - loss: 0.3088 - accuracy - ETA: 10s - loss: 0.3086 - accu - ETA: 9s - loss: 0.3087 - accuracy: 0. - ETA: 9s - loss: 0.3088 - accuracy:  - ETA: 9s - loss: 0.3091 - accuracy:  - - ETA: 7s - - ETA: 0s - l\n",
      "Epoch 00051: val_accuracy did not improve from 0.88430\n",
      "781/781 [==============================] - 57s 73ms/step - loss: 0.3101 - accuracy: 0.9258 - val_loss: 0.4933 - val_accuracy: 0.8798\n",
      "Epoch 52/100\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.3092 - accuracy: 0.9251 - ETA: 51s - loss: 0.2968 - accuracy: 0. - ETA: 50s - loss: 0.3039 - accuracy: 0.916 - ETA: 50s - loss: 0.2968 - accuracy: - ETA: 49s - loss: 0.3090 - accu - ETA: 48s - loss: 0.2970 - accuracy: 0.924 - ETA: 48s - loss: 0.2949 - accuracy: 0.9 - ETA: 48s - loss: - ETA: 46s - loss: 0. - ETA: 45s - loss: 0.2928 - accura - ETA: 44s - loss: 0.2 - ETA: 43s - loss: 0.2937 - accuracy: 0. - ETA: 43s - loss:  - ETA: 41s - lo - ETA: 39s - loss: - ETA: 37s - loss: 0.2979 - accuracy: 0.9 - ETA: 37s - loss: 0.2979 - a - ETA: 36s - - ETA: 34s - los - ETA: 29s - loss: 0.3019 - accuracy - ETA: 29s - loss: 0.3018 - accu - ETA: 28s - loss: 0.3017  - ETA: 27s - loss: 0.3 - ETA: 25s - loss: 0. - ETA: 21s - loss: 0.3044 - accuracy: 0 - ETA: 20s - loss: 0.3042 - accuracy: 0. - ETA: 20s - loss: 0.3045 - accuracy: 0 - ETA: 20s - loss: 0.3052 -  - ETA: 19s - loss: 0.3054 - accuracy:  - ETA: 18s - loss: 0.3054 - accuracy: 0.92 - ETA: 18s - loss: 0.3053 - ac - ETA: 17s - loss: 0.306 - ETA: 0s - loss: 0.3091 - accuracy: 0.\n",
      "Epoch 00052: val_accuracy did not improve from 0.88430\n",
      "781/781 [==============================] - 56s 71ms/step - loss: 0.3092 - accuracy: 0.9251 - val_loss: 0.5266 - val_accuracy: 0.8680\n",
      "Epoch 53/100\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.3105 - accuracy: 0.9243 - ETA: 37s - loss: 0.3024 - accuracy:  - ETA: 36s - ETA: 34 - ETA: 32s -   - ETA: 27s  - ETA: 25s - loss: 0.3070 - accura - ETA: 24s - loss: 0.3068 - acc - ETA: 24 - ETA: 21s - loss - ETA: 19s - loss: 0.3095 -  - ETA: 18s - loss: 0.3097 - accuracy: - ETA: 18s - loss:  - ETA: 16s - loss: 0.3100 -  - ETA: 15s - ETA: 13s - lo - ETA: 11s - loss: 0.3104 - accuracy - ETA: 11s - l - ETA: 5s - loss: 0.3119 - accuracy - ETA: 4s - ETA - ETA: 2s - loss: 0.3111 - accuracy - ETA: 2s - los - ETA: 1s - loss: 0.3107 - accu - ETA: 0s - l\n",
      "Epoch 00053: val_accuracy did not improve from 0.88430\n",
      "781/781 [==============================] - 56s 72ms/step - loss: 0.3105 - accuracy: 0.9243 - val_loss: 0.5534 - val_accuracy: 0.8672\n",
      "Epoch 54/100\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.3084 - accuracy: 0.9258 - ETA: 48s - loss: 0.3023 - accuracy: - ETA: 48s - loss: 0.3051 - accuracy: 0. - ETA: 48s - loss: 0.3028 - ac - ETA: 47s - loss: 0.2958 - accura - ETA: 46s - l - - ETA: 39s - loss: 0.3026 - accurac - ETA: 39s - loss: 0.30 - ETA: 28s - loss: 0.3060 - accuracy - ETA: 28s - loss: 0.3054 - accuracy: - ETA: 27s - loss: 0.3052 - accuracy: 0.9 - ETA: 27s - loss: 0.3049 - accuracy: - ETA: 27s - loss: 0.305 - ETA: 26s - loss: 0.3039 - accura - ETA: 25s - loss: 0.3040 - accuracy:  - ETA: 24s - loss:  - ETA: 23s  - ETA: 21s - loss: 0.3043 - accuracy:  - ETA: 20s -  - ETA: 18s - loss: 0.3055 - ETA: 17s - loss: 0.3056 - accurac - ETA: 17s - loss: 0.3061 - accuracy: 0.925 - ETA: 16s - loss: 0.3 - ETA: 15s - loss: 0.3066 - ac -  - ETA: 11s - loss: 0.3071 - accuracy: - ETA: 11s - loss: 0.3074 - accuracy: 0.92 - ETA: 11s - loss: 0.3076 - accuracy: 0.925 - ETA: 11s - loss: 0.3077 - accuracy: 0.92 - ETA: 11s - loss: 0.3076 - accuracy: 0. - ETA: 10s - lo - ETA: 9s - los - ETA: 8s - loss: 0.3079 - ac - ETA: 8s - l - ETA: 7s - loss: 0.3069 - accuracy: 0. - ETA: 6s - loss: 0.306 - ETA: 6s - loss: - ETA: 4s - loss: 0.3 - ETA: 0s - loss: 0.3085 - accu\n",
      "Epoch 00054: val_accuracy did not improve from 0.88430\n",
      "781/781 [==============================] - 56s 71ms/step - loss: 0.3084 - accuracy: 0.9258 - val_loss: 0.5151 - val_accuracy: 0.8768\n",
      "Epoch 55/100\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.3117 - accuracy: 0.9242 - ETA: 46s - loss: 0.2939 - accuracy: 0.92 - ETA: 46s - loss: 0.29 - ETA: 45s - loss: 0.2926 - accur - ETA: 44s - loss: 0.2955 - accur - ETA: 43s - loss: 0.2969 - accuracy: 0.9 - ETA: 43s - loss: 0.2960 - accur - ETA: 39s - loss: 0.2944 - accuracy: 0 - ETA: 39s - loss: 0.2937 - accuracy:  - ETA: 38s - loss: 0.2940 - accu - ETA: 38s - loss: 0.2952 - accuracy: 0.92 - ETA: 37s - loss: 0.2953 - accurac - ETA: 37s - loss: 0.2966 - accuracy: 0.9 - ETA: 37s - loss: 0.2969 - accuracy - ETA: 36s - loss: 0.2966 - accuracy: 0.926 - E - ETA: 33s - loss: 0.2979 - accuracy: 0.927 - ETA: 33s - loss: 0.2979 - a - ETA: 32s - loss: 0.2981 - accuracy - ETA:  - E - ETA: 27s - loss: 0.2970 - accuracy: 0.927 - ETA: 27s - loss: 0.2969 - accuracy: 0.92 - ETA: 27s - loss: 0.2970 - accuracy:  - ETA: 26s - loss: 0.2972 - accuracy: 0.92 - ETA: 26s - loss: 0.2977 - accurac - ETA: 25s - loss: 0.2998 - a - ETA: 24s - loss: 0.300 - ETA: 23s - loss: 0.3019 - accuracy: 0.9 - ETA: 23s - loss: 0.3022 - accur - ETA: 22s - los - ETA: 20s - loss: 0.3035 - ac - ETA: 19s - loss: 0.3051 -  - ETA: 18s - loss: 0.3051  - ETA: 17s - loss: 0.3055 - accur - ETA: 17s - loss: 0 - ETA: 15s - loss: 0.30 - ETA: 11s - loss: 0.3079 - - ETA: 10s - loss: 0. - ETA: 0s - loss: 0.3113 - accuracy:  - ETA: 0s - loss: 0.3116 - accura - ETA: 0s - loss: 0.3117 - accuracy: 0.\n",
      "Epoch 00055: val_accuracy did not improve from 0.88430\n",
      "781/781 [==============================] - 56s 72ms/step - loss: 0.3117 - accuracy: 0.9242 - val_loss: 0.5572 - val_accuracy: 0.8701\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "781/781 [==============================] - ETA: 0s - loss: 0.3092 - accuracy: 0.9260 - ETA: 48s - loss: 0.2955 - ac - ETA: 48 - ETA: 46s - loss: 0.3030 - accuracy:  - ETA: 45s - loss: 0.3037 -  - ETA: 44s - loss: 0.3021 -  - ETA: 43s - loss: 0.2997 - accuracy: 0.929 - ETA: 43s - loss: 0.3004 - accuracy:  - ETA: 43s - loss: 0.3003 - accuracy - ETA: 42s - loss: 0.2998 - accu - ETA: 41s - loss: 0.3011 - accur - ETA: 40s - loss: 0.3021 - accura - ETA: 40s - loss: 0.2989 - ETA: 39s - loss: 0.2986 - ac - ETA: 38s - loss: 0.2999 - accuracy: - ETA: 37s - loss: 0.3010 - a - ETA: 36s - loss: 0.2990 - ac - ETA: 35s - loss: 0.2970 - accuracy: 0.93 - ETA: 35s - loss: 0.2 - ETA: 34s - loss: 0.2996 - accuracy: - ETA: 33s - l - ETA: 31s - loss: 0.2996 - acc - ETA: 27s - l - ETA: 23s - loss: 0.3028 - ETA: 21s - - ETA: 19s - loss: 0.30 - ETA: 18s - loss: 0.3057 - accuracy: - ETA: 18s - loss: 0.3057 - accuracy - ETA: 17s - loss: 0.3051 - ETA: 16s - loss: 0.3058 - - ETA: 15s - loss: 0.30 - - ETA: 9s - loss: 0.3073  - ETA: 8s - loss: 0.307 - ETA: 7s - loss: 0.307 - ETA: 7s - l - ETA: 6s - loss: 0.3083 - ac - ETA - ETA: 4s - loss: 0.3084 - ac - ETA: 2s - loss: 0.3094 - accu - ETA: 2s - loss: 0.3091 - accuracy:  - ETA: 2s - ETA: 0s - loss: 0.3087 - accuracy: 0. - ETA: 0s - loss: 0.3 - ETA: 0s - loss: 0.3090 - accuracy: 0.\n",
      "Epoch 00056: val_accuracy did not improve from 0.88430\n",
      "781/781 [==============================] - 56s 71ms/step - loss: 0.3092 - accuracy: 0.9260 - val_loss: 0.5948 - val_accuracy: 0.8598\n",
      "Epoch 57/100\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.3056 - accuracy: 0.9264 - ETA: 49s - loss: 0.2908 - accuracy: 0.930 - ETA: 49s - loss: 0.3011 - accuracy:  - ETA: 49s - loss: 0.3024 - accurac - ETA: 48s - loss: 0.3058 - ETA: 47s - loss: 0.3046 - - ETA: 46s - ETA: 44 - ETA: 41s - loss: 0.2977 - accu - ETA: 41s - loss: 0.2974 -  - ETA: 39s - loss: 0.2964 - - ETA: 38s - loss: 0.2933 - accuracy:  - ETA: 38s - loss: 0.2935 - accuracy: 0.930 - ETA: 38s - loss: 0.2939 - accuracy: 0 - ETA: 37s -  - ETA: 35s - loss: 0.2932 -  - ETA: 34s - loss: 0.2945 - accuracy: - ETA: 34s - loss: 0.2942 - accuracy: 0. - ETA: 33s - loss: 0.2941 - accuracy: 0.93 - ETA: 33s - loss: 0.2941 - accuracy: 0 - ETA: 33s - loss: 0.2941 - accuracy: 0. - ETA: 33s - los - ETA: 31s - loss: 0.2974 - acc - ETA: 30s - loss: 0.298 - ETA: 29s - loss: 0.2994 - accuracy: 0. - ETA: 29s - loss: 0.3000 - accuracy: 0.92 - ETA: 28s - loss: 0.2 - ETA: 27s - loss: 0.3000 - ETA: 26s - loss: 0.2995 - accuracy: 0.92 - ETA: 26s - loss: 0.2997 - ac - ETA: 25s - loss: 0.2997 - a - ETA: 24s - loss: 0.3005 - accur  - ETA: 20s - loss: 0.299 - ETA: 19s - loss: 0.3015 - accuracy - ETA: 18s - loss: 0.3025 - accuracy: 0.927 - ETA: 18s - loss: 0.3028 - ac - ETA: 17s - loss: 0.3031 - accuracy - ETA: 17s - loss: 0.3022 - accuracy: 0 - ETA: 17s - loss: 0.3032 - accuracy:  - ETA: 16s - loss: 0.3032 - accur - ETA: 15s - loss: 0.3025 - a - ETA: 14s - loss: 0.3027 - accuracy: 0. - ETA: 14s - loss: 0.3026 - accuracy: 0. - ETA: 14s - loss: 0.3031 - accuracy: 0.9 - ETA: 14s - loss: 0.3029 \n",
      "Epoch 00057: val_accuracy did not improve from 0.88430\n",
      "781/781 [==============================] - 56s 71ms/step - loss: 0.3056 - accuracy: 0.9264 - val_loss: 0.5272 - val_accuracy: 0.8690\n",
      "Epoch 58/100\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.3076 - accuracy: 0.9259 - ETA: 49s - loss: 0.2907 - accuracy: 0 - ETA: 49s - loss: 0.2894 - - ETA: 47s - loss: 0.2982 - accura - ETA: 47s - loss: 0. - ETA: 46s - loss: 0.3016 - - ETA: 45s - loss: 0.3057 - accuracy: 0.927 - ETA: 45s - loss - ETA: 43s - loss: 0.3058 - acc - ETA: 4 - ETA: 39s - loss: 0.3088 - accuracy: 0. - ETA: 39s - loss: 0.3072 - a - ETA: 38s - loss: 0.3089 - accuracy: 0.92 - ETA: 38s - loss: 0.3085 - accur - ETA: 37s -  - ETA: 36s - loss: 0.3040 - accuracy: 0.928 - ETA: 35s - loss: 0.3036 - accuracy: - ETA: 32s - loss: 0.3035 - accuracy: 0.92 - ETA: 32s - loss: 0.3037 - accur - ETA: 26s - loss: 0.3065 - accuracy:  - ETA: 25s - loss: 0.3063 - accuracy - ETA: 25s - loss: 0.3062 - ac - ETA: 24s - loss: 0.3064 - accuracy:  - ETA: 23s - loss: 0.3057 - accuracy: 0. - ETA: 23s - loss: 0.3054 - accuracy:  - ETA: 23s - loss: 0.3052 - accura - ETA: 22s - los - ETA: 12s - loss: 0.3040 - accuracy: 0.927 - ETA: 12s - loss: 0.3040 - accu - ETA: 11s - loss: 0.3045 - accuracy: - ETA: 10s - loss: 0.3046 - accuracy:  - ETA: 10s - loss: 0.3048 - accuracy: 0.92 - ETA: 10s - loss: 0.3048 - acc - ETA: 9s - loss: 0.3050 - accuracy: 0. - ETA: 9s - los - ETA: 8s - loss: 0.3058 - accuracy: 0. - ETA: 8s - l - - ETA: 3s - ETA:  - ETA: 1s - ETA: 0s - loss: 0.3077 - accuracy: 0.9259\n",
      "Epoch 00058: val_accuracy did not improve from 0.88430\n",
      "781/781 [==============================] - 56s 71ms/step - loss: 0.3077 - accuracy: 0.9259 - val_loss: 0.5663 - val_accuracy: 0.8662\n",
      "Epoch 59/100\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.3042 - accuracy: 0.9259 - ETA: 49s - loss: 0.3032 - accuracy: 0.9 - ETA: 49 - ETA: 47s - loss: 0. - ET - ETA: 43s - loss: 0.3005 -  - ETA: 42s - loss: 0. - ETA: 41s - loss: 0.3027 - accuracy: - ETA: 40s - loss: 0.3013 - accuracy: 0.9 - ETA: 40s - loss: 0.3018 - accura - ETA: 39s - loss: 0.3028 - accuracy: 0 - ETA: 39s - loss: 0.3031 - accuracy: 0. - ETA: 39s - loss: 0.3035 - accuracy:  - ETA: 38s - loss: 0.3039 - accuracy: 0.9 - ETA: 38s - loss: 0.3036 - accuracy: 0.9 - ETA - ETA: 36s - loss: 0.3013 - - ETA: 35s - loss: 0.3001 - accuracy: - ETA: 34s - loss: 0.2991 - accuracy: 0. - ETA: 34s - loss: 0.2990 - ETA: 33s - loss: 0.3022 - acc - ETA: 32s - loss: 0.3028 - accurac - ETA: 31s - loss: 0.3032 - accurac - ETA: 30s - ETA: 28s - loss: 0 - ETA: 27s - loss: 0.3038 - accuracy: - ETA: 26s - loss: 0.303 - ETA: 25s - loss: 0.3047 - accuracy: 0.9 - ETA: 25s - loss: 0.30 - ETA: 23s - loss:  - ETA: 19s - loss: 0. - ETA: 17s - loss: 0.3049 - ac - ETA: 16s - loss: 0.3053 - accu - ETA: 15s - loss: 0.3053 - accuracy: 0.925 - ETA: 15s - loss: 0.3053 - accuracy: - E - ETA: 6s - loss: 0.3035 - accuracy: 0.92 - ETA: 6s - loss: 0.3034 - accura - E - ETA: 3s - ETA: 2s - loss: 0.3037 - accuracy:  - ETA: 0s - loss: 0.3039 - ac - ETA: 0s - loss: 0.3037 - \n",
      "Epoch 00059: val_accuracy did not improve from 0.88430\n",
      "781/781 [==============================] - 56s 72ms/step - loss: 0.3042 - accuracy: 0.9259 - val_loss: 0.5707 - val_accuracy: 0.8657\n",
      "Epoch 60/100\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.3086 - accuracy: 0.9253 - ETA: 48s - lo - ETA: 47s - loss: 0.2819 - accuracy: 0 - ETA: 47s - loss: 0.2844 - accuracy: 0.93 - ETA: 47s - loss: 0.2850 - accuracy: 0.9 - ETA: 47s - loss: 0.2860 - accuracy: 0 - ETA: 47s - loss: 0.2833 - - ETA: 46s - l - ETA: 44s - loss: 0. - ETA: 42s - los - ETA: 40s - loss: 0 - ET - ETA: 36s - loss: 0.2994 - accuracy: 0.929 - ETA: 36s - los - ETA: 34s - loss: 0.3016 - a - ETA: 33s - loss: 0.3004 - ETA: 32s - loss: 0.2999 - ETA: 31s - loss: 0.3006 - accuracy: 0.9 - ETA: 31s - - ETA: 29s - loss: 0.2976 - acc - ETA: 28s - loss: 0.2985 - accuracy: 0.929 - ETA: 28s - loss: 0.2 - ETA: 26s - loss: 0.299 - ETA: 25s - loss: - ETA: 20s - loss: 0.3054 - accura - ETA: 20s - loss: 0.3051 - accur - ETA: 19s - loss: 0.3049 - accuracy: 0. - ETA: 19s - loss: 0 - ETA: 17s - loss: 0.3048 - accuracy - ETA: 16s - lo - ETA: 15s - loss: 0.3059 - accuracy: 0.92 - ETA: 14s - loss: 0.3057 - accuracy: 0.926 - ETA: 14s - loss: 0.3060 - accuracy: 0.926 - ETA: 14s - loss: 0.3059 - acc - ETA: 13s - loss: 0.3058 - accuracy: 0.926 - ETA: 13s - loss:  - ETA: 12s - l - ETA: 10s - loss: 0.3063 - accuracy: 0. - ETA: 10s - loss: 0. - ETA: 9s - ETA: 2s - loss: 0.3076 - ac - ETA: 1s - loss: 0.308 - ETA: 1s - loss: 0.3 - ETA: 0s - loss: 0.3085 \n",
      "Epoch 00060: val_accuracy did not improve from 0.88430\n",
      "781/781 [==============================] - 56s 72ms/step - loss: 0.3086 - accuracy: 0.9253 - val_loss: 0.5057 - val_accuracy: 0.8764\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "781/781 [==============================] - ETA: 0s - loss: 0.3056 - accuracy: 0.9264 - ETA: 49s - loss: 0.2988 - accuracy: -  - ETA: 46 - ETA: 41s - loss: 0.3026 - accuracy: 0 - ETA: 41s - loss: 0.3018 - accurac - ETA: 40s - loss: 0.2 - ETA: 39s - loss: 0.2976 -  - ETA: 38s - loss: 0.2968 - accuracy: 0.9 - ETA: 37s - loss: 0.2970 - accuracy: 0 - ETA: 37s - loss: 0.2958 - accu - ETA: 36s -  - ETA: 34s - loss: 0.2971 - acc - ETA: 33s - loss: 0.2981 - accuracy: 0 - ETA: 33s - loss: 0.2986 - accuracy: 0.928 - ETA: 33s - loss: 0.2987 - a - ETA: 32s - loss: 0.2981 - accur - ETA: 31s - loss: 0.2979 - accuracy: 0.92 - ETA: 31s - loss: 0.2981 - accur - ETA: 30s - loss: 0.2980 - accuracy: 0.9 - ETA: 30s - loss: 0.2979 - accuracy - ETA: 30s - loss: 0.2976 - accuracy: 0 - ETA: 29s - loss: 0.2978 - accuracy: 0.92 - ETA: 29s - - ETA: 27s - loss: 0.2965 - accur - ETA: 23s - loss - ETA: 22s - loss: 0.2987 - accuracy: 0.92 - ETA: 21s - loss: 0.2991 - accu - ETA: 21s - loss: 0.2983 - acc - ETA: 20s - loss: 0.2998 - accuracy: 0 - ETA: 19s - loss: 0.3008 - accuracy: 0.92 - ETA: 19s - loss: 0.3008 - accu - ETA: 19s - loss: 0.3010 - accuracy: 0.9 - ETA: 18s - loss: 0.3010 - a - ETA: 17s - loss: 0.3012 - accuracy: 0. - ETA: 17s - loss: 0.30 - ETA: 13s - loss: 0.3 - ETA: 11s - loss: 0.301 - ETA: 10s - loss: 0.3031 - accuracy -  - ETA: 2s - loss: 0.3047 - accuracy - ETA: 1s - loss: 0 - ETA: 0s - loss: 0.3055 - ac\n",
      "Epoch 00061: val_accuracy did not improve from 0.88430\n",
      "781/781 [==============================] - 56s 71ms/step - loss: 0.3056 - accuracy: 0.9264 - val_loss: 0.5209 - val_accuracy: 0.8773\n",
      "Epoch 62/100\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.3021 - accuracy: 0.9289 - ETA: 47s - loss: 0.3099  - ETA: 46s - loss: 0.3165 - a - ETA: 44s - loss: 0.3133 - accu - ETA: 43s - loss: 0.3133  - ETA: 42s - loss: 0.3092 - acc - ETA: 41s - loss: 0.3101 - accuracy: - ETA: 38s -  - ETA: 36s - loss: 0.3043 - accurac - ETA: 35s - - ETA: 30s  - ETA: 28s - loss: 0.3020 - accuracy:  -  - ETA: 25s - loss: 0.3033 - accura - ETA: 24s - l - ETA: 22s - loss: 0. - ETA: 21s - loss: 0. - ETA: 19s - loss: 0.3031 - accuracy: 0. - ETA: 19s - loss: 0.3027 - ETA: 18s - loss: 0.3023 - accurac - ETA: 17s -  - ETA: 15s - loss: 0.3019 - accuracy: 0.928 - ETA: 15s - loss: 0.3018 - accuracy: 0.9 - ETA: 15s - loss: 0.3022 - accuracy: 0.928 - ETA: 15 - ETA: 13s - loss - ETA: 9s - loss: 0.304 - ETA: 5s - loss: 0.3027  - ETA: 5s - loss: 0.3028 -  - ETA: 3s - loss: - ETA: 0s - loss: 0.3021 - accuracy:  - ETA: 0s - loss: 0.3\n",
      "Epoch 00062: val_accuracy did not improve from 0.88430\n",
      "781/781 [==============================] - 56s 71ms/step - loss: 0.3021 - accuracy: 0.9289 - val_loss: 0.5156 - val_accuracy: 0.8710\n",
      "Epoch 63/100\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.3059 - accuracy: 0.9268 - ETA: 48s - loss: 0.2608 - accuracy:  - ETA: 48s - loss: - ETA: 47s - loss:  - ETA: 46s - loss: 0.2873 - - ETA: 44s - loss: 0.2971 - accuracy - ETA: 44s - loss: 0.2971 - accu - ETA: 41s - loss: 0.3031 - accuracy: 0. - ETA: 40s - loss: 0.3029 - accuracy: 0.92 - ETA: 40s - loss - ETA: 38 - ETA: 36s - loss: 0.3019 - accuracy: 0 - ETA: 36s - loss: 0.3021 - accuracy: 0.927 - ETA: 36s - loss - ETA: 34s - loss: 0.3007 - accura - ETA: 34s - loss: 0.3011 - a - ETA: 33s - loss: 0 - ETA: 31s - loss: 0.3023 - accuracy - ETA: 30s - loss: 0.3027 - accuracy: - ETA: 30s - loss: 0.3025 - accuracy: - ETA: 30s - loss:  - ETA: 28s - loss: 0.3040 - accur - ETA: 27s - loss: 0.302 - ETA: 26s - loss: 0.3035 - accuracy: 0.9 - ETA: 26s - loss: 0.3032 - accuracy: 0.926 - ETA: 26s - loss: 0.303 - ETA: 25s - loss: 0.3023 - accuracy: 0.92 - ETA: 24s - loss: 0.3021 - accurac - ETA: 24s - loss: 0.3025 - accuracy: 0 - ETA: 23s - loss: 0.3 - ETA: 22s - loss: 0.3035 - accuracy:  - ETA: 22s - loss: 0.3034 - ac - ETA: 21s - loss: 0.3033 - ac - ETA: 20s - loss: 0.3051 - accurac - ETA: 19s - loss: 0.3 - ETA: 18s - loss: 0.3049 - ac - ETA: 17s - loss: 0.30 - ETA: 16s - loss: 0.304 - ETA: 14s - loss: 0.3039 - accuracy - ETA: 14s - loss: 0.3034 - accuracy:  - ETA: 13s - loss: 0.3038 - accuracy: 0.92 - ETA: 13s - loss: 0.3039  - ETA: 12s - ETA: 10s - loss: 0. - ETA: 9s - loss: 0 - ETA: 8s - los - ETA: 3s - los - ETA: 2s - loss: 0.3057 - ac - ETA: 1s - loss: 0 - ETA: 1s - loss: 0.3061 -  - ETA: 0s - loss: 0.306\n",
      "Epoch 00063: val_accuracy did not improve from 0.88430\n",
      "781/781 [==============================] - 56s 72ms/step - loss: 0.3059 - accuracy: 0.9268 - val_loss: 0.5003 - val_accuracy: 0.8827\n",
      "Epoch 64/100\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.3062 - accuracy: 0.9260 - ETA: 49s - loss: 0.2440 - accura - ETA: 46s - loss: 0.2936 - accura - ETA: 45s - loss: 0.2939 - acc - ETA: 44s - l - ETA: 42s - loss: 0.2946 - accu - ETA: 42s - - ETA: 40s - loss: 0.2974 - ETA: 39s - loss: 0.2979 - accuracy: 0.9 - ETA: 38s - loss: 0.2985 - accura - ETA: 38s - loss: 0.2990 - acc - ETA: 37s - loss: 0.2998 - accu - ETA: 36s - loss: 0.3016 - accuracy - ETA: 36s  - E - ETA: 31s - loss: 0.3039 - accu - ETA: 30s - loss: 0.3039 - accura - ETA: 29s - loss: 0.3038 - accuracy: 0. - ETA: 23s - loss: 0.3045 - - ETA: 22s - loss: 0.3045 - accuracy: 0.92 - ETA: 22s - loss: 0.3047 - ac - ETA: 21s - loss: 0.3042 - accu - - ETA: 14s - loss: 0.3051 - accuracy: 0 - ETA: 14s - loss: 0.3052 - accura - ETA: 13s - loss: 0.3056 - ac - ETA: 13s - loss: 0.3058 - accuracy: 0.92 - ETA: 12s - loss: 0.3056 - accuracy: 0. - ETA: 12s - lo - ETA: 7s - ETA: 2s - loss: 0.3058 - accuracy:  - ETA: 1s - loss: - ETA: 0s - loss: 0.3 - ETA: 0s - loss: 0.3060 - accuracy\n",
      "Epoch 00064: val_accuracy did not improve from 0.88430\n",
      "781/781 [==============================] - 56s 72ms/step - loss: 0.3062 - accuracy: 0.9260 - val_loss: 0.4903 - val_accuracy: 0.8821\n",
      "Epoch 65/100\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.3032 - accuracy: 0.9268 - ETA: 49s - loss: 0. - ETA: 48s - loss:  - ETA: 46s - loss: 0.3081 - accuracy: 0.922 - ETA: 46s - loss: 0.3078 - accuracy: 0 - ETA: 46s - loss: 0.305 - ETA: 45s - loss: 0.3012 - a - ETA: 44s - loss: 0.2989 - accuracy:  - ETA: 43s - loss: 0.2984 - accura - ETA: 43s  - ETA: 41s - loss: 0.3044  - ETA: 39s - loss:  - ETA: 38s - loss: 0.3030 - accuracy: - ETA: 37s - loss: 0.3014 - acc - ETA: 36s - loss: 0.3002 - accuracy -  - ETA: 33s - loss: 0.2985 -  - ETA: 32s - loss: 0.2976 - accuracy:  - ETA: 32s - loss: 0.2992 - accu - ETA: 31s - loss: 0.2981 - accuracy: 0.928 - ETA: 31s - loss: 0.2981 - accur - ETA: 30s - loss: 0.2977 - accura - ETA: 30s - loss: 0.2975 - accura - ETA: 29s - loss: 0.2967 - ETA: 28s - loss: 0.2967 - accuracy: 0.929 - ETA: 28s - loss: 0.2964 - accuracy: - ETA: 27s - loss: 0.2968 - accuracy: - ETA: 27s - loss: 0.2973 - accurac - ETA: 26s - loss: 0.297 - ETA: 25s - loss: 0.2983 - accuracy - ETA: 24 - ETA: 22s - ETA: 20s - loss: 0.3018 - accura - ETA: 19s - loss: 0.3019 - accuracy: 0.927 - ETA: 19 - ETA: 17s - loss: 0.3012 - accuracy - ETA: 16s - loss: 0.30 - ETA: 12s - loss: 0.3029 -  - ETA: 11s - loss:  - ETA: 8s - loss: 0 - ETA:  - ETA: 6s - loss: 0.3035 - accuracy:  - ETA: 6s - loss: 0.3036 - accura - ETA: 6s - l - ETA: 3s - loss: 0.3040 - accuracy: 0. - ETA: 2s - loss: 0.3036 - accuracy - - ETA: 0s - loss: 0.3039 - accuracy:  - ETA: 0s - loss: 0.3036 - accuracy: 0. - ETA: 0s - loss: 0.3034 - accuracy\n",
      "Epoch 00065: val_accuracy did not improve from 0.88430\n",
      "781/781 [==============================] - 55s 70ms/step - loss: 0.3032 - accuracy: 0.9268 - val_loss: 0.5322 - val_accuracy: 0.8768\n",
      "Epoch 66/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "781/781 [==============================] - ETA: 0s - loss: 0.3040 - accuracy: 0.9269 - ETA: 49s - loss: 0.294 - ETA: 48s - loss: 0.2888 - accuracy: 0. - ETA: 47s - loss: 0.2942 - accuracy - ETA: 47s - loss: 0.3043 - accuracy:  - ETA: 46s - loss: 0.2997 - accu - ETA: 45s - l - ETA: 43s - loss: 0.2998 - - ETA: 42s - loss: 0.3014 - ac - ETA: 41s - loss: 0.2993 - accura - ETA: 41s - loss: 0.2948 - accuracy:  - ETA: 40s - loss: 0.2955 - accuracy: 0.92 - ETA - ETA: 38s - loss: 0 - ETA: 36s - lo - ETA: 34s - loss: 0.2987 - accuracy:  - ETA: 34s - loss: 0.2973 - ETA: 30s - loss: 0.2988 - accuracy: 0.92 - ETA: 30s - loss: 0.2988 - ac - ETA: 29s - loss: 0.2997 - accuracy: 0.9 - ETA: 29s - loss: 0.3010 - accuracy: 0.92 - ETA: 28s - loss: 0.3014 - accuracy:  - ETA: 28s - loss: 0.3014 - a - ETA: 27s - loss: 0.3003 - accuracy: - ETA: 27s - loss: 0.2994 - accu - ETA: 26s - loss: 0.29 - ETA: 24s - loss: 0.2993 - - ETA: 23s - loss: 0.2995 - accuracy: - ETA: 23s - los - ETA: 21s - loss: 0.3029 - accuracy - ETA: 21s - loss: 0.3035 - accu - ETA: 20s - loss: 0.3024 - accu - ETA: 19s - loss: 0.3029 - accuracy: - ETA: 19s - loss: - ETA: 17s - loss: 0.3020 - a - ETA: 16s - loss: 0. - ETA: 15s - loss: 0.3028 - a - ETA: 14s - loss: 0. - ETA: 8s - ETA: 7s - loss: 0.3038 - accuracy: 0. - ETA: 7s - loss: 0.3037 - accuracy:  - ETA: 6s - loss: 0.3039  - ETA: 6s - loss: 0.3043 - accura - ETA: 6s - loss: 0.3039  - ETA: 5s - loss: 0.3033 - accuracy - ETA:  - ETA\n",
      "Epoch 00066: val_accuracy improved from 0.88430 to 0.88680, saving model to my_best_model.epoch66-accuracy0.89.hdf5\n",
      "781/781 [==============================] - 55s 71ms/step - loss: 0.3040 - accuracy: 0.9269 - val_loss: 0.4732 - val_accuracy: 0.8868\n",
      "Epoch 67/100\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.3019 - accuracy: 0.9278 - ETA: 46s - loss: 0.2951 - ac - ETA: 45s - loss: 0.2919 - accuracy: - ETA: 45s - loss:  - ETA: 43s - loss: 0.2940 - accuracy:  - ETA: 43s - loss: 0.2946 - accuracy: 0.932 - ETA: 43s - loss: 0.2942 - accurac - ETA: 42s - loss: 0.2939 - accuracy: 0.9 - ETA: 42s - loss: 0.2958 - a - ETA: 41s - loss: 0.2 - ETA: 40s - lo - ETA: 38s - ETA: 36s - loss: 0.2931 -  - ETA: 35s - l - ETA: 33s - loss: 0.2957 - accurac - ETA: 32s - loss: 0.2961 - accuracy: 0.9 - ETA:  - ETA: 30s - loss: 0.2981 - accuracy - ETA: 29s - loss: 0.2982 - accur - ETA: 28s - loss: 0.2980 - accuracy: 0.929 - ETA: 28s - loss: 0.2982 - accuracy - ETA: 28s - loss: 0.2971 - - ETA: 27s - loss: 0.2993 - accurac - ETA: 26s - loss: - ETA: 25s - loss: 0.3023 - accuracy: 0.9 - ETA: 24s - loss: 0.3023  - ETA: 23s - loss: 0.3014 - accu - ETA: 22s - loss: 0.3022 - ETA: 21s - loss: 0.3016 - accura - ETA: 21s - loss: 0 - ETA: 19s - loss: 0.302 - ETA: 18s - loss - ETA: 16s - loss: 0.3043 - accur - ETA: 15s - loss: - ETA: 14s - lo - ETA: 12s - los - ETA: 10s - loss: 0.3021 - accuracy: - ETA: 9s - loss: 0.3 - - - ETA: 2s - loss: 0.3026 - accuracy: 0.92 - ETA - ETA: 0s - loss: 0.3024 - accura - ETA: 0s - loss: 0.3022 - ac\n",
      "Epoch 00067: val_accuracy improved from 0.88680 to 0.89220, saving model to my_best_model.epoch67-accuracy0.89.hdf5\n",
      "781/781 [==============================] - 56s 71ms/step - loss: 0.3019 - accuracy: 0.9278 - val_loss: 0.4415 - val_accuracy: 0.8922\n",
      "Epoch 68/100\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.3045 - accuracy: 0.9274 - ETA: 45s - loss: 0.3031 - acc - - ETA: 41s - loss: 0.2954 - acc - ETA: - ETA: 38s - loss: 0.2957 - accur - ETA: 37s - loss: 0.2955 - accurac - ETA: 34s - loss:  - ETA: 32s - loss: 0.2977 - accuracy: 0.929 - ETA: 32s - loss: 0.2 - ETA: 30s - loss: 0.2962  - ETA: 29s - loss: 0.2986 - ac - ETA: 28s  - ETA: 23s - loss: - ETA: 22s - loss: 0.3014 -  - ETA: 21s - loss: 0.3023 - accuracy - ETA: 20s - loss: 0.3032 - accurac - ETA: 20s - loss: 0.3028 - accuracy: 0.92 - ETA: 19s - loss: 0.3026 - accur - ETA: 19s - loss: 0.3023 - accuracy: 0.927 - ETA: 19s - loss: 0.3022 - accuracy: 0.927 - ETA: 19s - loss: 0.3021 -  - ETA: 15s - loss: 0.3025 - accuracy:  - ETA: 14s - loss: 0.3025 - accurac - ETA: 14s - loss: 0.3021 - ETA: 12s - loss: 0.302 - ETA: - E - - ETA: 1s - loss: 0.304 - ETA: 0s - loss: 0.3045 - accu\n",
      "Epoch 00068: val_accuracy did not improve from 0.89220\n",
      "781/781 [==============================] - 56s 71ms/step - loss: 0.3045 - accuracy: 0.9274 - val_loss: 0.5020 - val_accuracy: 0.8842\n",
      "Epoch 69/100\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.3018 - accuracy: 0.9274 - ETA: 49s - loss: 0.3057 - accurac - ETA: 49s - loss: 0.3084 - ac - ETA: 45s - loss: 0.3019 - accura - ETA:  - ETA: 42s - loss: 0.2951 - accuracy: 0. - ETA: 42s - loss: 0.2950 - acc - ETA: 41s - loss: 0.2936 - accuracy: 0.93 - ETA: 41s - loss: 0.2 - ETA: 39s - loss: 0. - ETA: 38s - loss: 0 - ETA: 36s - loss: 0.2961 - a - ETA: 23s - loss: 0.3004 - accuracy:  - ETA: 23s - loss: 0.3010 - accuracy: 0.928  - ETA: 20s - loss: 0.3020 - ETA: 19s - loss: 0.3028  - ETA: 18s - loss: 0.3034 - acc - ETA: 14s - loss: 0.3036 - a - ETA - ETA: 10s - loss: 0.3032 - accuracy: 0.92 - ET - E - ETA: 0s - loss: 0.3019 - accuracy\n",
      "Epoch 00069: val_accuracy did not improve from 0.89220\n",
      "781/781 [==============================] - 57s 72ms/step - loss: 0.3018 - accuracy: 0.9274 - val_loss: 0.4811 - val_accuracy: 0.8816\n",
      "Epoch 70/100\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.3013 - accuracy: 0.9270 - ETA: 42s - loss: 0.2982 - accuracy: 0.92 - ETA: 42s - - ETA: 37s - loss: 0.2951 - - ETA: 35s - loss: 0.2951 - accurac - ETA: 35s - loss: 0.2950 - accuracy:  - ETA: 34s - loss: 0.2942 - a - ETA: 33s - loss: 0.2949 - accuracy: 0.928 - ETA: 33s - loss: 0.2948 - accuracy:  - ETA: 33s - loss: 0.2947 - accur - ETA: 32s - loss: 0.2953 - accu - ETA: 31s - loss: 0.2945 - ac - ETA: 30s - ETA: 19s - loss - ETA: 18s - loss: 0.3001 - ETA: 16s - loss: 0.3001 - - ETA: 9s - loss: 0.2996 - accu - - ETA: 8s - loss: - ETA: 7s - l - ETA: 1s - loss: 0.3015 - accuracy: 0.92 - ETA: 1s - loss: 0.3016 - accu\n",
      "Epoch 00070: val_accuracy did not improve from 0.89220\n",
      "781/781 [==============================] - 56s 72ms/step - loss: 0.3013 - accuracy: 0.9270 - val_loss: 0.5586 - val_accuracy: 0.8691\n",
      "Epoch 71/100\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.3023 - accuracy: 0.9280 - ETA: 49s - loss: 0.3204 - ETA: 49s - loss: 0.3100 - accuracy: 0 - ETA: 48s - loss: 0.3008 - accur - ETA: 48s - loss: 0.2987 - accuracy: 0.93 - ETA: 48s - loss: 0.30 - ETA: 4 - ETA: 44s - loss: 0.3041 - accuracy: 0.92 -  - ETA: 41s - lo - ETA: 39s - loss: 0.2948 - accuracy: 0 - ETA: 39s - loss:  - ETA: 37s - loss: 0.2950 - accuracy: 0.931 - ETA: 37s - loss: 0.2947 - accuracy: 0.9 - ETA: 37s - loss: 0.2954 - accuracy - ETA: 36s - loss: - ETA: 35s - loss: 0.2924 - accu - ETA: 31s - loss: 0.295 - - ETA: 27s - loss: 0.2955 - accuracy: 0.93 - ETA: 27s - loss: 0.2957 - acc - ETA: 26s - loss: 0.2975 - accuracy: 0 - ETA: 25s - loss: 0.2975 - accuracy: 0. - ETA: 25s - loss: 0.2 - ETA: 24s - loss: 0.2975 - accuracy: 0. - ETA: 23 - ETA: 15s - loss: - ETA: 14s - loss: 0.3003 - - ETA: 12s - loss: 0.2994 - accuracy: 0. - ETA: 12s  - ETA: 4s - ETA: 1s - loss: 0.3009 - accu\n",
      "Epoch 00071: val_accuracy did not improve from 0.89220\n",
      "781/781 [==============================] - 56s 72ms/step - loss: 0.3023 - accuracy: 0.9280 - val_loss: 0.6214 - val_accuracy: 0.8505\n",
      "Epoch 72/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "781/781 [==============================] - ETA: 0s - loss: 0.2979 - accuracy: 0.9287 - ETA: 47s - loss: 0.2838 -  - ETA: 47s - loss: 0.2713 - a - ETA: 46s - loss: 0.2770 - ac - ETA: 45s - loss: 0.2827 - acc - ETA: 44s - los - ETA: 37s - loss: 0.2878 - accuracy: 0.9 - ETA: 36s - loss: 0.2875  - ETA: 35s - loss: 0.2882 - accuracy - ETA: 35s - - ETA - ETA: 30s - ETA: 28s - loss: 0.2896 - accu - ETA: 27s - loss: 0.290 - ETA: 26s - loss: 0.2914 - accuracy - ETA: 25s - loss: 0.2913 - accuracy: 0.93 - ETA: 25s - loss: 0.2915 - accuracy: - ETA: 25s - loss: 0.2913 - accuracy: 0.931 - ETA: 25s - loss: 0.2914 - accuracy: 0. - ETA: 24s - loss: 0.2923 - accur - ETA: 24s - loss: 0.2922 - ac - ETA: 23s - loss: 0.2927 - accuracy: 0.930 - ETA: 23s - loss: 0.2926 - accuracy: - ETA: 19s - loss: 0.2941 - accur - ETA: 18s - loss: 0.2941 - accuracy: 0.93 - ETA: 18s - loss: 0.2949 - accuracy: 0.929 - ETA: 18s - loss: 0.2950 - acc - ETA: 17s - loss: 0.2954 - accuracy: - ETA: 17s - loss: 0.2951 -  - ETA: 16s - - ETA: 14s - loss: 0.2965 - accuracy: 0.9 - ETA: 14s - loss: 0.2965 - accuracy: 0 - ETA: 13s - loss: 0.2962 - accuracy: 0 - ETA: 13s - loss: 0.2959 - - ETA: 12s - loss: 0.2955 - accuracy: 0.929 - ETA: 12s - loss: 0.2957  - ET - ETA: 6s - los - ETA: 3s - loss: 0 - ETA: 3s - loss: 0 - ETA: 2s - loss: 0.2982 - accu - ETA: 0s - loss: 0.2985 - \n",
      "Epoch 00072: val_accuracy did not improve from 0.89220\n",
      "781/781 [==============================] - 56s 71ms/step - loss: 0.2979 - accuracy: 0.9287 - val_loss: 0.5036 - val_accuracy: 0.8785\n",
      "Epoch 73/100\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.2978 - accuracy: 0.9295 - ETA: 48s - - - ETA: 44s -  - ETA: 42 - ETA: 40s - loss - ETA: 39s - loss: 0.2808 -  - ETA: 38s - loss: 0.2821 - accurac - ETA: 37s - loss: 0.2835 - - ETA: 36s - loss: 0.2840 - accuracy: 0.932 - ETA: 36s - loss: 0.2837 - accuracy: 0.9 - ETA: 36s - loss: 0.2844 - accuracy: 0. - ETA: 36s - - ETA: 30 - ETA: 28s - loss: 0.2911 - - ETA: 27s - loss: 0.2925 - accuracy: - ETA: 27s - lo - ETA: 25s - loss: 0.2954 - accu - ETA: 24s - loss: 0.2951 - accuracy: 0 - ETA: 24s - loss: 0.2945 - accuracy: 0.930 - ETA: 24s - loss: 0.2945 - accuracy: 0.930 - ETA: 24s - loss: 0.2949 - - ETA: 20s - loss: 0.2957 - accuracy - ETA: 19s - loss: 0.2951 - accu - ETA: 18s - loss: 0.2964 - accuracy: 0 - ETA: 15s - loss: 0.2966 - accuracy: 0 - ETA: 15s - loss: 0. - ETA: 13s - lo - ETA: 7s - loss: 0 - ETA: 7s - loss: 0.2983 - accu - ETA - ETA\n",
      "Epoch 00073: val_accuracy did not improve from 0.89220\n",
      "781/781 [==============================] - 56s 72ms/step - loss: 0.2978 - accuracy: 0.9295 - val_loss: 0.5740 - val_accuracy: 0.8603\n",
      "Epoch 74/100\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.3032 - accuracy: 0.9269 - ETA: 47s - loss: 0.2889 - - ETA: 46s - loss: 0.2889 - accuracy: - ETA: 45s - ETA: 43s - loss: 0.2889  - ETA: 42s - - ETA: 40s - loss: 0.29 - ETA: 39s - loss: 0.2959 - accuracy: 0. - ETA: 38s - loss: 0.2975 - accuracy: 0 - ETA: 38s - loss: 0.2963 - accuracy: 0.93 - ETA: 38s - loss: 0.2 - ETA: 37s - loss: 0.2959 - acc - ETA: 36s - loss: 0. - ETA: 34s - loss: 0.2963 - accuracy:  - ETA: 34s - loss: 0.2955 - accuracy: 0.931 - ETA: 34s - loss: 0.2957 - accurac - ETA: 33s - loss: 0.2953 - acc - ETA: 32s - loss: 0.2958 - accuracy: - ETA: 32s - loss: 0.2951 - accuracy: - ETA: 31s - loss: 0.2952 - ac - ETA: 30s - loss: 0.2940 - a - ETA: 29s - loss: 0.2947 - accuracy: 0 - ETA: 29s - loss: 0.2944 - accuracy: 0.93 - ETA: 29s - loss: 0.2941 - ETA: 28s - loss:  - ETA: 23s - loss: 0.2954  - ETA: 22s - loss: 0.2975 - accurac - ETA: 21s - loss: 0.2969 - accuracy: 0.9 - ETA: 21s  - ETA: 5s - loss: 0.3027 - accura - E\n",
      "Epoch 00074: val_accuracy did not improve from 0.89220\n",
      "781/781 [==============================] - 56s 71ms/step - loss: 0.3032 - accuracy: 0.9269 - val_loss: 0.4723 - val_accuracy: 0.8890\n",
      "Epoch 75/100\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.2983 - accuracy: 0.9284 - ETA: 49s - loss: 0.2802 - accuracy: 0. - ETA: 49s - loss: 0 - ETA: 4 - ETA: 45s - loss: 0.2893 - acc - ETA: 39s - loss: 0.2964 - accuracy:  - ETA: 38s - loss: 0.2943 - - ETA - ETA: 29s - loss: 0.29 - ETA: 25s - loss: 0.2926 - accuracy: 0.9 - ETA: 24s - loss: 0.2925  - ETA: 23s - loss: 0.2946 - accura - ETA: 22s - loss: 0.2950 - accuracy:  - ETA: 22s - loss: 0.2960 - accuracy: 0.92 - ETA: 22s - loss: 0.2963 - - ETA: 21s - loss: 0.2953 - accuracy - ETA: 20s - loss: 0.2955 - a - ETA: 19s - loss: 0.2953 - ETA: 18s - loss: 0.2958 - accuracy: 0.928 - ETA: 18s - loss: 0.2956 - accuracy: 0 - ETA: 18s - loss: 0.2955 -  - ETA: 17s - loss: 0.2945 - - ETA: 10s - loss: 0.2964 - accuracy: 0. - ETA: 9s - loss: 0.2963 - accuracy:  - ETA: 9s - loss: 0 - ETA: 8s - loss: 0.2960 - accuracy: 0.92 - ETA: 8s - los - ETA: 7s - loss: 0.2960 -  - ETA: 0s - loss: 0.2981 - accuracy - ETA: 0s - loss: 0.2984 - accuracy: 0.9284\n",
      "Epoch 00075: val_accuracy did not improve from 0.89220\n",
      "781/781 [==============================] - 56s 72ms/step - loss: 0.2984 - accuracy: 0.9284 - val_loss: 0.5708 - val_accuracy: 0.8643\n",
      "Epoch 76/100\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.2920 - accuracy: 0.9308 - ETA: 49s - loss: 0.2867 - acc - ETA: 48s - loss: 0.2777 - accuracy: 0.935 - ETA: 48s - loss: 0.2788 - accu - ETA: 47s - loss - ETA: 42 - ETA: 40s - loss: 0.2906 - accuracy: - ETA: 36s - loss: 0.2873 - accuracy:  - ETA: 36s - loss: 0.2872 - accur - ETA: 35s - ETA: 33s - loss: 0.2880 - accuracy: 0. - ETA: 33s - loss: 0.2888 - accuracy:  - ETA: 32s - loss: 0.2884 - accuracy: 0.9 - ETA: 32s - loss: 0.2883 - accuracy: 0. - ETA: 32s - los - ETA: 30s - loss: 0.2880 - ETA: 29s - loss: 0.2873 - accu - ETA: 28s - loss: 0.2881 - ETA: 27s - loss: 0.2876 - accuracy: 0.931 - ETA: 27s - loss: 0.2 - ETA: 25s - loss: 0.2861  - ETA: 2 - ETA: 22s - loss: 0.2892 - accuracy: 0.9 - ETA: 21s - loss: 0.2899 - accuracy: 0.9 - ETA: 21s - loss: 0.28 - ETA: 20s - loss: 0.2895 -  - ETA: 19s -  - ETA: 17s - loss: 0.290 - ETA: 15s - loss: 0.2912  - ETA: 14s - loss: 0.2904 - accuracy: - ETA: 14s - loss: 0.2904 - a - ETA: 13s - loss: 0.2901 - accuracy: 0.93 - ETA: 13s - loss: 0.2900 - acc - ETA: 12s - loss: 0.2898 - accuracy: 0.9 - ETA: 12s - loss: 0.2893  - ETA: 10s - loss: 0.2895 - accuracy:  - ETA: 10s - loss: 0.2901 - accuracy: - ETA: 10s - loss: 0.2899 - accura - ETA: 8s - loss: 0.2905 - accuracy: 0.93 - ETA:  - ETA: 7s - loss: 0 - E - ETA: 4s - loss: - ETA: 4s - loss: 0.2904 - ac - - ETA: 0s - loss: 0.2910 -  - ETA: 0s - loss: 0.2914 - accuracy\n",
      "Epoch 00076: val_accuracy did not improve from 0.89220\n",
      "781/781 [==============================] - 56s 72ms/step - loss: 0.2920 - accuracy: 0.9308 - val_loss: 0.5262 - val_accuracy: 0.8729\n",
      "Epoch 77/100\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.2951 - accuracy: 0.93084- ETA: 48s - loss: 0.2719   - ETA: 41s - loss: - ETA: 39s - loss: 0.2844 - a - ETA: 38s - - ETA: 36s - loss: 0.2839 - accuracy: - ETA: 33s - lo - ETA: 28s - loss: 0.2917 - a - ETA: 27s - loss: 0.2916 -  - ETA: 23s - loss: 0.2946 - accura - ETA: 22s - loss: 0.2958 - accuracy: 0 - ETA: 22s - loss: 0.2964 - ac - ETA: 21s - loss: 0.2968 - accurac - ETA: 21s - loss: 0.2970 - accuracy:  - ETA: 20s - loss: 0. - ETA: 19s - loss: 0.2972 - accurac - ETA: 18s - loss: 0.2968 - a - ETA: 17s - loss: 0.2967 - accura - ETA: 1 - ETA: 14s - loss: 0.2943 - accuracy: 0.93 - ETA: 14s - loss: 0.2941 - acc - ETA: 13s - loss: 0.2942 - accur - ETA: 12s - loss: 0.2941 - ETA: 11s - loss: 0.29 - ETA: 10s - loss: 0.2952 - accuracy: 0.9 - ETA: 9s - loss: 0.2952 - accuracy: 0.930 - ETA: 9s - loss: - ETA: 4s - loss: 0.294 - ETA: 3s - loss: 0.2953 - accuracy - ETA: 2s - loss: 0.2950 - ac - ETA: 1s - los - ETA: 0s - loss:\n",
      "Epoch 00077: val_accuracy did not improve from 0.89220\n",
      "781/781 [==============================] - 57s 73ms/step - loss: 0.2951 - accuracy: 0.9308 - val_loss: 0.5373 - val_accuracy: 0.8691\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "781/781 [==============================] - ETA: 0s - loss: 0.2977 - accuracy: 0.9284 - ETA - ETA: 47s - loss: 0.2733 - accu - ETA: 47s - loss: 0.2822 - accuracy: 0.935 - ETA: 47s - loss: 0.2851 - accur - E - ETA: 40s - loss: 0.2842 - accuracy:  - ETA: 40s - loss: 0.2838 - accuracy: - ETA: 39s - loss: 0.2837 - acc - ETA: 38s - loss: 0.2850 - accur - ETA: 38s - loss: 0.2837 - accuracy: 0. - ETA: 37s - loss: 0.2835 - accuracy: 0. - ETA: 37s - loss: 0.2833 - accuracy - ETA: 37s - loss:  - ETA: 35s - lo - ETA: 33s - loss: 0.2876  - ETA: 32s - loss: 0.2882 - ac - ETA: 31s - loss: 0.2894 -  - ETA: 30s - loss: 0.2899  - ETA: 2 - ETA: 23s - loss: 0.2938 - accuracy: 0.92 - ETA: 23s - loss: 0.2939 - accuracy: 0 - ETA: 23s - loss: 0.2938 - accurac - ETA: 22s - loss: 0.2932 - accur - ETA: - ETA: 16s - loss: 0.2949 - ETA: 15s - loss: 0.2946 - accuracy:  - ETA: 14s - loss: 0.2949 - accuracy: 0.9 - ETA: 14s - loss: 0.2949 - acc - ETA: 13s - loss: 0.2950 - accuracy: 0 - ETA: 13s - loss: 0.2950 - ETA: 12s - loss: 0.2954 - accuracy: - ETA: 11s - ETA: \n",
      "Epoch 00078: val_accuracy did not improve from 0.89220\n",
      "781/781 [==============================] - 56s 71ms/step - loss: 0.2977 - accuracy: 0.9284 - val_loss: 0.5207 - val_accuracy: 0.8754\n",
      "Epoch 79/100\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.2972 - accuracy: 0.9288 - ETA: 45s - loss: 0.2913 - accur - ETA: 44s - loss: 0.2928 - accuracy - ETA: 43s - loss: 0.2943 - accuracy: 0.927 - ETA: 43s - loss: 0.2927 -  - ETA: 34s - loss: 0. - ETA: 32s - loss: 0.2953 - accuracy:  - ETA: 32s - loss: 0.2950 - accur - ETA: 31s - loss: 0.29 - ETA: 30s - loss: 0.2965 - accuracy: 0.930 - ETA: 30s - loss: 0.2961 - accuracy: 0. - ETA: 30s - loss - ETA: 28s - loss: 0.2991 - ETA: 27s - loss: 0.2995 - acc - ETA: 26s - loss: 0.2991 - accu - ETA: 25s - loss: 0.2993 - accuracy: 0.92 - ETA: 25s - loss: 0.2993 - ac - ETA: 24s - loss: 0.2988 - accurac - ETA: 23s - loss: 0.2992 - ac - ETA: 23s - loss: 0.2986 - accuracy:   - ETA: 16s - loss: 0.2993 - accuracy: 0.928 - ETA: 16s - loss: 0.2992 - ETA: 15 - ETA: 13s - loss: 0.2982 - accuracy: 0 - ETA: 13s - loss: 0.2976 - accur - ETA: 12s - loss: 0.2986 - accuracy: 0.92 - ETA: 12s - loss: 0.2990 - accuracy: 0.9 - ETA: 11s - ETA: 6s - loss: 0.2985  - ETA: 6s - loss: 0.2989 -  - ETA: 2s - loss: 0.2985 - accuracy - ETA: 2s - - ETA: 1s - loss: - ETA: 0s - loss: 0.2972  - ETA: 0s - loss: 0.2974 - accuracy\n",
      "Epoch 00079: val_accuracy did not improve from 0.89220\n",
      "781/781 [==============================] - 56s 71ms/step - loss: 0.2972 - accuracy: 0.9288 - val_loss: 0.5406 - val_accuracy: 0.8737\n",
      "Epoch 80/100\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.2965 - accuracy: 0.9295 -  - ETA: 48s - loss: 0.2890 - accuracy: 0.9 - ETA: 48s - loss: 0.2930 - accuracy: 0.92 - ETA: 47s - loss: 0.2 - ETA: 46s - loss: 0. - ETA: 44s - loss: 0.2929 - accuracy: 0.9 - ETA: 44s - loss: 0.2907 - accuracy: 0 - ETA: 43s - loss: 0.2923 - accuracy: 0.92 - ETA: 43s - loss: 0.2915 - accuracy:  - ETA: 43s - loss: 0.2923 - accuracy: 0.92 - ETA: 43s - loss: 0.2 - ETA: 41s - loss: 0.2 - ETA: 40s - loss: 0.2951  - ETA: 36s - loss: 0.2939 - accuracy: 0 - ETA: 36s - loss: 0.2957 - accuracy: 0.928 - ETA: 35s - loss: 0.295 - ETA: 34s - loss: 0.2966  - ETA: 33s - loss: 0.2963 - accurac - ETA: 32s - loss: 0.2976 - ac - ETA: 31s - loss: 0.2975 - accur - ETA: 31s - loss: 0.2968 - ac - ETA: 30s - loss: 0.2955 - accuracy: 0.9 - ETA: 30s - loss: 0.2959 - accuracy: 0 - ETA: 29s - l - ETA: 27s - loss: 0.2970 - - ETA: 26s - loss: 0.296 - ETA: 25s - loss: 0.2952 - accu - ETA: 24s - loss: - ETA: 22s - loss: 0.2 - ETA: 18s - loss: 0.2963 -  - ETA: 17s -  - ETA: 15s - loss: 0.2953 - accurac - ETA: 14s - ETA: 12s - loss: 0.2956 - accu - ETA: 11s - loss: 0.29 - ETA:  - ETA: 4s - loss: 0.2956 - accu - ETA: 4s - l - ETA: 3s - loss: 0.2960 - ac - ETA: 2s - loss: 0.2959 - accuracy: 0. - ETA: 2s - loss: 0.2960 - accura - ETA: 2s - loss: 0.2964 - ac - ETA: 0s - loss: 0.2966 - accu\n",
      "Epoch 00080: val_accuracy did not improve from 0.89220\n",
      "781/781 [==============================] - 56s 72ms/step - loss: 0.2965 - accuracy: 0.9295 - val_loss: 0.4556 - val_accuracy: 0.8894\n",
      "Epoch 81/100\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.2976 - accuracy: 0.9275 - ETA: 42s - loss: 0 - ETA: 37s - loss: 0.2877 - accuracy: 0. - ETA: 37s - loss: 0.2879 - accuracy: 0.93 - ETA: 37s - loss: 0.2879 - acc - ETA: 36s - loss:  - ETA: 35s - loss: 0.28 - ETA: 34s - loss: 0.2883 - accuracy: - ETA: 33s - loss: 0.2887 - a - ETA: 32s - lo - ETA: 27s - loss: 0.2913 - accuracy: 0 - ETA: 27s - loss: 0.2909 - ac - ETA: - ETA: 23s - loss: 0.2915 - accuracy: 0.9 - ETA: 23s - loss: 0.2917 - accurac - ETA: 22s - loss: 0.2910 -  - ETA: 21s - loss: 0.2915 - accuracy: 0.9 - ETA: 21s - loss: 0.2914 - accuracy: 0.930 - ETA: 21s - loss: 0.2914 - accuracy: 0.93 - ETA: 21s - loss: 0.2915 - accu - ETA: 20s - loss: 0.2913 - accuracy: 0. - ETA: 20s - loss: 0.2914 - accuracy: - ETA: 19s - loss: 0.2913 - a - ETA: 18s - loss: 0.2919 - accuracy: 0.9 - ETA: 18s - loss: 0.2925 - acc - ETA: 14s - loss: 0.2944 -  - ETA: 13s - loss: - ETA: 12s - ETA: 9s - loss: 0.2943 - ac - ETA: 9s - loss: 0.2937 - accuracy: 0.92 - E - E - ETA: 0s - loss:\n",
      "Epoch 00081: val_accuracy did not improve from 0.89220\n",
      "781/781 [==============================] - 56s 72ms/step - loss: 0.2976 - accuracy: 0.9275 - val_loss: 0.4735 - val_accuracy: 0.8891\n",
      "Epoch 82/100\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.2957 - accuracy: 0.9294 - ETA: 51s - loss: 0.3157 - accuracy - ETA: 49s - loss: 0.2865 - accuracy: 0.928 - ETA: 49s - loss: 0.2866 - accuracy: 0.92 - ETA: 49s - loss: 0.2833 - accuracy:  - ETA: 49s - loss: 0.2746 - accur - ETA: 48s - loss: 0.2791 - accurac - ETA: 47s - loss: 0.2818 -  - ETA: 46s - loss: 0.2735 - accuracy: 0 - ETA: 46s - loss: 0.2736 - accuracy: 0 - ETA: 46s - loss: - ETA: 44s - loss: 0.279 - ETA: 43s - loss: 0.2796 - accura - ETA: 42s - loss: 0.2788 - accuracy: 0.936 - ETA: 42s - loss: 0.2788 - accuracy: 0.93 - ETA: 42s - loss: 0.2780 - accuracy: 0.9 - ETA: 41s - loss: 0.277 - ETA: 40s - loss: 0.2796 - accuracy: 0. - ETA: 40s - loss: 0.2819 - - ETA: 39s - loss: 0.2827 - a - ETA: 38s - loss: 0.2824 - accura - ETA: 37s - loss: 0.2846 - accuracy: 0.9 - ETA: 37s - loss: 0 - ETA: 35s - loss: 0.2850 - a - ETA: 34s - loss: 0.2872 - accuracy: 0.9 - ETA: 34s - lo - ETA: 32s - loss: 0.2880 - accuracy:  - ETA: 32s - loss: 0.2883 - ac - ETA: 31s - loss: 0.2900 - acc - ETA: 30s - loss: 0.2889 -  - ETA: 29s - loss: 0.2892 - accuracy - ETA: 29s - loss: 0.2885 - accuracy:  - ETA: 28s - loss: 0.2883 - accu - ETA: 27s - loss: 0.28 - ETA: 26s - loss: 0.2890 -  - ETA: 25s - loss: 0.2881 - accuracy: 0.931 - ETA: 25s - loss: 0.2883 - accuracy: - ETA: 25s - loss: 0.2881 - accuracy: 0. - ETA: 24s - loss: 0.2881  - ETA: 23s - l -  - ETA: \n",
      "Epoch 00082: val_accuracy did not improve from 0.89220\n",
      "781/781 [==============================] - 56s 72ms/step - loss: 0.2957 - accuracy: 0.9294 - val_loss: 0.4788 - val_accuracy: 0.8820\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "781/781 [==============================] - ETA: 0s - loss: 0.2958 - accuracy: 0.9285 - ETA: 50s - loss: 0.2992 - accuracy: 0.932 - ETA: 50s - loss: 0 - ETA: 49s - ETA: 46s - loss: 0.2863 - ETA: 45s - loss: 0.2946 - - ETA: 44s - loss: 0.2890 - accuracy: 0.93 - ETA - E - ETA: 39s - loss: 0.2891 - - ETA: 37s  - ETA: 35s - loss: 0.2900 - acc - ETA: 34s  - ETA: 27s - loss: 0.2891 - accuracy: 0.93 - ETA: 26s - loss: 0.2894 - accuracy: 0.93 - ETA: 26s - loss: 0.2894 - a - ETA: 25s - loss: 0.2907 - accuracy: 0. - ETA: 25s - loss: 0.2915 - accuracy - ETA: 24s - lo - ETA: 22s - loss: - ETA: 21s - loss: 0.29 - ETA: 19s - loss: 0.2910 - accuracy: 0.9 - ETA: 19s - loss: 0. - ETA: 18s - loss: 0.2904 - accuracy:  - ET - ETA: 15s - loss: 0.2918 - accuracy: 0 - ETA: 14s - loss: 0.2925 - accu - ETA: 14s - loss: 0.2922 - accuracy: 0.930 - ETA: 13s - loss: 0.2923 - a - ETA: 12s - loss: 0.2926 - accurac - ETA: 12s - loss: 0.2925 - accuracy - ETA: 11s - loss: 0.2926 -  - ETA: 10s - loss: 0.2928 - accuracy: - ETA: 10s - loss: 0.2928 - accurac - ETA: 9s - loss: 0.2926  - ETA: 7s - E - ETA: 2s - loss: 0.2936 - accuracy:  - ETA: 2s - loss: 0.2937 - accu - ETA: 1s - loss: 0.2941 - accura - ETA: 1s - loss: 0.2947 - accura - ETA: 1s\n",
      "Epoch 00083: val_accuracy did not improve from 0.89220\n",
      "781/781 [==============================] - 56s 72ms/step - loss: 0.2958 - accuracy: 0.9285 - val_loss: 0.5354 - val_accuracy: 0.8740\n",
      "Epoch 84/100\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.2964 - accuracy: 0.9298 - ETA: 49s - lo - ETA: 47s - loss: 0.3005 - acc - ETA: 47s - loss: 0.3037 - accuracy: 0.9 - ETA: 47s  - ETA: 45s - loss: 0. - ETA: 43s - loss: 0.2990 - accuracy: 0. - ETA: 43s - loss: 0.2971 - accuracy: 0.930 - ETA: 43s - loss: 0.2970 - accuracy: 0.9 - ETA: 43s - loss: 0.2963 - accurac - ETA: 42s - loss: 0.2932 - acc - ETA: 41s - loss: 0.2957 - ac - ETA: 40s - loss: 0.2989 - accuracy - ETA: 40s - loss: 0.2986 - accuracy - ETA: 39s - loss: 0. - ETA: 38s - ETA: 36s - loss: 0.2983 - accurac - - ETA: 32s - loss: 0.2984 - - ETA: 31s - loss: 0.29 - ETA: 30s - loss: 0 - ETA: 28s - loss: 0.2964 - accur - ETA: 27s - loss: 0.2974 - ac - ETA: 26s - loss: 0.2969 - accuracy: 0. - ETA: 26s - loss: 0.2965 - a - ETA: 25s - loss: 0.2968 - accuracy: 0.9 - ETA: 25s - loss - ETA: 23s - loss: 0.2957 - ac - ETA: 22s - loss: 0.2956 - accuracy: 0.92 - ETA: 22s - loss: 0.2956 - accuracy:  - ETA - ETA: 16s - loss: 0.2953 - accuracy: 0.930 - ETA: 16s - loss: 0.2951 - accura - ETA: 16s - loss: 0.2949 -  - ETA: 15s - loss: 0.2938 - accuracy: 0. - ETA: 14s - loss: 0.2938 - acc - ET - ETA: 11s - loss: 0.2949 - accuracy: 0. - ETA: 11s - loss: 0.2952 - ac - ETA: 10s - los - ETA: 9s - loss: 0.2947 - accuracy: 0.93 - ETA: 9s - loss: 0.2947 - accura - ETA: 8s - loss: - ETA: 6s - loss: 0.295 - ETA: 5s - loss: - ETA: 4s - loss: 0.2945 - accuracy:  - ETA: 4s - loss: 0.2945 - accu - E - ETA: 3s - loss: 0 - ETA: 2s - loss: 0.2951 - accu - ETA: 1s - loss: 0.2954 -  - ETA: 1s - loss: 0.2958 - accuracy - ETA: 1s - loss: 0.2959 - accuracy - ETA: 0s - loss: 0\n",
      "Epoch 00084: val_accuracy did not improve from 0.89220\n",
      "781/781 [==============================] - 56s 72ms/step - loss: 0.2964 - accuracy: 0.9298 - val_loss: 0.5126 - val_accuracy: 0.8801\n",
      "Epoch 85/100\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.2888 - accuracy: 0.9329 - ET - ETA: 42s - loss: 0.2851 -  - ETA: 41s - loss: 0.2853 - accuracy: 0.932 - ETA: 41s - loss: 0.2849 - accura - ETA: 40s - loss: 0.2866 - accuracy: 0. - ETA: 40s - loss: 0.2869 - accuracy: 0. - ETA: 40s - loss: 0.2866 - accuracy: 0 - ETA: 39s - loss: 0.2868 - accuracy: 0.93 - ETA: 39s - loss: 0.2868 - accuracy: - ETA: 39s - los - ETA: 37s - loss: 0.2846 - accuracy: 0.9 - ETA: 37s - loss: 0.2842 -  - ETA: 33s - loss: 0. - ETA: 31s - loss: 0.2834 - accuracy: 0.934 - ETA: 31s - loss: 0.2831 - accuracy: 0. - ETA: 31s - loss: 0.2822 - accuracy: 0 - ETA: 30s - loss: 0.2828 - accuracy: 0 - ETA: 30s - loss: 0.2833 - accuracy - ETA: 30s - - ETA: 27s - loss: 0.2827 - accuracy: 0 - ETA: 27s - loss: 0.2832 - acc - ETA: 26s - loss: 0.2833 - accur - ETA: 26s - loss: 0.2831 - accuracy - ETA: 25s - loss: 0.2827 - accur - ETA: 24s - loss: 0.2834 - accura  - ETA: 18s - loss: 0.2847 - accuracy:  - ETA: 17s - loss: 0.285 - ETA: 13s - loss: 0.2865 - accuracy:  - ETA: 13s - loss: 0.2863 - acc - ETA: 12s - loss: 0.2870 - accuracy: 0.93 - ETA: 12s - loss: 0.2869 - accuracy: 0.933 - ETA: 12s - loss: 0.2868 - accuracy:  - ETA: 11s - loss - ETA: 8s - loss: 0.2879 - accura - ETA: 8s - loss: - ETA: 7s - loss: - ETA: 0s - loss: 0.2\n",
      "Epoch 00085: val_accuracy did not improve from 0.89220\n",
      "781/781 [==============================] - 56s 72ms/step - loss: 0.2888 - accuracy: 0.9329 - val_loss: 0.4807 - val_accuracy: 0.8831\n",
      "Epoch 86/100\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.2919 - accuracy: 0.9304 - ETA: 50s - loss: 0.2876 - accuracy:  - ETA: 50s - loss: 0.2861 - accuracy - ETA: 49s - loss: 0.2898 - accura - ETA: 48s - loss: 0.2843 - accu - ETA: 47s - loss: 0.2849 - accuracy:  - ETA: 44s - loss: 0.2909 - accuracy: 0.928 - ETA: 44s - loss: 0.2914 - accuracy: 0. - ETA: 43s - loss: 0.2932 - a - ETA: 42s - loss: 0.2911 - accuracy: - ETA: 42s - loss: 0.2897 - accura - ETA: 41s - loss: 0.2904 - accuracy: 0. - ETA: 41s - loss: 0.2903 - accuracy: 0.928 - ETA: 41s - loss: 0.2899 - accuracy: 0.92 - ETA: 41s - loss: 0.2904 - accuracy - ETA:  - ETA: 38s - loss: 0.2889 - accuracy: 0.928 - ETA: 38s - loss - ETA: 36s - loss: 0.2883 - accuracy: 0 - ETA: 35s - lo - ETA: 3 - ETA: 31s - - ETA: 26s - loss: 0.2892 - accuracy: 0 - ETA: - ETA: 23s - l - ETA: 21s - loss: 0.2891 - accuracy: 0 - ETA: 21s - loss: 0.2887 - accuracy: 0.93 - ETA: 21s - loss: 0.2889 - accuracy:  - ETA: 21 - ETA: 18s - loss: 0.2913 - acc - ETA: 17s - loss - ETA: 7s - loss: 0 - ETA: 6s - los - ETA: 5s - loss: 0.292 - ETA: 4s - loss: 0.292 - ETA: 4s - loss: 0.2923 - accuracy: 0. - ETA: 4s\n",
      "Epoch 00086: val_accuracy did not improve from 0.89220\n",
      "781/781 [==============================] - 57s 73ms/step - loss: 0.2919 - accuracy: 0.9304 - val_loss: 0.5361 - val_accuracy: 0.8699\n",
      "Epoch 87/100\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.2927 - accuracy: 0.9301 - ETA: 44s - loss: 0.2810 - accuracy: 0.9 - ETA: 44s - loss: 0.2 - ETA: 43s - loss: 0.28 - ETA: 41s - loss: 0.2850 - - ETA: 40s - loss: 0.2839 - accuracy: 0.9 - ETA: 40s - loss: 0.2841 - accuracy: 0. - ETA: 40s - loss: 0.2842 - accuracy: 0. - ETA: 40s - loss: 0.2856 - accuracy: 0 - ETA: 39 - ETA: 37s - loss: 0.2846 - accu - ETA: 36s - loss: 0.2857 - accura - ETA: 36s - loss: 0.2859 - acc - ETA: 35s  - ETA: 33s - loss: 0.2879 - accuracy:  - ETA: 33s - loss: 0.2869 - accur - ETA: 29s - loss: 0.2901 - accuracy: 0. - ETA: 29s - loss: 0.2 - ETA: 27s - loss: 0.2901 - - ETA: 26s - loss: 0.2897 - accurac - ETA: 23s - loss: 0.2892 - accura - ETA: 19s - loss: - ETA: 18 - ETA: 15s - loss: 0.2902 -  - ETA: 14s - loss: 0.2899 - a - ETA: 13s - loss: 0.2 - ETA: 12s - loss: 0.2921 - accuracy: 0 - ETA: 12s - loss: 0.2919 - accuracy: 0 - ETA: 11s - loss: 0.2919 - - ETA: 10s - loss: 0.2917 - a - ETA:  - ETA: 2s - loss: 0.2927 - accuracy: 0. - ETA: 2s - loss: 0.2932 -  - ETA: 2s - loss: 0.2928 - accu - ETA: 1s - loss: 0.2928 - accuracy:  - ETA: 1s - loss: 0.293 - ETA: 1s - loss: 0.2928 - accuracy:  - ETA: 0s - loss:\n",
      "Epoch 00087: val_accuracy did not improve from 0.89220\n",
      "781/781 [==============================] - 56s 71ms/step - loss: 0.2927 - accuracy: 0.9301 - val_loss: 0.5478 - val_accuracy: 0.8660\n",
      "Epoch 88/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "781/781 [==============================] - ETA: 0s - loss: 0.2921 - accuracy: 0.9308 - ETA: 49s - loss: 0.2721 - accuracy: 0.937 - ETA: 49s - loss: 0.2760 - accurac - ETA: 48s - loss: 0.2802 - accuracy:  - ETA: 48s - loss: 0.2842 - accur - ETA: 47s - loss: 0.2914 - accuracy - ETA: 47s - loss: 0.2954 - accuracy: 0. - ETA: 47s - loss: 0.2935 - accurac - ETA: 46s - loss: 0.2927 - accura - ETA: 46s - loss: 0.2860 - accuracy: 0.936 - ETA: 46s - loss: 0.2851 - accuracy: 0 - ETA: 45s - loss: 0.2821 - accuracy: 0. - ETA: 45s - loss: 0.2829 - accuracy: - ETA: 45 - ETA: 42s - loss: 0.2820 - ac - ETA: 41s - loss: 0.2825 - accuracy:  - ETA: 41s - loss: 0.2831 - accurac - ETA: 41s - loss: 0.2849 - accurac - ETA: 40s - loss: 0.2837 - accuracy: 0.93 - ETA: - ETA: 37s - loss: 0.2829 - accuracy: 0 - ETA: 37s - loss: 0.2830 - accu - ETA: 36s - loss: 0.2846 - accura - ETA: 36s - loss: 0.2833 - accuracy: 0. - ETA: 35s - loss: 0.2844 -  - ETA: 34s - loss: 0.2845 - accuracy: 0. - ETA: 34s - loss - ETA: 32s - loss: 0.2867 - accurac - ETA: 32s - l - ETA: 30s - loss - ETA: 28s - ETA: 26s - loss: 0.2909 - accuracy:  - ETA: 25s - loss: 0.2907  - ETA: 24s - loss: 0.2911  - ETA: 23s - loss: 0.2922 - accuracy: 0 - ETA: 23s - loss: 0.2921 - accuracy: 0.9 - ETA: 20s - loss: 0.2908 - accuracy: 0.931 - ETA: 20s - loss: 0.2910 - accu - ETA: 19s - loss: 0.2907 - accuracy: 0.93 - ETA: 19s - loss: 0.2906 - ac - ETA: 18s - loss: 0.2913 - acc - ETA: 0s - loss: 0.2919 - accuracy:  - ETA: 0s - loss: 0.2922 - accuracy: 0.93 - ETA: 0s - loss: 0.2923 - accuracy\n",
      "Epoch 00088: val_accuracy did not improve from 0.89220\n",
      "781/781 [==============================] - 56s 72ms/step - loss: 0.2921 - accuracy: 0.9308 - val_loss: 0.4869 - val_accuracy: 0.8833\n",
      "Epoch 89/100\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.2918 - accuracy: 0.9306 - ETA: 48s - loss: 0.2995 - accuracy: 0.9 - ETA: 48s - loss: 0.3023 - accuracy: 0.92 - ETA: 48s - loss: 0.3013 - accuracy: 0.92 - ETA: 48s - loss: 0.2 - ETA: 47s - loss: 0.2809 - ETA: 45s - loss: 0.2815 - accu - ETA: 39s - loss: 0.2864 - accuracy: 0.9 - ETA: 39s - loss: 0.2872 -  - ETA: 38s - loss: 0.2874 - a - ETA: 37s - loss: 0.2873 - ETA: 36s - loss: 0. - ETA: 34s - loss: 0.2899 - accura - ETA: 34s - loss: 0.2900 - accuracy: - ETA: 33s -  -  - ETA: 28s - loss: 0.2908 - accuracy - ETA: 28s - loss: 0.2909 - accuracy: 0.931 - ETA: 28s - loss: 0.291 - ETA: 27s - loss: 0 - ETA:  - ETA: 23s - loss: 0.2916 - accuracy: - ETA: 22s - loss: 0.2 - ETA: 21s - loss: 0.292 - ETA: 19s - loss: 0.2911 - accuracy:  - ETA: 19s - loss: 0.2910 - acc - ETA: 18s - loss: 0.2910 - accur - ETA: 17s - loss: 0.290 - ETA: 16s - loss: 0.2899 - accuracy: 0.93 - ETA: 16s - loss: 0.2902 - accuracy: 0. - ETA: 16s - loss: 0.2904 - accu - ETA: 15s - loss: 0.2905 - accuracy: 0.93 - ETA: 15s - loss: 0.2903 - accuracy:  - ETA: 14s - loss: 0.2912 - accuracy - ETA: 14s - loss: 0.2918 - - ETA: 13s - loss: 0.2913 - accuracy: 0.93 - ETA: 13s - loss: 0.2913 - - ETA: 11s -  - ETA: 5s - loss: 0 - ETA: 4s - loss: - ETA: 3s - loss: 0.2915 - ac - ETA: 3s - - ETA: 2s - los\n",
      "Epoch 00089: val_accuracy did not improve from 0.89220\n",
      "781/781 [==============================] - 56s 72ms/step - loss: 0.2918 - accuracy: 0.9306 - val_loss: 0.6588 - val_accuracy: 0.8482\n",
      "Epoch 90/100\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.2901 - accuracy: 0.9317 - ETA: 50s - loss: 0.29 - ETA: 45s - loss: 0.2853 - accuracy: - ETA: 44s - loss: 0.2850 - accuracy:  - ETA: 44s - loss: 0.2868 - accuracy: 0.93 - ETA: 43s - loss: 0.2855 - accuracy - ETA:  - ETA: 40s - loss: 0.2819 - accu - ETA: 40s - loss: 0.282 - ETA: 36s - loss: 0.2809 - accuracy: - ETA: 35s - loss: 0.2811 -  - ETA: 3 - ETA: 32s - loss: 0.2818 - accura - ETA: 31s - loss: 0.2812 - accuracy: 0.933 - ETA: 3 - ETA: 29s - loss: 0.2806 - ac - ETA: 28s - loss: 0.2820 - accurac - ETA: 27s - loss: 0.2823 - accuracy:  - ETA: 27s - loss: 0.2823 - accur - ETA: 26s - loss: 0.2833 - accuracy: - E - ETA: 23s - l - E - ETA: 15s - loss: 0.2883 - accurac - ETA: 15s - loss: 0.2885 - accurac - ETA: 14s - loss: 0.2 - ETA: 1 - ETA: 7s - loss: 0.2891 - ac - ETA:  - E - ETA: 0s - loss: 0.2901 - accuracy: 0.93\n",
      "Epoch 00090: val_accuracy did not improve from 0.89220\n",
      "781/781 [==============================] - 57s 72ms/step - loss: 0.2901 - accuracy: 0.9317 - val_loss: 0.5712 - val_accuracy: 0.8666\n",
      "Epoch 91/100\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.2925 - accuracy: 0.9305 - ETA: 43s - loss: 0.2881 - ac - ETA: 42s - - ETA: 40s - loss: 0.28 - ETA: 38s - loss: 0.2842 - ETA: 37s - loss: 0.2838 - ac - ETA: 36s - l - ETA: 28s - loss: 0.2 - ETA: 27s - loss: 0.2910 - accuracy: 0.931 - ETA: 27s - loss: 0.2918 - accuracy: 0.93 - ETA: 27s - loss: 0.2918 - accuracy: 0. - ETA: 26s - los - ETA: 25s - los - ETA: 23s - loss: 0.2913 -  - ETA:  - ETA: 13s - loss: 0.2917 - accuracy: 0. - ETA: 13s - loss: 0.2914 - accura - ETA: 12 - ETA: 5s - loss: 0.2933 - ac - ETA: 5s - loss: 0.2932  - ETA: 4s - loss: 0.2930 - accuracy:  - ETA: 4s - loss: 0.2930 - accu - ETA: 4s - loss: 0.2930 - accuracy - ETA: 3s - loss: 0.2 - ETA: 3s - loss: 0.2934 - accura\n",
      "Epoch 00091: val_accuracy did not improve from 0.89220\n",
      "781/781 [==============================] - 56s 72ms/step - loss: 0.2925 - accuracy: 0.9305 - val_loss: 0.5358 - val_accuracy: 0.8718\n",
      "Epoch 92/100\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.2904 - accuracy: 0.9320 - ETA: 50s - lo - ETA: 48s - loss: 0.2758 - accur - ETA: 48s - loss: 0.2788 - accuracy:  - ETA: 47s - loss: 0.2735 - accuracy: - ETA: 47s - lo -  - ETA: 42s - loss: 0.2732 - accuracy: - ETA: 42s - loss: 0.2751 - accuracy: 0.934 - ETA: 42s - l - ETA: 39s - loss: 0.2764 - accuracy: 0 - ETA: 39s - loss: 0.2763 - accuracy - ETA: 38s - loss: 0.2778 - accu - ETA: 38 - ETA: 35s - loss: 0 -  - ETA: 31s - loss: 0.2852 - accuracy: 0. - ETA: 31s - loss: 0.2851 - accuracy: - ETA: 30s - loss: 0.2853 - accuracy:  - ETA: 30s - loss: 0.2856 - accuracy: 0.9 - ETA: 30s - loss: 0.2853 - accuracy: 0.93 - ETA: 30s - loss: - ETA: 28s - lo - ETA: 23s - loss: 0.2846 - accuracy: 0.93 - - ETA: 20s - loss: 0.28 - ETA: - ETA: 10s - loss: 0.2907  - ETA: 5s - loss: 0.2894 - accuracy - ETA: 5s - loss: 0.2893 - accuracy: 0. - ETA:  - ETA: 3s - los - ETA: 2s - loss: 0.2896 - accuracy: 0. - ETA: 2s - loss: 0 - ETA: 1s - loss: 0.2902 - accuracy - ETA: 1s - loss: 0.2903 - accuracy: 0. - ETA: 1s - l - ETA: 0s - loss: 0.2901 - accuracy: 0.93 - ETA: 0s - loss: 0.2901 - ac\n",
      "Epoch 00092: val_accuracy did not improve from 0.89220\n",
      "781/781 [==============================] - 56s 72ms/step - loss: 0.2904 - accuracy: 0.9320 - val_loss: 0.4670 - val_accuracy: 0.8884\n",
      "Epoch 93/100\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.2909 - accuracy: 0.9307 -  - ETA: 27s - loss: 0.2874 - accur - ETA: 27s - loss: 0.2872 - accuracy: 0.932 - ETA: 26s - loss: 0 - ETA: 22s - loss: 0.2866 - accura - ETA: 21s - loss: 0.2873 - accuracy: 0.931 - ETA: 21s - loss:  - ETA: 19s - loss: 0.2 - ETA: 18s - loss: 0.2871 - accuracy: 0.931 - ETA: 18s - loss: 0.2871 - accuracy: 0.931 - ETA: 18s - loss: 0.2870 - ac - ETA: 17s - loss: 0.2869 -  - ETA: 16s - loss: 0.2866 - accuracy: 0.9 - ETA: 15s - loss: 0.2867 - accuracy:  - ETA: 15s - loss: 0.2865 - accuracy - ETA: 14s - loss: 0.2863 - accuracy: 0.9 - ETA: 14s - loss: 0.2867  - ETA: 13s - loss: 0.2869 - accuracy: - ETA: 12s - loss: 0.2873 - accuracy: 0. - ETA: 12s - loss: 0. - ETA: 9s - loss: 0 - ETA: 8s -\n",
      "Epoch 00093: val_accuracy did not improve from 0.89220\n",
      "781/781 [==============================] - 56s 72ms/step - loss: 0.2909 - accuracy: 0.9307 - val_loss: 0.5042 - val_accuracy: 0.8801\n",
      "Epoch 94/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "781/781 [==============================] - ETA: 0s - loss: 0.2888 - accuracy: 0.9327 - ETA: 53s - loss: 0.2670 - accuracy: - ETA: 51s - l - ETA: 49s - loss:   - ETA: 44s - loss: 0.2818 - accuracy: - ETA: 43s - loss: 0.2814 - accu - ETA: 43s - loss: 0.2796 - accuracy: - ETA: 36s - loss: 0.2807 - acc - ETA: 35s - loss: 0.2808 - accuracy: 0 - ETA: 35s - loss: 0.2811 - accuracy: 0.93 - ETA: 35s - loss: 0.2812 -  - ETA: 34s - loss - ETA: 32s - loss: 0.2828 - accuracy: 0.9 - ETA: 32s - loss: 0.2832 - accu - ETA: 31s - loss: 0.2825 - accur - ETA: 3 - ETA: 25s - loss: 0.2834 - accuracy: 0.93 - ETA: 24s - loss: 0.2831 - accur - ETA: 24s - loss: 0.2825 - accuracy: - ETA: 23s - loss: 0.2818 - accuracy: 0. - ETA: 23s - loss: 0.2820 - accu  - ETA: 19s - loss: 0.2843 - accuracy:  - ETA: 19s - loss: 0.2845 - accurac - ETA: 18s - loss: 0.2843 - acc - ETA: 17s - loss: 0.2851 - accuracy: 0.9 - ETA: 17s - loss: 0.2849 - E\n",
      "Epoch 00094: val_accuracy did not improve from 0.89220\n",
      "781/781 [==============================] - 57s 72ms/step - loss: 0.2888 - accuracy: 0.9327 - val_loss: 0.5380 - val_accuracy: 0.8717\n",
      "Epoch 95/100\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.2891 - accuracy: 0.9316 - E - ETA: 48s - loss: 0.2821 - accurac - ETA: 47s - loss: 0.2759 - a - ETA: 46s - loss: 0.2764 - accuracy: 0.937 - ETA: 46s - loss: 0 - ETA: 44s - loss: 0.2802 - accuracy: 0 - ETA: 44s - loss: 0.2781 - accuracy: 0.934 - ETA: 44s - loss: 0.2776 - accuracy: 0.93 - ETA: 43s - loss: 0.2788 - accurac - ETA: 43s  - ETA: 41s - loss: 0.2859 - accuracy: 0.9 - ETA: 41s  - ETA: 38s - loss: 0.2861 - accuracy: 0.932 - ETA: 38s - loss: 0.2856 - ac - ETA: 37s - loss: 0.2849 - ac - ETA: 37s - loss: 0.2850 - accura - ETA: 36s - loss: 0.2846 - accuracy: 0 - ETA: 36 - ETA: 33s - loss: 0.2817 - accuracy:  - ETA: 33s - loss: 0.2816 - accura - ETA: 32s - loss: 0.2819 - accur - ETA: 31s - loss: 0.2815 - ac - ETA: - ETA: 25s - loss: 0.2848 - accuracy: 0.93 - ETA: 25s - loss: 0.2850 - accuracy - ETA: 21s - loss: 0.2872 - accuracy:  - ETA: 21s - loss: 0.2880 - ETA: 20s - loss: 0.2886 - accuracy: 0 - ETA - ETA: 17s - loss: 0. - ETA: 15s - loss: 0.287 - ETA: 14s -  - ETA: 12s - loss: 0.2883 - accuracy: 0.93 - ETA: 12s - loss: 0.2882 - accuracy: 0.93 - ETA: 12s - loss: 0. - ETA: 4s - loss: 0.2894 - accura\n",
      "Epoch 00095: val_accuracy did not improve from 0.89220\n",
      "781/781 [==============================] - 55s 70ms/step - loss: 0.2891 - accuracy: 0.9316 - val_loss: 0.4862 - val_accuracy: 0.8842\n",
      "Epoch 96/100\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.2908 - accuracy: 0.9310 - - ETA: 47s - loss: 0.2875 - accuracy: 0.932 - ETA: 47s - loss: 0.2876 - accuracy: 0.9 - ETA: 46s - loss: 0.2887 - accuracy: 0.931 - ETA: 46s - loss: 0.2901 - accuracy: 0.93 - ETA: 46s - loss: 0.2896 - accurac - ETA: 45s - loss: 0.2877 - accuracy: 0.933 - ETA: 45s - ETA: 43s - loss: 0.2852 - accuracy: 0 - ETA: 42s - loss: 0 - ETA: 41s - loss: 0.2795 - acc - ETA: 40s - loss: 0.2799 - accur - ETA: 39s - loss: 0.2815  - ETA: 38s - loss: 0.2 - ETA: 36s - loss: 0.2774 - accu - ETA: 36s - loss: 0.2775 - accuracy:  - ETA: 35 - ETA: 30s - loss: 0.2825 -  - ETA: 29s - loss: 0.2824 - a - ETA: 28s - loss: 0.2827 - accurac - ETA: 28s - loss: 0.2832 - accuracy: 0.93 - ETA: 27s - loss: 0.2834 - accu - ETA: 27s - loss: 0.2 - ETA: 25s - loss: 0.2840 - accuracy: - ETA: 25s - loss: 0.2845 - accur - ETA: 24s - loss: 0.28 - ETA: 23s - loss: 0.2843 - acc - ETA: 22s - loss: 0.2858 - accuracy: 0.93  - ETA: 6s - los - ETA: 5s - los - ETA: 4s - loss: 0.2906 - accuracy:  - ETA: 4s - loss: 0.2906  - ETA: 3s - loss: 0.290 - ETA: 3s - loss: 0.2908 - accuracy: 0.93 - ETA: 2s - loss: 0.2909 - accuracy: 0.93 - ETA: 2s - loss: 0.2911 - accuracy: 0. - ETA - ETA: 1s - loss: 0.2910 - accuracy: 0. - ETA: 0s - loss: 0.2906 - accuracy: 0.93\n",
      "Epoch 00096: val_accuracy did not improve from 0.89220\n",
      "781/781 [==============================] - 54s 69ms/step - loss: 0.2908 - accuracy: 0.9310 - val_loss: 0.5195 - val_accuracy: 0.8765\n",
      "Epoch 97/100\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.2879 - accuracy: 0.9311 - ETA: 47s - loss: 0.276 - ETA: 47s - loss: 0.2585 - accuracy: 0. - ETA: 47s - loss - ETA: 45s - loss: 0.2732 - accuracy: 0.936 - ETA: 45s - loss: 0.2746 - accuracy - ETA: 44s - loss: 0.2802  - ETA: 43s - loss: 0.2873 - accuracy: 0. - ETA: 43s - loss: 0.2843 - - ETA: 42s - loss: 0.2805 - accuracy:  - ETA: 41s - loss: 0.2820 - accurac - ETA: 41s - loss: 0.2849 - a - ETA: 40s - loss: 0.2861 - accuracy: 0.9 - ETA: 40s - loss: 0.2854 -  - ETA: 39s - loss: 0.2839 - accuracy: 0. - ETA: 39s - loss: 0.2826 - accuracy: 0.932 - ETA: 39s - loss: 0.2828 - accuracy: - ETA: 38s - loss: 0.2820 - accurac - ETA: 38s - loss: 0.2811 - accura - ETA: 37s - loss: 0.2803 - accuracy: 0.933 - ETA: 37s - loss: 0.2802 - accuracy: 0 - ETA: 37s - loss: 0.2813 - accuracy: 0. - ETA: 36s - loss: 0.2827 - accuracy - ETA: 36s - los - ETA: 34s - loss: 0.2796 - accuracy: 0.93 - ETA: 34s - loss - ETA: 32s - loss: 0.2800 - accuracy: 0.934 - E - ETA:  - ETA: 27s - loss: 0. - ETA: 26s - loss: 0.2791 - accuracy: 0.93 - ETA: 26s - loss: 0.27 - ETA: 24s - loss: 0.2798 - - ETA: 23s - loss: 0.2 - ETA: 22s - loss: 0.2811 -  - ETA: 21s - loss: 0.2811 - accuracy: 0.9 - ETA: 21s - loss - ETA: 19s - loss - ETA: 17s - loss: 0.2822 - accuracy: 0.93 - ETA: 17s - loss: 0.2821 - accuracy:  - ETA: 17s - loss: 0.2819 - accur - ET - E - ETA: 0s - l\n",
      "Epoch 00097: val_accuracy did not improve from 0.89220\n",
      "781/781 [==============================] - 54s 70ms/step - loss: 0.2879 - accuracy: 0.9311 - val_loss: 0.4838 - val_accuracy: 0.8844\n",
      "Epoch 98/100\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.2903 - accuracy: 0.9307 - ETA: 52s - los - ETA: 49s  - ETA: 46s - loss: 0.2844 - - ETA: 46s -  - ETA: - ETA: 41s - loss: 0.2845 - accuracy:  - ETA: 40s - l - ETA: 38s - loss: 0.2848 - accuracy: 0 - ETA: 38s - loss: 0.2863 - accuracy - ETA: 37s - loss: 0.2874 - accuracy: 0.93 - ETA: 37s - loss: 0.2878 - accura - ETA: 37s - loss: 0.2861 - accur - ETA: 36s - loss: 0.2879 - accuracy - ETA: 35s - loss: 0.2885 - accura - ETA: 35s - loss: 0.2876 - accuracy: 0 - ETA: 34s - loss: 0.2871 - accuracy: 0. - ETA: 34s - loss: 0.2873 - accurac - ETA: 33s - loss: 0.2865 - accur - ETA: 33s - loss: 0.2863 - accura - - ETA: 29 - ETA: 27s - loss: 0.2884 - accura - ETA: 26s - loss: 0.2886 - ac - ETA: 25s - loss: 0.2886 - accuracy: 0 - ETA: 25s - lo - ETA: 23s - loss: 0.2896 - accuracy: 0.9 - ETA: 23s - loss: 0.2894 -  - ETA: 22s - loss: 0.2893 - ac - ETA: 21s - loss: 0.2885 - accuracy: 0. - ETA: 21s - loss: 0.2887 - accuracy: - ETA: 20s - loss: 0.2885 - accuracy: 0.93 - ETA: 20s - ETA: 18s - loss: 0.28 - ETA: 17s - loss: 0.2893 - accuracy: - ETA: 16s - loss: 0.2894 - accuracy: 0.9 - ETA: 16s - loss: 0.2894 - accuracy - ETA: 15s - loss: 0.2898 - accuracy: 0 - ETA: 15s - ETA: 13s - loss: 0.2908 - accuracy - ETA: 12s - loss: - ETA: 11s - loss: 0.2909 - accuracy: 0.93 - ET - ETA: 6s - loss: - ETA: 3s - loss: 0.2898 - accuracy: 0.93 - ETA: 3s - loss: 0.2898 - accuracy: 0.93 - ETA: 3s - l\n",
      "Epoch 00098: val_accuracy did not improve from 0.89220\n",
      "781/781 [==============================] - 56s 71ms/step - loss: 0.2903 - accuracy: 0.9307 - val_loss: 0.5043 - val_accuracy: 0.8821\n",
      "Epoch 99/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "781/781 [==============================] - ETA: 0s - loss: 0.2872 - accuracy: 0.9339 - ETA: 49s - loss: 0.2971 - accuracy: 0.927 - ETA: 49s - loss: 0.2932 - accuracy: 0 - ETA: 48s - loss: 0.2844 - accuracy: 0.92 - ETA: 48s - loss: 0.2844 - accura - ETA: 48s - loss: 0.2750 - accuracy:  - ETA: 47s - loss: 0.2729 - accuracy: 0 - ETA:  - ETA: 44s - loss: 0.2815 - acc - ETA: 43s - loss: 0.2852 - ETA: 43s - loss: 0.28 - ETA: 41s - loss: 0.2863 - accuracy:  - ETA: 41s - loss: 0.2861 - accuracy: 0.93 - ETA: 41s - los - ETA: 39s - loss: 0.2860 - accuracy: 0 - ETA: 39s - loss: 0.2862 - accurac - ETA: 38s - - ETA:  - ETA: 31s - loss: 0.2819 - a - ETA: 30s - loss: 0.2831 - ac - ETA: 29s - loss: 0.285 - ETA: 27s - loss:  - ETA: 26s - loss: 0.2848 - accuracy: 0 - ETA: 25s - loss: 0.2848 - accuracy: 0.934 - ETA: 25s - loss: 0.2852 - accu - ETA: 24s - loss: 0.2862 - accuracy: - ETA: 24s - loss: 0.2863 - accuracy: - ETA: 24s - loss: 0.2868 - accuracy: - ETA: 23s - loss: 0.2875 - accurac - ETA: 23s - loss: 0.2871 - accu - ETA: 22s - loss: 0.2867 - accuracy - ETA: 21s - loss: 0.2869 - accuracy - ETA: 21s - loss: 0.2866 -  - ETA: 20s - loss: 0.2872 - accuracy: 0.93 - ETA: 20s - loss: 0.2870 - accur - ETA: 19s - loss: 0.2869 - accuracy: - ETA: 18s -  - ETA: 16s - loss: 0.2871 - a - ETA: 15s - loss: 0.2860 -  - ETA: 14s -  - ETA: 12s - loss: 0.2855 - accuracy - ETA: 12s - loss: 0.2856 - a - - ETA: 9s - loss: 0.2857 - accuracy:  - ETA:  - ETA: 3s - loss: 0 - ETA: 2s - loss: 0.2863 - accura - ETA: 2s - ETA: 1s - loss: 0.2872 -  - ETA: 0s - loss: 0.287\n",
      "Epoch 00099: val_accuracy did not improve from 0.89220\n",
      "781/781 [==============================] - 56s 72ms/step - loss: 0.2872 - accuracy: 0.9339 - val_loss: 0.5039 - val_accuracy: 0.8847\n",
      "Epoch 100/100\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.2870 - accuracy: 0.9312 - ETA: 48s - loss: 0.2664 - accurac - ETA: 48s - lo - ETA: 47s - loss: 0.2737 - accuracy: 0. - ETA: 47s - loss: 0.2758 - accuracy: 0.934 - ETA: 47s - loss: 0.274 - ETA: 45s - loss: 0.2806 -  - ETA: 44s - l - - ETA: 37s - loss: 0.2812 - accur - ETA: 36s - loss: 0.2815 - accur - ETA: 35s  - ETA: 24s - loss: 0.285 - ETA: 23s - loss: 0.2841 - accuracy: 0 - ETA: 23s  - ETA: 21s - loss: 0.2850 - accura - ETA: 2 - ETA: 0s - loss: 0.2869 - accuracy: 0. - ETA: 0s - loss: 0.2869 - accura - ETA: 0s - loss: 0.2870 - accuracy\n",
      "Epoch 00100: val_accuracy did not improve from 0.89220\n",
      "781/781 [==============================] - 56s 72ms/step - loss: 0.2870 - accuracy: 0.9312 - val_loss: 0.5934 - val_accuracy: 0.8604\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24a52f84820>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(img_gen,\n",
    "          steps_per_epoch=steps,\n",
    "          epochs=100,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, y_test),\n",
    "          callbacks=[checkpoint,tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 7780), started 12:16:39 ago. (Use '!kill 7780' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-bc730e69b0417537\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-bc730e69b0417537\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "best_model = load_model('my_best_model.epoch67-accuracy0.89.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "id": "ZcWydmIVhZGr",
    "outputId": "a0345aa5-79ff-4e56-eb94-50437b43c4fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 4s 12ms/step - loss: 0.4415 - accuracy: 0.8922\n",
      "Test loss: 0.441528856754303\n",
      "Test accuracy: 0.8921999931335449\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "score = best_model.evaluate(X_test, y_test, verbose=1)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(learning_rate=0.0003,decay=1e-6),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.2635 - accuracy: 0.9411  - ETA: 53s - loss: 0.2804 - accurac - ETA: 52s - loss: - ETA: 42s - loss: 0.2658 - accuracy: 0.939 - ETA: 42s - loss: 0.2650 - ETA: 41s - loss: 0.2643 - - ETA: 39s - loss: 0.2652 - accurac - ETA: 39s - loss: 0.2 - ETA: 38s - loss: 0.2653 - ac - ETA: 37s - loss:  - ETA: 35s - loss: 0.2644 - accuracy - ETA: 34s - loss: 0.26 - ETA: 33s - loss: 0.2665 - accuracy - ETA: - ETA: 30s - loss: 0.2658 - accuracy: 0 - ETA: 30s - loss: 0.26 - ETA:  - ETA: 26s  - ETA: 24s - loss: 0.2660 - accuracy: 0.9 - ETA: 23s - loss: 0.2660 - - ETA: 22s - loss: 0.2655 - accurac - ETA: 22s - loss: 0.2661 - accurac - ETA: 21s - loss: 0.2654 - - ETA: 20s - loss: 0.2656 - accuracy: 0.940 - ETA: 20s - loss: 0.2655 - - ETA: 19s - loss: 0.2647 -  - ETA: 18s - loss: 0.2645 - accuracy: 0. - ETA: 18s - loss: 0.2644 - accuracy: 0. - ETA: 9s - loss: 0.2633 - ac - ETA: 9s - loss: 0.263 - ETA: 6s - loss: 0.2639 - ac - ETA: 6s - loss: 0.2634 - accuracy: 0.94 - ETA: 6s - loss: 0.2637 -  - ETA: 0s - loss: 0.2634 - accuracy: \n",
      "Epoch 00001: val_accuracy did not improve from 0.89220\n",
      "781/781 [==============================] - 63s 72ms/step - loss: 0.2635 - accuracy: 0.9411 - val_loss: 0.4825 - val_accuracy: 0.8854\n",
      "Epoch 2/30\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.2534 - accuracy: 0.9435 - ETA: 50s - loss: 0.2660 - accuracy: 0 - ETA: 49s - loss: 0.2565 - acc - ETA: 48s - loss: 0.2634 - accuracy: 0. - ETA: 48s - loss: 0.2603 - a - ETA: 47s - loss: 0.2 - ETA: 45s - loss: 0.2721 - a - ETA: 44s - loss: 0.2 - ETA: 43s - los - ETA: 41s - loss: 0.2602 - accurac - ETA: 40s - loss: 0.2589 - accuracy: - ETA: 40s - loss: 0.2587 - accur - ETA: 39s - loss: 0.2579 - accur -  - ETA: 36s - loss: 0.2582 - accu - ETA: 35s - loss: 0.2571 - accurac - ETA: 34s - loss: 0.2577 - - ETA: 33s - loss: 0.2588 - accuracy: 0 - ETA: 33s - loss: 0.2587 - accur - ETA: 32s - loss: 0.259 - ETA: 31s - loss: 0.2601 - acc - ETA: 30s - loss: 0.2605 - accuracy: 0.94 - ETA: 30s - loss: 0.2602 - accur - ETA: 29s - loss: 0.2600 - accuracy: 0.94 - ETA: 29s - loss: 0.2599 - accuracy: 0. - ETA: 29s - loss: - ETA: 27s - loss: 0.2596 - - ETA: 23s - loss: 0.2566 - accur - ETA: 22s -  - ETA: 20s - loss: 0.2559 - - ETA: 19s - loss: 0.2557 - accuracy:  - ETA: 19s - loss - ETA: 17s - loss: 0.2552 - - ETA: 16s - lo - ETA: 11s - loss: 0.2533 \n",
      "Epoch 00002: val_accuracy improved from 0.89220 to 0.89250, saving model to my_best_model.epoch02-accuracy0.89.hdf5\n",
      "781/781 [==============================] - 56s 72ms/step - loss: 0.2534 - accuracy: 0.9435 - val_loss: 0.4474 - val_accuracy: 0.8925\n",
      "Epoch 3/30\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.2517 - accuracy: 0.9447 - ETA: 49s - loss: 0 - ETA: 47 - ETA: 45s - loss: 0.2614 - a - ETA: 44s - loss: 0.2597 - ac - ETA: 43s - lo - ETA: 42s - loss: 0 - ETA: 40s - loss: 0.2553 - accuracy: 0.94 - ETA: 40s - loss: 0.2552 - acc - ETA: 39s - lo - ETA: 37s - loss: 0.2514 - ETA: 36s - loss: 0.2489 - accurac - ETA: 36s - loss: 0.2497 - accuracy: 0. - ETA: 36s - loss: 0.24 - ETA: 34s - loss: 0.2504 - accuracy - ETA: 34s - loss: 0.2506 - accuracy: 0. - ETA: 33s - loss: 0.2507 - accuracy: 0.945 - ETA: 33s - loss: 0.2505 - accuracy: - ETA: 33s - loss: 0. - ETA: 29s - loss: 0.2511 - accuracy: 0. - ETA: 28s - loss: 0 - ETA: 27s - loss: 0.2505 - accura - ETA: 26s - loss:  - E - ETA: 22s - loss: 0.2510 - accurac - ETA: 21s - loss: 0.2511 - accurac - ETA: 21s - loss - ETA: 1 - ETA: 16s - loss: 0.2500 - accuracy: 0 - ETA: 16s - loss: 0 - ETA: 15s - loss: 0.2501 - accuracy: 0.94 - ETA: 14s - loss: 0.2497 - accurac -  - ETA: 1 - ETA:  - E\n",
      "Epoch 00003: val_accuracy did not improve from 0.89250\n",
      "781/781 [==============================] - 55s 71ms/step - loss: 0.2517 - accuracy: 0.9447 - val_loss: 0.4733 - val_accuracy: 0.8906\n",
      "Epoch 4/30\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.2514 - accuracy: 0.9437 - ETA: 49s - loss: 0.2716 - ac - ETA: 49s - loss: 0.2493  - ETA: 47s - loss: 0.2494 - acc - ETA: 46s - loss: 0.2554 - accur - ETA: 46s - loss: 0.25 - ET - ETA: 42s - loss: 0.2528 - accuracy: 0 - ETA: 42s - loss: 0.2515 - ETA: 40s - loss: 0.2513 - accur - ETA: 40s - loss: 0.2501 - accu - E - ETA: 36s - loss: 0.2510 - accuracy:  - ETA: 36s - loss: 0.2514 - ac - ETA: 35s - loss: 0.2517 - accuracy: 0.94 -  - ETA: 32s - loss - ETA: 27s -  - ETA: 25s - loss: 0.2536 - accuracy: - ETA: 25s - los - ETA: 23s - loss: 0. - ETA: 18s - loss: 0.2534 - ac - ETA: 18s - loss: 0. - ETA: 16s -  - ETA: 1s - loss: 0.2514 - ac\n",
      "Epoch 00004: val_accuracy did not improve from 0.89250\n",
      "781/781 [==============================] - 57s 73ms/step - loss: 0.2514 - accuracy: 0.9437 - val_loss: 0.5076 - val_accuracy: 0.8848\n",
      "Epoch 5/30\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.2464 - accuracy: 0.9456 - ETA: 52s - l - ETA: 48s - loss: 0.2232 - accuracy: 0 - ETA: 48s - loss: 0.2226 - accuracy: 0 - ETA: 48s - loss: 0.2208 - accura - ETA - ETA: 45s - loss: 0.2242 -  - ETA: 44s - loss: 0.2276 - accuracy: - ETA: 44s - loss - ETA: 42s - loss: 0.2322 - accurac - ETA:  - ETA: 2s - loss: 0.2463 - accu - - ETA: 0s - loss: 0.2466 - accuracy\n",
      "Epoch 00005: val_accuracy did not improve from 0.89250\n",
      "781/781 [==============================] - 58s 74ms/step - loss: 0.2464 - accuracy: 0.9456 - val_loss: 0.5392 - val_accuracy: 0.8779\n",
      "Epoch 6/30\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.2464 - accuracy: 0.9446 - ETA: 51s - loss: 0.2268 -  - ETA: 50s - loss: 0.2221 - accuracy: 0. - - ETA: 43s - loss: 0.2397 -  - ETA: 42s - loss: 0.2379 - accuracy: 0.94 - ETA: 42s - loss: 0.2386 -  - ETA: 41s - loss: 0.23 - ETA: 40s - loss: 0.2406 - accuracy: 0.946 - ETA: 40s - loss: 0. - ETA: 38s - loss: 0.2388 - accuracy: 0.947 - ETA: 38s -  - ETA: 36s - loss: 0.2394 - accuracy: - ETA: 36s - - ETA: 34s - loss: - ETA: 32s - loss: 0.2400 - a - ETA: 31s - loss: - ETA: 23s - loss: 0.2446 - accuracy:  - ETA: 6s - loss: 0.2439 - accuracy: 0.94 - ETA: 6s - loss: 0.2438 - accuracy - ETA: 5s - loss: 0.2439 - accuracy: 0.94 - ETA: 5s - loss: - ETA: 4s - loss: 0.244 - ETA: 4s - l - ETA: 3s - E - ETA: 0s - loss: 0.2461  - ETA: 0s - loss: 0.2461 - accuracy: 0. - ETA: 0s - loss: 0.2464 - accuracy: 0.\n",
      "Epoch 00006: val_accuracy improved from 0.89250 to 0.89640, saving model to my_best_model.epoch06-accuracy0.90.hdf5\n",
      "781/781 [==============================] - 56s 72ms/step - loss: 0.2464 - accuracy: 0.9446 - val_loss: 0.4505 - val_accuracy: 0.8964\n",
      "Epoch 7/30\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.2457 - accuracy: 0.9461 - ETA: 48s - loss: 0.2326 - accuracy: 0.952 - ETA: 48s - loss: 0.2302 - acc - ETA: 47s - loss: 0.2281 - accuracy: 0.95 - ETA: 47s - loss: - ETA: 46s - loss: 0.2292 - accuracy: - ETA - ETA: 43s - loss: 0.2383  - ETA: 42s - loss: 0.2409 - accura - ETA: 41s - loss: 0.2428 - accu - ETA: 40s - loss: 0.242 - ETA: 36s - loss: 0.2412 - accuracy: 0 - ETA: 36s - loss: 0.2413 - accur - ETA: 35s - loss: 0.2415 - accuracy: 0 - ETA: 35s - loss: 0.2406 - accur - ETA: 34s - loss: 0.2404 - accuracy: 0 - ETA: 33s - loss: 0.2409 - accuracy:  - ETA: 33s - loss: 0.2411 - accuracy: 0.948 - ETA: 33s - loss - ETA: 31s - loss: 0.2409 - accuracy: 0.9 - ETA: 31s - loss: 0.2407 - accuracy:  - ETA: 31s - loss: 0.2423 - accuracy: 0.9 - ETA: 31s - loss: 0.2423 -  - ETA: 29s - loss: 0.2443 - accuracy: 0.9 - E - ETA: 24s - loss: 0.2442 - accuracy: 0.947 - ETA: 24s - loss: 0.2441 - accuracy: 0.947 - ETA: 24s - loss: 0.2440 - accuracy: 0.947 - ETA: 23s - loss: 0.2438 - accuracy: 0.947 - ETA: 23s - loss: 0.2442 - accuracy: 0 - ETA: 23s - loss: 0.2439 - - ETA: 22s - loss: 0.2435 - accuracy: 0.9 - ETA: 22s - loss: 0. - ETA: 20s - loss: 0.2432 - accuracy: 0. - - ETA: 14s - loss: 0.2457 - accur - ETA: 14s - loss: 0.2455 - accu - ETA: 13s - loss: 0.2452 - a - ETA: 12s - loss: 0.2446 - a - ETA: 11s -  - ETA: 5s - loss: 0 - ETA: 4s - los - ETA: 3s - loss: 0.245\n",
      "Epoch 00007: val_accuracy did not improve from 0.89640\n",
      "781/781 [==============================] - 56s 72ms/step - loss: 0.2457 - accuracy: 0.9461 - val_loss: 0.5016 - val_accuracy: 0.8849\n",
      "Epoch 8/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "781/781 [==============================] - ETA: 0s - loss: 0.2464 - accuracy: 0.9451 - - ETA: 37s - loss: 0.2415 - accur - ETA: 36s - loss: 0.2420 - accuracy: 0.94 - ETA: 36s - loss: 0.2419 - accuracy: 0.94 - ETA: 36s - los - ETA: 31s - loss: 0.2414 - ETA: 27s - loss: 0.2431 - accuracy: 0.944 - ETA: 27s  - ETA: 24s - loss: 0.2434 - accuracy: 0.944 - ETA: 24s - loss: 0.2433  - ETA: 23s - loss: 0.2438 - accur - ETA: 22s - loss: 0.2447 - accuracy: - ETA: 22s - loss: 0.2444 - accuracy: 0.9 - ETA: 22s - loss: 0.2444 - accuracy: 0 - ETA: 21s - loss: 0.2444 - accuracy - E  - ETA: 12s - loss: 0.2443 - ac - ETA: 11s - loss: 0.2446 - accu - ETA: 11s - loss: 0.2445 - accuracy: 0. - ETA: 10s - loss: 0.2447 - accuracy: 0. - ETA: 10s - loss: 0.2447 - accuracy: 0.9 - - ETA: 4s - loss: 0.2464 - accu - ETA: 3s - loss: 0.2464 - accu - ETA: 3s - loss: 0.2466 - accura - ETA: 3s - loss: 0.2466 - accuracy: 0.94 - ETA: 3s - loss: 0.2466 - accuracy - ETA: 2s - loss: 0.2468 - accuracy: 0.94 - ETA: 2s - loss: 0.2467 - accuracy: 0.94 - ETA: 2s - loss: 0.2467 - ac - ETA: 2s - l - E\n",
      "Epoch 00008: val_accuracy did not improve from 0.89640\n",
      "781/781 [==============================] - 56s 72ms/step - loss: 0.2464 - accuracy: 0.9451 - val_loss: 0.4792 - val_accuracy: 0.8914\n",
      "Epoch 9/30\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.2418 - accuracy: 0.9466 - ETA: 49s - loss: 0.2302 - accuracy: 0 - E - ETA: 49s - loss: 0.2319 - accurac - ETA: 48s - - ETA: 45s - loss: 0.2355 - accuracy: - ETA: 45s - loss: 0.2338 - accur - ETA: 44s - loss: 0.2328 - accur - ETA: 43s - loss: 0 - ETA: 42s - loss: 0.2369 - accuracy: 0.9 - ETA: 42s - loss: 0.2360 - accuracy - ETA: 41s - loss:  - ETA: 39s - loss: 0.2385 - accuracy: 0.946 - ETA: 39s - loss: 0.2380 - accuracy:  - ETA: 39s - loss: - ETA: 37s - loss: 0.2408 -  - ETA: 36s - loss: 0.2418 - accuracy: 0.945 - ETA: 36s - loss: 0.2415 - accuracy:  - ETA: 35s - loss: 0.2433 - accura - ETA: 34s - loss: 0.2431 - accuracy: 0.94 - ETA: 34s - loss: 0.2431 - accu - ETA: 33s - loss: - ETA: 32s - loss: 0.2440 - ac - ETA: 31s - loss: 0 - ETA: 23s - loss: 0.2430  - ETA: 22s - loss: 0.2443 - - ETA: 21s - loss: 0.2427 -  - ETA: 20s - loss: 0.2429 - - ETA: 19s - loss: 0.2422 - a - ETA: 18s - loss: 0.2424 - accuracy: 0.9 - ETA: 18s - loss: 0.2424 - a - ETA: 17s - loss: 0.2421 -  - ETA: 16s - loss: 0.2 - ETA: 14s - loss: 0.2409 - ETA: 13  - ETA: 1s - loss: 0.2419 - accuracy:  - ETA: 1s - loss: 0.2419 - accuracy\n",
      "Epoch 00009: val_accuracy did not improve from 0.89640\n",
      "781/781 [==============================] - 56s 71ms/step - loss: 0.2418 - accuracy: 0.9466 - val_loss: 0.4561 - val_accuracy: 0.8962\n",
      "Epoch 10/30\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.2397 - accuracy: 0.9484 - ETA: 48s - loss: 0.2220 - accu - ETA: - ETA: - ETA: 42s - loss: 0.2328 -  - ETA: 41s - loss: 0.2359 - accuracy: 0.9 - ETA: 41s - loss: 0.237 - ETA: 40s - loss: 0.2366 - a - ETA: - ETA: 33s -  - ETA: 31s - loss: 0.2343 - - ETA: 30s - loss: 0.2345 - accuracy: 0.949 - ETA: 30s - loss: 0. - ETA: 29s - loss: 0.2349 - accuracy: - ETA: 28s - loss:  - ETA: 26s  - ETA: 24s - loss: 0.2368 - accuracy: 0.94 - ETA: 24s - loss: 0.2369 -  - ETA: 23s - loss: 0.2374 - accu - ETA: 22s - loss: 0.2376 - accur - ETA: 22s -  - ETA: 20s - loss: 0.2374 - accuracy: 0.948 - ETA: 19s - loss: 0.2372 - a - ETA: 19s - loss: 0.2384 - accuracy: 0. - ETA: 18s - loss: 0.2392 - accuracy:  - ETA: 18s - loss: 0.2394 - accura - ETA: 17s - loss: 0.2395 - - ETA: 16s - loss: 0 - ETA: 12s - loss: 0.2399 - accuracy:  - ETA: 7s - loss: 0.2393  - ETA: 7s - loss: 0.2392  - ETA: 6s - loss: 0.2 - ETA - ETA: 0s - loss: 0.2399 - accu\n",
      "Epoch 00010: val_accuracy did not improve from 0.89640\n",
      "781/781 [==============================] - 56s 71ms/step - loss: 0.2397 - accuracy: 0.9484 - val_loss: 0.5312 - val_accuracy: 0.8840\n",
      "Epoch 11/30\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.2412 - accuracy: 0.9468 - ETA: 48s - loss: 0.2459 - accuracy: 0 - ETA: 48s - loss: 0.2444 - accuracy:  - ETA: 47s - ETA: 43s -  - ETA: 38s - loss: 0.2337 - accu - ETA: 37s - loss: 0.2347 - accuracy: 0. - ETA: 37s - loss: 0.2346 - - ETA: 36s - loss: 0.2347 - accuracy:  - ETA: 35s - loss: 0.2342 - accuracy: 0 - ETA: 35s - loss: 0.234 - ETA: 33s - loss: 0.2344 - accura - ETA: 33s - loss: 0.234 - ETA: 31s - los - ETA: 29s - loss: 0.2340 - accura - ETA: 29s - loss: 0.2344 - - ETA: 28s - loss: 0.23 - ETA: 26s - loss: 0.2357 - accuracy: 0 - ETA: 26s - loss: 0. - ETA: 24s - loss: 0.2366 - - ETA: 23s - loss: 0.2366 - accurac - ETA: 23s - loss: 0.2375 - accu - ETA: 22s - loss: 0.2380 - accuracy: 0. - ETA: 22s - loss: 0.2382 - accuracy: 0.948 - ETA: 22s - loss: 0.2381 - accuracy: 0 - ETA: 21s - loss: 0.2384 - accuracy: 0.9 - ETA: 21s - loss: 0.2382 - - ETA: - ETA: 17s - loss: 0.2390 - accuracy - ETA: 17s - loss: 0.2391 - accuracy: 0 - ETA: 16s - loss: 0.2393 - accuracy: - ETA: 16s - loss: 0.2395 - accuracy:  - ETA: 16s - loss: 0.2396 - accuracy - ETA: 15s - loss: 0 - ETA: 14s - loss: 0.2395 - accuracy: 0.9 - ETA: 13s - l - ETA: 11s - loss: 0.2405 - accuracy: 0 - ETA: 11s - loss: 0.2406 - accuracy: - ETA: 11s - loss: 0.240 - ETA: 9s - loss: 0.2 - ETA: 9s - - ETA: 8s - - ETA: 7s - loss: 0.2419 - accura - ETA: 6s - loss:\n",
      "Epoch 00011: val_accuracy did not improve from 0.89640\n",
      "781/781 [==============================] - 57s 72ms/step - loss: 0.2412 - accuracy: 0.9468 - val_loss: 0.4833 - val_accuracy: 0.8896\n",
      "Epoch 12/30\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.2406 - accuracy: 0.9459 - ETA: 48s - loss: 0.2068 - accuracy: 0.9 - ETA: 48s - loss: 0.2083 - accuracy:  - ETA: 48s - loss: 0.2071 - accuracy: 0.96 - ETA: 48s - loss: 0.2112 - accuracy:  - ETA: 48s - los - ETA: 46s - loss: 0.22 - ETA: 45s - loss: 0.2328 - a - ETA: 44s - loss: 0.2308 - accu - ETA: 43s - loss: 0.2266 - accuracy:  - ETA: 43s - loss: 0.2263 - ETA: 42s - loss: 0.2301 - accur - ETA: 41s - lo - ETA: 39s - l - ETA: 37s - loss: 0.2333 - accur - ETA: 37s - loss: 0.2337 - accurac - ETA: 36s - loss: 0.2349 -  - ETA: 35s - loss: 0.2355 - ac - ETA: 28s - loss: 0.23 - ETA: 27s - loss: 0.2376 - accuracy:  - ETA: 27s - loss: 0.2378 - accurac - ETA: 26 - ETA: 24s -  - ETA: 22s - loss: 0.2396 - - ETA: 20s - loss: 0.2393 - accuracy: 0.9 - ETA: 20s - loss: 0.2393 - accuracy: 0 - ETA: 20s - loss: 0.2390 - accuracy:  - ETA: 20s - loss: 0.2388  - ETA: 18s - loss: 0.2383 - accuracy: 0. - ETA: 18s - loss: 0.2378 - a - ETA:  - ETA: 15s - loss: 0.2387 - accuracy:  - ETA: 14s - los - ETA: 13s - loss: 0.2389 - a - ETA: 12s - loss: 0.2402 - accuracy: 0.9 - ETA: 11s - loss: 0.2400 - accuracy:  - - ETA: 7s - loss: 0.2408 - ac - ETA: 7s - ETA:  - ETA: 5s - loss: 0.2405 - accuracy: 0.94 - ETA: 4s - loss: 0.2407 - accura - ETA: 4s - loss: 0.2406 - accuracy: 0. - ETA: 4s - loss: 0.2405 - accuracy: 0.94 - ETA: 4s - loss: 0.2404 - accuracy: 0. - ETA: 4s - loss: 0.2404 - accu - ETA: 3s - loss: 0.2401 - ac - ETA: 3s - loss: 0.240 - ETA:  - ETA: 1s - loss: 0.2 - ETA: 0s - los\n",
      "Epoch 00012: val_accuracy did not improve from 0.89640\n",
      "781/781 [==============================] - 56s 72ms/step - loss: 0.2406 - accuracy: 0.9459 - val_loss: 0.4666 - val_accuracy: 0.8932\n",
      "Epoch 13/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "781/781 [==============================] - ETA: 0s - loss: 0.2441 - accuracy: 0.9461 - ETA: 50s - loss: 0.2491 -  - ETA: 49s - loss: 0.2418 - accuracy: 0 - ETA: 49s - loss: 0.2355 - acc - ETA: 48s - loss: 0.2347 - accuracy: 0.949 - ETA: 48s - loss: 0.2336 - accura - E - ETA: 44s - ETA: 42s - loss: 0.2459 - accuracy: 0.9 - ETA: 42s - loss: 0.2477 - accuracy: 0.9 - ETA: 42s - loss - ETA:  - ETA: 37s - loss: 0.2462 - accuracy:  - ETA: 37s - loss: 0.2465 - accurac - ETA: 36s - loss:  - ETA: 35s - loss: 0.2475 - a - ETA: 34s - loss: 0.2453 - - ETA: 32s - loss: 0.2458 - accuracy: 0.94 - ETA: 32s - ETA: 30s - loss: 0.2458 - - ETA: 29s - loss: 0.2450 - accuracy: 0.94 - ETA: 29s - loss: 0.2451 - accur - ETA: 28s - loss:  - ETA: 27s - loss: 0.2469 - accuracy: 0.9 - ETA: 26s - loss: 0.24 - ETA: 25s - loss - ETA: 23s - loss: 0.2445 -  - ETA - ETA: 20s - loss: 0.2436 - accurac - ETA: - ETA: 17s - loss: 0.2441 -  - ETA: 15s - loss: 0.2433 - accuracy: 0.9 - ETA: 15s - loss: 0.2432 - accuracy: 0.9  - ETA: 12s - loss: 0.243 - ETA: 4s - loss: 0.2441 - accuracy: 0.94 - ETA: 4s - loss: 0.2442 - accuracy: 0. - ETA: 4s - loss: 0.2442  - ETA: 3s - loss: 0.2441 - accuracy: 0. - ETA: 3s - l - ETA: 2s - l - ETA: 0s - loss: 0.2443 - accuracy: 0. - ETA: 0s - loss: 0.2442 - accuracy: 0.94 - ETA: 0s - loss: 0.2443 - accuracy: \n",
      "Epoch 00013: val_accuracy did not improve from 0.89640\n",
      "781/781 [==============================] - 57s 72ms/step - loss: 0.2441 - accuracy: 0.9461 - val_loss: 0.5051 - val_accuracy: 0.8855\n",
      "Epoch 14/30\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.2428 - accuracy: 0.9454 - ETA: 46s -  - ETA: 44s - loss: 0.2392 - accuracy: 0.944 - ETA: 44s - loss: 0.2390 - accuracy: 0 - ETA: 43s - loss: 0.24 - ETA: 42s - loss: 0.2356 - ac - ETA: 41s - loss: 0.2366 - acc - ETA: 38s - loss: 0.2379 - accuracy:  - ETA: 37s - loss: 0.2370 - accuracy:  - ETA: 37 - ETA: 34s - loss: 0.2401 - accu - ETA: 34s - loss: 0.2413 -  - ETA: 33s - loss: 0.2425 - accuracy: - ETA: 32s - loss: 0.2422 - accurac - ETA: 32s - loss: 0.2431 - accuracy: 0 - ETA: 31s - loss: 0.2443 - accuracy:  - ETA: 31s - loss: 0.2435 - accuracy: 0.944 - ETA: 31s - loss: 0.2437 - accuracy: - ETA: 30s - loss: 0.2435 - ac - ETA: 29s - loss: 0.2438 - accuracy: 0.9 - ETA: 29s - loss: 0.2447 - - ETA: 28 - ETA: 26s - loss: 0.2441 - accuracy: 0. - E - ETA: 23s - loss: 0.2449 - accuracy: 0.94 - ETA: 23s - loss: 0.2448 - accuracy: 0.94 - ETA: 23s - loss: 0.2449 - accuracy: 0.9 - ETA: 22s - loss: 0.2450 - accuracy: 0.9 - ETA: 22s - loss: 0.2454 - accuracy: 0 - ETA: 22s - loss: 0.24 - ETA: 20s - loss: 0.24 - ETA:  - ETA: 17s - loss: 0.2431 - accuracy: 0 - ETA: 16s - loss: 0.2432 - accura - ETA: 16s - loss: 0.2441 - acc - ETA: 15s - loss: 0.2435 - accuracy: - ETA: 14s - loss: 0.2432 - - ETA: 13s - loss: 0.2434 - accur - ETA: \n",
      "Epoch 00014: val_accuracy did not improve from 0.89640\n",
      "781/781 [==============================] - 57s 74ms/step - loss: 0.2428 - accuracy: 0.9454 - val_loss: 0.4929 - val_accuracy: 0.8869\n",
      "Epoch 15/30\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.2386 - accuracy: 0.9474 - ETA: 50s - loss: 0 - ETA - ETA: 46s - loss: 0.2328 - accuracy: 0.952 - ETA: 46s - loss: 0.2327 - accuracy: 0.9 - ETA: 45s -  - ET - ETA: 40s - loss: 0.2 - ETA: 39s - loss: 0 - ETA: 37s - loss: 0.2336 - accurac - ETA: 37s - loss: 0.2338 - accuracy: 0.94 - ETA: 36s - loss: 0.2340 - accuracy - ETA: 36s - loss: 0.2339 -  - ETA: 35s - loss: 0.2344 - accurac - ETA: 34s - loss: 0.2354 - accuracy: 0.94 - ETA: 34s - loss: 0.2353 - accuracy: 0. - ETA: 34s - loss: 0.2352 - a - ETA: 33s - loss: 0.2360 - accur - ETA: 32s - loss: 0. - ETA: 31s - loss: 0.2350 - accuracy: 0.948 - ETA: 31s - loss: 0.2348 - acc - ETA: 30s - loss: 0.2350 - ETA: 26s - loss: 0.2357 - accuracy: 0.94 - ETA: 25s - - ETA: 23s - loss: 0.2361 - ac - ETA: 22s - loss: 0.2362 - accuracy: 0. - ETA: 22s - loss: 0.2359 - accuracy: - ETA: 22s - l - ETA: 20s - loss: 0.2363 - accuracy:  - ETA:  - ETA: 0s - loss: 0.2385 - accuracy - ETA: 0s - loss: 0.2387 - accuracy: 0.9474\n",
      "Epoch 00015: val_accuracy improved from 0.89640 to 0.89680, saving model to my_best_model.epoch15-accuracy0.90.hdf5\n",
      "781/781 [==============================] - 57s 73ms/step - loss: 0.2387 - accuracy: 0.9474 - val_loss: 0.4508 - val_accuracy: 0.8968\n",
      "Epoch 16/30\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.2394 - accuracy: 0.9467 - ETA: 48s - loss: 0.2244 - accuracy:  - ETA: 48s - loss:  - ETA: 46s - loss: 0 - ETA: 45s - loss:  - ETA: 43s - loss: 0.2251 - accuracy: 0.94 - ETA: 43s - loss: 0.2248 - acc - ETA: 42s - loss: 0.2305 - a - ETA: 42s  - ETA: 39s - los - ETA: 37s - lo - ETA: 36s - loss: 0.2348 - - ETA: 28s - loss: 0.2370 -  - ETA: 27s - loss: 0.2382 - accuracy:  - ETA: 27s - loss: 0.2385 - accura - ETA: 23s - loss: 0.2379 - accuracy: 0.9 - ETA: 23s - lo - ETA: 21s - loss: 0.2386 - accuracy - ETA: 21s - loss: 0.23 - ETA: 19s - loss: 0.2380 - accuracy: - ETA: 19s - - ETA: 17s - loss: 0.2391 - ETA: 15s - l - ETA: 13s - loss: 0 - ETA: 12s - loss: 0.2397 - accuracy: - ETA: 11s - loss: 0.2395 - accuracy: - ETA: 11s - loss: 0.2401 - accura - ETA: 10s - loss: 0.2402 - accuracy: 0.9 - ETA: 10s - loss: 0.2402 - accuracy: 0. - ETA: 10s - loss: 0.2402 -  - ETA: 8s - loss: 0.2404  - ETA - ETA: 4s - loss: 0.2409 - accu - ETA: 4s - los - ETA: 3s - loss: 0.2406 - accuracy: 0.94 - ETA: 3s - loss: 0.2406 -  - ETA: 2s - loss: 0.2 - ETA: 2s - loss: 0.2401 - accuracy - ETA: 1s - loss: 0.239 - ETA\n",
      "Epoch 00016: val_accuracy did not improve from 0.89680\n",
      "781/781 [==============================] - 56s 72ms/step - loss: 0.2394 - accuracy: 0.9467 - val_loss: 0.5567 - val_accuracy: 0.8738\n",
      "Epoch 17/30\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.2413 - accuracy: 0.9457 - ETA: 48s - loss: 0.2315 - accuracy: 0. - ETA: 48s - loss: 0.2284 - accuracy: 0. - ETA: 47s - loss: 0.2285 - acc - ETA: 4 - ETA: 44s - loss: 0.2291 - accuracy: 0.948 - ETA: 44s - loss: 0 - ETA:  - ETA: 37s -  - ETA: 35s - loss: 0. - ETA: 34s - loss: 0.2332 - accuracy: - ETA: 33s - loss: 0.2336 - accuracy: 0.94 - ETA: 33s - loss: 0.2336 - a - ETA: 32s - loss: 0.2344 - acc - ETA: 31s - loss: 0.2336 - accuracy: 0.947 - ETA: 31s - loss: 0.2337 - accuracy - ETA: 30s - loss: 0.2330 - accurac - ETA: 30s - loss: 0.2330 - accuracy: 0.947 - ETA: 30s - loss: 0 - ETA: 25s - loss: 0. - ETA: 24s - loss: 0.2341 - ac - ETA: 23s - loss: 0.2351  - ETA: - ETA: 19s - loss: 0.2358 - accu - ETA: 19s - loss: 0.2363 - accur - ETA: 18s - loss: 0.2361 - accuracy - ETA: 17s - loss: 0.2362 - accura - ETA: 17s - loss: 0.2365 - accuracy:  - ETA: 16s - lo - ETA: 14s - loss - ETA: 13s - l - ETA: 11s - loss: 0.239 - ETA: 9s - loss: 0.2391 - accuracy:  - ETA: 9s - loss: 0.2393 -  - ETA: 1s - loss: 0.2417 - ac - ETA: 1s - loss: 0.2415 - accu - ETA: 1s - loss: 0.2415 - ac - ETA: 0s - loss: 0.2415 - accuracy - ETA: 0s - loss: 0.2415 - accuracy: 0.94 - ETA: 0s - loss: 0.2413 - accuracy:  - ETA: 0s - loss: 0.2413 - accuracy: 0.94 - ETA: 0s - loss: 0.2412 - accuracy: 0.9457\n",
      "Epoch 00017: val_accuracy did not improve from 0.89680\n",
      "781/781 [==============================] - 56s 72ms/step - loss: 0.2412 - accuracy: 0.9457 - val_loss: 0.5873 - val_accuracy: 0.8709\n",
      "Epoch 18/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "781/781 [==============================] - ETA: 0s - loss: 0.2348 - accuracy: 0.94798- ETA: 48s - loss: - ETA: 47s  - ETA: 45s - loss: 0.2298 - accuracy: 0.9 - ETA: 44 - ETA: 43s - loss: 0.2324 - accuracy: 0 - ETA: 42s - loss: 0.2336 - accuracy: 0. - ETA: 42s - loss: 0.2338 - accu - ETA: 41s - loss: 0.2360 - acc - ETA: 40s - loss: 0.2361 - accu - ETA: 39 - ETA: 37s - - ETA: 35s - loss: 0.2330 - accu - ETA: 34s - loss: 0.2320 - accurac - ETA: 34s - loss: 0.2302 - accuracy - ETA: 33s - loss: 0.2304 - accuracy: 0.9 - ETA: 33s - loss: 0. - ETA: 32s - loss: 0.2324 - accuracy: 0.9 - ETA: 32s -  - ETA: 30s - loss: 0.2306 - accur - ETA: 29s - l - ETA: 27s - loss: 0.2314 - accu - ETA: 26s - loss: 0.2322 - accurac - ETA: 26s - loss: 0.2320 - accur - ETA: 22s - loss: 0.2316 - accuracy:  - ETA: 21s - loss: 0.2322 - ETA: 20s - loss: 0.2337 - accuracy - ETA: 20s - loss:  - ETA: 18s - lo - ETA: 16s - loss: 0.2349 - accu - ETA: 15s - loss: - ETA: 11s - loss: 0.2348 - accuracy: 0.94 - ETA: 11s - loss: 0.2349 - accuracy: 0. - ETA: 10s - loss: 0.2346 - acc - ETA: 10s - loss: 0.2347 - accuracy: 0.947 -  - ETA - ETA: 7s - loss: 0.2339 - accuracy: 0.94 - ETA: 7s - ETA: 6s - loss: - ETA: 5s - loss: 0.2345 - accuracy: 0. - ETA: 5s - loss: 0.2343 - accuracy - ETA: 4s - loss: 0.2343 - accura - ETA: 4s - - ETA: 3s - loss: 0.2 - ETA: 2s - los - E - ETA: 0s - loss: 0.2350 -  - ETA: 0s - loss: 0.2349 - accuracy: 0.94\n",
      "Epoch 00018: val_accuracy did not improve from 0.89680\n",
      "781/781 [==============================] - 56s 72ms/step - loss: 0.2348 - accuracy: 0.9479 - val_loss: 0.4674 - val_accuracy: 0.8911\n",
      "Epoch 19/30\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.2337 - accuracy: 0.9479 - ETA: 48s - loss: 0.2241 - accuracy: - ETA: 48s - loss: 0.2253 - accura - ETA: 47s - loss: 0.2245 - - ETA: 46s - loss: 0.2279 - a - ETA: 45s - loss: 0.2291 - accuracy: 0.947 - ETA: 45s - loss: 0 - ETA: 43s - loss: 0.2326 - accu - ETA: 42s - loss: 0.2311 - accur - ETA: 42s - loss: - ETA: 40s - loss: 0.2306 - - - ETA: 36s - loss: 0. - ETA: 35s - loss: 0.2313 - accuracy: 0.9 - ETA: 3 - ETA: 32 - ETA: 30s - loss: 0.2301 - accuracy: 0.949 -  - ETA: 27s - loss: 0.2311 -  - ETA: 26s - loss: 0.231 - ETA: 24s - loss: 0.231 - ETA: 23s - loss: 0.2329 - accuracy: 0.9 - ETA: 23s - loss: 0.2329 - accuracy: 0.94 - ETA: 23s - loss: 0.2326 - ETA: 22s - loss: 0.233 - ETA: 20s - loss: 0.2 - ETA: 19s - loss: 0.2324 - accuracy: 0.948 - ETA: 19s - loss: 0.2327 - accuracy: 0.9 - ETA: 19 - ETA: 16s - loss: 0.2323 - accuracy:  - ETA: 16s - loss: 0.2327 - accuracy: 0.947 - ETA: 16s - loss: 0.2326 - accuracy: 0.947 - ETA: 16s - loss: 0.2326 - accuracy: 0.9 - ETA: 16s - loss: 0.2326 - accuracy: 0.9 - ETA: 15s - loss: 0.2324 - a - ETA: 14s - loss: 0.2331 - accuracy:  - ETA: 14s - loss: 0.2327 - accuracy - ETA: 13s - loss: 0.2329 - accu - ETA: 13s - loss: 0.2333 -  - ETA: 12s - loss:\n",
      "Epoch 00019: val_accuracy did not improve from 0.89680\n",
      "781/781 [==============================] - 56s 72ms/step - loss: 0.2337 - accuracy: 0.9479 - val_loss: 0.4652 - val_accuracy: 0.8899\n",
      "Epoch 20/30\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.2360 - accuracy: 0.9478 - ETA: 49s - loss: 0.2299 - accuracy: 0.9 - ETA: 49s - - ETA: 47s - loss: 0.2261 - accuracy: 0.94 - ETA: 47s - loss: 0.2256 - accuracy - ETA: 46s - loss - ETA: 44s - loss: 0.2285 - accuracy: 0 - ETA: 44s - loss: 0.2288 - accuracy: - ETA: 44s - loss: 0.2279 - accu - ETA: 43s - loss: 0.2291 - accurac - ETA: 42s - loss: 0.2318 - accura - ETA: 42s - loss: 0.2326 - accuracy: - ETA: 41s - loss: 0.2316 - accuracy: 0.947 - ETA: 41s - loss: 0.2327 - ETA: 40s - loss:  - ETA: 38s - loss: 0.2336 - accuracy: - ETA: 38s - loss: 0.233 - ETA: 37s - loss: 0.2318  - ETA: 36s - ETA: 33s - loss: 0.2331 - accurac - ETA: 33s - loss: 0.2329 - acc - ETA: 32s - loss: 0.2327 - accura - ETA: 31s - lo - ETA: 29s - loss: 0.2329 - accura - ETA: 29s - loss: 0.2328 - accuracy: 0 - ETA: 28s - loss: 0.2338 - accu - ETA: 28s - loss: 0.2 - ETA: 26s - loss: 0.2341 - accuracy - ETA: 26s - loss: 0.2346 - acc - ETA: 25s - loss: 0.2356 - accurac - ETA: 24s - loss: 0.2365 - accuracy: 0.94 - ETA: 18s - loss: 0.2346 - accuracy:  - ETA: - ETA: 15s - loss: 0.2345 - accuracy: 0.948 - ETA: 15s - loss: 0.2346 - - ETA: 14s - loss: 0 - ETA: 13s - loss: 0.2365 - accurac -  - ETA: 7s - loss: 0.2353 - accuracy: 0.94 - - ETA: 2s - loss: 0.2358 - accura - ETA: 2s - loss: 0.2 - ETA: 1s - loss: 0.2359 - accuracy\n",
      "Epoch 00020: val_accuracy did not improve from 0.89680\n",
      "781/781 [==============================] - 56s 71ms/step - loss: 0.2360 - accuracy: 0.9478 - val_loss: 0.4893 - val_accuracy: 0.8911\n",
      "Epoch 21/30\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.2337 - accuracy: 0.9480 - ETA: 48 - ETA: 47s - - ETA: 45s - loss: 0.2369 - ETA: 43s   - ETA: 38s - loss: 0.2317 - accuracy: 0.9 - ETA: 38s - loss: 0.2313 - accuracy: 0.94 - ETA: 38s - loss:  - ETA: 36s - loss: 0.2 - ETA: 34s - loss: 0.2292 - accu - ETA: 31s - loss: 0.23 - ETA: 29s - loss: 0.2308 - accuracy: 0.9 - ETA: 29s - loss: - ETA: 27s - loss - ETA: 26s -  - ETA: 24s - loss: 0.2321 - accuracy:  - ETA: 23s - loss: 0.2321 - accuracy: - ETA: 23s - loss: 0.2323 - ac - ETA: 22s - loss: 0.2310 - accuracy: 0.94 - ETA: 22s - loss: 0.2309 - accuracy:  - ETA: 21s - loss: 0.23 - ETA: 20s - loss: 0.2308 - accu - ETA: 19s - ETA: 17s - loss: 0.2311 - accur - ETA: 16s - loss: 0.2320 - accuracy: 0. - ETA: 16s - loss: 0.2319 - accuracy: 0.948 - ETA: 16s - loss: 0.2320 - ac - ETA: 15s - loss: 0.2313 - accuracy: 0.948 - ETA: 15s - loss: 0.2314 - accuracy: - ETA: 14s - loss: 0.2308 - accuracy: 0.948 - ETA: 14s - loss: 0.\n",
      "Epoch 00021: val_accuracy did not improve from 0.89680\n",
      "781/781 [==============================] - 56s 72ms/step - loss: 0.2337 - accuracy: 0.9480 - val_loss: 0.4804 - val_accuracy: 0.8869\n",
      "Epoch 22/30\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.2342 - accuracy: 0.9483 - ETA: 51s - loss: 0.2225 - accuracy:  - ETA: 50s - loss: 0.2170 - accuracy - ETA: 49s - loss: 0.220 - ETA: 48s - loss: 0.2308 - accu - ETA: 47s - l - ETA: 45s -  - ETA: 43s - loss: 0.2345 - accuracy: 0 - ETA: 43s - loss: 0.2347  - ETA: 42s - los - ETA: 37s - loss: 0.2322 - accu - ETA: 36s - loss: 0.2354 - accu - ETA: 35s -  - ETA: 33s - loss: 0.2345 - accuracy: 0.9 - ETA: 33s - loss: 0.2350 -  - ETA: 20s - loss: 0.2 - ETA: 18s - loss: 0.23 - ETA: 17s - loss: 0.2320 \n",
      "Epoch 00022: val_accuracy did not improve from 0.89680\n",
      "781/781 [==============================] - 56s 72ms/step - loss: 0.2342 - accuracy: 0.9483 - val_loss: 0.4487 - val_accuracy: 0.8949\n",
      "Epoch 23/30\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.2334 - accuracy: 0.9479 - ETA: 50s - loss: 0.2647 - accuracy: 0.926 - ETA: 50s - loss: - ETA: 48s - loss: 0.2327 - accu - ETA: 4 - ETA: 45s - loss: 0.2302 - accuracy: 0.944 - ETA: 45s - loss: 0.2299 - ac - ETA: 44s - loss: 0.2306 - a - ETA: 43s - loss:  - ETA: 41s - loss: 0.2275 - accura - ETA: 41s - loss: 0.2289 - accu - ETA: 40s - loss: 0.2281 - accuracy - ET - ETA: 34s - loss: 0.2314 - accuracy: - ETA: 34s - loss: 0.2315 - accuracy: 0 - ET - ETA: 30s - loss: 0.2318 - accuracy: 0.94 - ETA: 30s - loss: 0.2314 - accuracy: 0 - ETA: 30s - loss: 0.2318 - acc - ETA: 29s - loss: 0.2319  - ETA:  - ETA: 26s - loss: 0.2 - ETA: 24s - loss: 0.2321 - accuracy: 0.94 - ETA: 24s - loss: 0.2322 - accuracy: 0 - ETA: 24s - los - ETA: 22s - loss: 0.2322 - acc - ETA: 21s - loss: 0.231 - ETA: 20s - loss: 0.2 - ETA: 18s -  - ETA: 16s - loss: 0.2322 - accuracy: 0.9 - ETA: 16s - l - ETA: 14s - loss: 0.2323 - accura - ETA: 3s - loss: 0.232 - ETA: 2s - loss: 0.2322 - accuracy: 0.94 - ETA: 2s - loss: 0.2322 - accuracy: 0. - ETA: 2s - loss: 0.2323 - accuracy - ETA: 2s - loss: 0.2323 - accuracy: 0.94 - ETA: 1s - loss: 0.2324  - ETA: 1s - loss: 0.2328 -  - ETA: 0s - loss: 0.2330 - accuracy - ETA: 0s - loss: 0.2330 \n",
      "Epoch 00023: val_accuracy improved from 0.89680 to 0.89850, saving model to my_best_model.epoch23-accuracy0.90.hdf5\n",
      "781/781 [==============================] - 56s 71ms/step - loss: 0.2334 - accuracy: 0.9479 - val_loss: 0.4489 - val_accuracy: 0.8985\n",
      "Epoch 24/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "781/781 [==============================] - ETA: 0s - loss: 0.2355 - accuracy: 0.9471 - ETA: 45s - loss: 0.2229  - ETA: 44s - loss: 0.2250 - accuracy: 0. - ETA: 44s - loss: 0.2244 - ac - ETA: 43s - loss: 0.2286 - accuracy:  - ETA: 42s - loss: 0.2285 - accur - ETA: 42s - loss: 0.2285 - accura - ETA: 41s - loss: 0.2283 - accuracy: 0.9 - ETA: 41s - loss: 0.2286 - accuracy:  - ETA: 41s - loss: 0.2266 - acc - ETA: 40s - loss: 0.2257 - accuracy: 0. - ETA: 39s - loss: 0.2259 - accuracy: 0.948 - ETA: 39s - loss: 0.2262 - accuracy: 0.9 - ETA: 39s - loss: 0.2270 - accuracy: 0 - E - ETA: 36s - loss: 0.2264  - ETA: 35s - loss: 0.2270 - ETA: 34s - loss: 0.22 - ETA: 32s - loss: 0.2268 - accur - ETA: 32s - loss: 0.2265 - accurac - ETA: 31s - loss: 0.2268 - accu - ETA: 30s - loss: 0.2283 - accuracy: 0.94 - ETA: 30s - loss: 0.2278 - accuracy: 0.949 - ETA: 30s - loss: - ETA: 28s - loss: 0.2271 - accuracy: 0 - ETA: 28s - loss: 0.228 -  - ETA: 21s - loss: 0.2309 - accurac - ETA: 21s -  - ETA: 19s - loss: 0.2312 - accuracy: 0.9 - ETA: - ETA: 16s - loss: 0.2337 - accu - ETA: 15s - loss: 0.2336 - accuracy: 0 - ETA: 15s - loss:  - ETA: 13s - loss:  - ETA: 12s - los - ETA: 10s - loss: 0.234 - ETA: 9s - loss: 0.2347 -  - ETA: 7s - loss: 0.2342 - accuracy: 0. - ETA - ETA: 0s - loss: 0.2356 - accura\n",
      "Epoch 00024: val_accuracy did not improve from 0.89850\n",
      "781/781 [==============================] - 56s 72ms/step - loss: 0.2355 - accuracy: 0.9471 - val_loss: 0.4605 - val_accuracy: 0.8976\n",
      "Epoch 25/30\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.2336 - accuracy: 0.9482 - ETA: 49s - loss: 0.2328 - accuracy: 0.950 - ETA: 49 - ETA: 47s - loss: 0.2237 -  - ETA: 46s - loss: 0 - ETA: 44s -  - ETA: 42s - loss: 0.2246 - accurac - ETA: 42s - loss: 0.22 - ETA: 40s - loss: 0.2257 -  - ETA: 39s - loss: 0. - ETA: 38s - loss: 0.2264 - accuracy: 0.9 - ETA: 38s - loss: 0.2262 - accuracy: - ETA: 37s - loss: 0.2249 - ac - ETA: 36s - loss: 0 - ETA: 35s - loss: 0.2270 - ETA: 33s - loss: 0.2272 - accuracy: 0.950 - ETA: 33s - loss: 0.2269 - accura -  - ETA: 30s - loss: 0.  - E - ETA: 20s - loss: 0.2328 - a - ETA: 19s - loss: 0.2329 - accuracy: 0.949 - ETA: 19s - loss: 0.2331 - accuracy: 0 - ETA: 18s - loss: - ET - ETA: 14s - loss: 0.2325 - accuracy: - ETA: 13s - loss: 0. - ETA: 12s - loss: 0.2330 - accura - ETA: 11s - loss: 0.2332 - accuracy: 0.948 - ET - ETA: 5s - loss: 0.2342 - ac - ETA: 4s - l - ETA: 3s - loss: 0 - ETA: 2s - loss: 0.2340 - accu - - ETA: 0s - l\n",
      "Epoch 00025: val_accuracy did not improve from 0.89850\n",
      "781/781 [==============================] - 56s 72ms/step - loss: 0.2336 - accuracy: 0.9482 - val_loss: 0.4511 - val_accuracy: 0.8968\n",
      "Epoch 26/30\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.2296 - accuracy: 0.9499 - ETA: 50s - loss: 0.1943 - accura - ETA: 50s - loss: 0.1954 - a - ETA - ETA: 46s - loss: 0.2109 - acc - ETA: 45s - loss: 0.2113 - ac - ETA: 45s - loss - ETA: 43s -  - ETA: 38s - loss: 0.2267 - accu - ETA: 37s - loss: 0.2244 - accu - ETA: 30s - loss: 0.2243 - accuracy - ETA: 30s - loss: 0.2233 -  - ETA: 29s - loss: 0.2236 - accuracy: 0.9 - ETA: - ETA: 26s - loss: 0.22 - ETA: 22s - loss: 0.2255 - accuracy: 0 - ETA: 21s - loss: 0.2258 - accuracy - - ETA: 18s - loss: 0.2269 - accura - ETA: 17s - loss: 0.2264 - accuracy: 0.9 - ETA: 17s - loss: 0.2262 - ac - ETA: 16s - loss: 0.2269 - accuracy: 0.9 - ETA: 16s - loss: 0.2266 - accuracy:  - ETA: 16s - loss: 0.2266 - acc - ETA: 15s - loss: 0.2280 - accuracy: 0.951 - ETA: 15s - loss: 0.2278 - accu - - - ETA: 0s - loss: 0.2292 - \n",
      "Epoch 00026: val_accuracy did not improve from 0.89850\n",
      "781/781 [==============================] - 56s 72ms/step - loss: 0.2296 - accuracy: 0.9499 - val_loss: 0.5231 - val_accuracy: 0.8820\n",
      "Epoch 27/30\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.2320 - accuracy: 0.9474 - ETA: 50s - loss: 0.2131 - accur - ETA: 50s - loss: 0.2104 - accuracy: 0.95 - ETA: 49s - loss: 0.2132 - accuracy: 0 - ETA: 49s - loss: 0.2111 - accuracy: 0. - ETA: 48s - loss: 0.2115 - accu - ETA: 48s - loss: - ETA: 46s - loss: 0.2193 - acc - ETA: 45s - loss: 0.2181 - accura - ETA: 45s - lo - ETA: 42s - loss: 0.2197 - accurac - ETA: 42s - loss: 0.2179 - accuracy: 0.95 - ETA: 42s - loss: 0.2177 - - ETA: 40s - loss: 0.2194 - accuracy: 0.9 - ETA: 40s - loss: 0.2204 - accuracy: 0.951 - ETA: 40s - loss: 0.2203 - accura - ETA: 39s - loss: 0.22 - ETA: 38s - loss: 0.2234 - accuracy: 0.95 - ETA: 38s - los - ETA: 30s - loss: 0.2277 - accuracy: 0. - ETA: 30s - loss:  - ETA: 22s - loss: 0.2301  - ETA: 18s - loss: 0.2310 - accuracy: 0. - ETA: 18s - l - ETA: 16s - loss: 0.2324 - ETA: 15s - loss: 0.2319 - accuracy: 0. - ETA: 15s - loss: - - ETA: 8s - loss: 0.2322  - ETA - ETA - ETA: 5s - loss: 0.2324 - accuracy: 0.94 - ETA: 5s - loss: 0.2324 - accuracy:  - ETA: 5s - loss: 0.2321 - accuracy:  - E - ETA: 3s - loss: 0.2324 - accuracy: 0. - ETA: 3s - loss: 0.2326 -  - ETA: 3s - loss: 0.2329 - accura - ETA: 3s - loss: 0.2328 - accuracy: 0. - ETA: 2s - loss: 0.2328 - accuracy: 0.94 - ETA: 2s - loss: 0.2327 - accuracy: 0. - ETA: 2s - - ETA: 0s - loss: 0.2319 - accuracy: \n",
      "Epoch 00027: val_accuracy did not improve from 0.89850\n",
      "781/781 [==============================] - 56s 72ms/step - loss: 0.2320 - accuracy: 0.9474 - val_loss: 0.5640 - val_accuracy: 0.8760\n",
      "Epoch 28/30\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.2333 - accuracy: 0.9475 - ETA: 38s - loss: 0. - ETA: 34s - loss: 0.2284 - accuracy - ETA: 33s - loss: 0.2291 - - ETA: 32s - loss: 0.2282 - accurac - ETA: 31s - loss: 0.2290 - accuracy: 0.948 - ETA: 31s - loss: 0.2289 - ac - ETA: 27s - loss: 0.2301 - accuracy: 0  - ETA: 21s - loss: 0.2338 - accuracy: 0.947 - ETA: 21s - loss: 0.2337 - accuracy:  - ETA: 4s - los - ETA: 3s - loss: 0.2334 - accuracy:  - ETA: 3s - loss: 0\n",
      "Epoch 00028: val_accuracy did not improve from 0.89850\n",
      "781/781 [==============================] - 57s 73ms/step - loss: 0.2333 - accuracy: 0.9475 - val_loss: 0.5538 - val_accuracy: 0.8767\n",
      "Epoch 29/30\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.2333 - accuracy: 0.9472 - ETA: 48s - loss: 0.2342 - accuracy - ETA: 44s - loss: 0.2270 - accuracy: 0 - ETA: 43s - loss: 0.2285  - ETA: 39s - loss: 0.2310 - accuracy:  - ETA: 39s - loss: 0.2316 - accuracy:  - ETA: 39s - loss: 0.2308 - accuracy: 0.9 - ETA: 38s - loss: 0.2303 - accura - ETA: 38s - loss: 0.2299 - ETA: 36s - loss: 0.2299 - ac - ETA: 36s - loss: 0.2295 - accuracy:  - ETA: 35s - loss: 0.229 - ETA: 34s - l - ETA: 32s - loss: 0.2310 - acc - ETA: 31s - loss: 0.2312 - accuracy: 0.94 - ETA: 31s - ETA: 26s - loss: 0.2321 - accuracy: 0.94 - ETA: 25s - loss: 0.2322 - accuracy: 0.9 - ETA: 25s - loss: 0.2325 - accuracy: 0.9 - ETA: 25s - loss: 0.2322 - accuracy: 0.9 - ETA: 25s - loss: 0.2321 - accurac - ETA: 24s - loss: 0.2323 - ETA: 20s - lo - ETA: 18s - loss: 0.2332 - acc - ETA: 17s -  - ETA: 15s - loss: 0.2328 - a - ETA: 14s - loss: 0.2329 - accuracy: 0. - ETA: 14s - los - ETA: 2s - l\n",
      "Epoch 00029: val_accuracy did not improve from 0.89850\n",
      "781/781 [==============================] - 57s 72ms/step - loss: 0.2333 - accuracy: 0.9472 - val_loss: 0.4628 - val_accuracy: 0.8927\n",
      "Epoch 30/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "781/781 [==============================] - ETA: 0s - loss: 0.2324 - accuracy: 0.9475 - ET - ETA: 42s - loss: 0.225 - ETA: 41s - loss: 0.2296 - accurac - ETA: 41s - loss: 0.2306 - acc - ETA: 40s - loss: 0.2304 - accu - ETA: 39s - loss: 0.2298 - accuracy - ETA: 38s - loss: 0.229 - ETA: 37s - loss: 0.2289 - accuracy: 0.948 - ETA: 37s - loss: 0.2287 - ETA: 36s - loss: 0.2308 - accur - ETA: 35s - loss: 0.2306 - accura - ETA: 34s - loss - ETA: 23s - loss: 0.2290 - accuracy: 0.9 - ETA: 23s - loss: 0.2292 - accura - ETA: 22s  - ETA: 20s - loss: 0.2292 - accuracy: 0.949 - ETA: 20s -  - ETA: - ETA: 16s - loss: 0.2288 - accuracy: 0.94 - ETA: 15s - loss: 0.228 - ETA: 14s - loss: 0.2293 - - ETA: 13s - loss: 0.2298 - accurac - ETA: 12s - loss: 0.2297 - accuracy: 0.948 - ETA: 12s - loss: 0.2295 - accuracy: 0 - ETA: 12s - ETA: 10s - loss:  - ETA: 7s - loss: 0.2303 - accuracy - ETA: 7s - loss: 0.2304 -  - ETA: 7s - loss: 0.2302 - accuracy: 0. - ETA: 6s - loss: 0.2303  - ETA: 6s - loss: 0.2309 - accu - ETA: 5s - loss: 0.2307 - accu - ETA: 4s - loss: 0.2317 - accuracy:  - ETA: 3s - los\n",
      "Epoch 00030: val_accuracy did not improve from 0.89850\n",
      "781/781 [==============================] - 56s 72ms/step - loss: 0.2324 - accuracy: 0.9475 - val_loss: 0.5717 - val_accuracy: 0.8737\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24af8fedf70>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(img_gen,\n",
    "          steps_per_epoch=steps,\n",
    "          epochs=30,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, y_test),\n",
    "          callbacks=[checkpoint,tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 7780), started 12:48:35 ago. (Use '!kill 7780' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-83256e6dd3147425\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-83256e6dd3147425\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(learning_rate=0.0002,decay=1e-6),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.2124 - accuracy: 0.9541 - ETA: 44s - loss: 0.2047 - accuracy: 0.95 - ETA: 44s - loss: 0.2040 - accuracy: 0.95 - ETA: 44s  - ETA: 42s - ETA: 40s - loss: 0.2075 - accuracy - ETA: 40s - loss: 0.2082 - accuracy - ETA: 39s - loss: - ETA: 37s - loss - ETA: 36s - los - ETA: 28s - loss: 0.2082 - accurac - ETA: 25s - loss: 0.2100 - accuracy: - ETA: 24s - loss: 0.210 - ETA: 23s - loss: 0.2103 - accuracy - ETA: 22s - loss: 0. - ETA: 21s - - ETA: 19s - loss: 0.2115 - accura - ETA: 18s - loss: 0.2124 - accuracy: - ETA: 18s - l - ETA: 16s - loss: 0.2124  - ETA: 14s - loss: 0.2114 - accuracy: 0.954 - ETA: 14s - loss: 0.2114 - accurac - ETA: 4s - loss: 0.2115 - ac\n",
      "Epoch 00001: val_accuracy did not improve from 0.89850\n",
      "781/781 [==============================] - 63s 72ms/step - loss: 0.2124 - accuracy: 0.9541 - val_loss: 0.4724 - val_accuracy: 0.8944\n",
      "Epoch 2/25\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.2080 - accuracy: 0.9563 - ETA: 49s - loss: 0.2028 - accuracy: 0.960 - ETA: 48s - loss: 0.202 - ETA: 44s - loss: 0.204 - ETA: 43s - loss: 0. - ETA: 41s - loss: 0.2052 - accuracy: 0. - ETA: 41s - loss: 0.2041 - accu - ETA: 40s - l - ETA: 38s - loss: - ETA: 37s - loss: 0.2063 - accuracy:  - ETA: 36s - loss: 0.2 - ETA: 35s - loss: 0.2052 - a - ETA: 34s - loss: 0.2 - ETA: 32s - loss: 0.2081 - ac -  - ETA: 26s - loss:  - ETA: 21s  - ETA: 16s - loss: 0.2057 - a - ETA: 15s - loss: 0.2055 - accuracy: 0.95 - ETA: 15s - loss: 0.2054 - accura - ETA: 14s - loss: 0.2054 - accuracy: 0 - ETA: 14s - loss: 0.2050 - accur - ETA: 13s - loss: 0.2057 - E - ETA: 8s - loss: 0.2072 - accu - E - ETA: 5s - loss: 0.207 - ETA: 4s - loss: - ETA: 3s - l - ETA: 1s - loss: 0.2077 -  - ETA: 0s - loss: 0\n",
      "Epoch 00002: val_accuracy did not improve from 0.89850\n",
      "781/781 [==============================] - 56s 71ms/step - loss: 0.2080 - accuracy: 0.9563 - val_loss: 0.4984 - val_accuracy: 0.8906\n",
      "Epoch 3/25\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.2064 - accuracy: 0.9570 - ETA: 41s - loss: 0.1946 - accura - ETA: 40s - loss: 0.1941 - accur - ETA: 37s - loss: 0.1975 -  - ETA: 35s - loss: 0.1963 -  - ETA: 34s - loss: 0.1975 - accuracy: 0 - ETA: 34s - loss: 0.1966 - accuracy: 0.961 - ETA: 34s - loss: 0.1966 - accuracy: 0.9 - ETA: 34s - loss: 0.1964 - ETA: 30s - loss: 0.1979 - - ETA: 28s - l - ETA: 27s - loss: 0.2004 - accuracy: 0 - ETA: 26s - loss: 0.2008 - accur - ETA: 25s - loss: - ETA: 21s - loss: 0.2027 - accuracy: 0 - ETA: 18s - loss: 0.2037 - accuracy:  - ETA: 17s - loss: 0.20 - ETA: 16s - loss: 0.204 - ETA: 15s - loss: 0.2042 - accuracy: 0.957 - ETA: 14s - loss: 0.2041 - ac - ETA: 14s - loss: 0.2043 - accuracy: 0.95 - ETA: 13s - loss: 0.2043 - accur - ETA: 13s - loss: 0.2041 -  - ETA: 12s - loss: 0.2038 - accura - ETA: 11s - loss: 0.2042 - accuracy: 0.95 - ETA: 11s - loss: 0.2044 - accuracy: 0. - ETA: 11s - loss: 0.2044 - ac - ETA: 10s - loss: 0.204 - ETA: 8s - loss: - ETA: 5s - loss: 0.2056 - accu - ETA: 5s - loss: 0.2059 - accuracy: 0.95 - ETA: 5s - loss: 0.2059 - accuracy: 0. - ETA: 5s - loss: 0.2060  - ETA:  - ETA: 3s - loss: - ETA: 1s - loss: 0.2058 - accuracy: 0.95 - ETA: 1s - loss: 0 - ETA: 0s - loss: 0.2062 - accura\n",
      "Epoch 00003: val_accuracy did not improve from 0.89850\n",
      "781/781 [==============================] - 55s 71ms/step - loss: 0.2064 - accuracy: 0.9570 - val_loss: 0.4925 - val_accuracy: 0.8887\n",
      "Epoch 4/25\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.2064 - accuracy: 0.95685- ETA: 48s - loss: 0.2036 - accuracy - ETA: 47s - loss: 0.2127 - accuracy: 0 - ETA: 47s - loss: 0.2117 - accuracy: 0. - ETA: 47s - loss: 0.2068 - accuracy: - ETA: 46s - loss: 0.2027 - accuracy:  - ETA: 46s - loss: 0.2038 - accurac - ETA: 46s - loss: 0.2045 - accuracy - ETA: 45s  - ETA: 43s - loss: 0.2039 - accuracy: - ETA: 43s - loss: - ETA: 41s - loss: 0.2058 - accurac - ETA: 41s - - ETA: - ETA: 36s - loss: 0.2054 - accurac - ETA: 36s - loss: 0.2041 - a - ETA: 35s - loss: 0.2036 - accuracy:  - ETA: 34s - loss: 0.2037 - accuracy - ETA: 34s - loss: 0.2032 - accuracy - ETA: 33s - loss: 0.2031 - accu - ETA: 32s - loss: 0.2018 - ac - ETA: 31 - ETA: 29s - loss: 0.2029 - accuracy - ETA: 29s - loss: 0.2029 - accuracy: - E - ETA: 25s - loss: 0.204 - ETA: 24s -  - ETA: 22s - loss: 0.2059 - accuracy - ETA: 22s - loss: 0.2062 - - ETA: 20s - loss: 0. - ETA: 19s - loss: - ETA: 17s - loss: 0.2068 - accuracy:  - ETA: 17s - loss: 0.2068 - accuracy:  - - ETA: 14s - loss: 0.2058 - ETA: 12s - loss: 0 - ETA: 11s - loss: 0.2049 - accuracy:  - ETA: 10s - loss: 0.2047 - accuracy: - ETA: - ETA: 1s - loss: 0.2054 - accu - E\n",
      "Epoch 00004: val_accuracy improved from 0.89850 to 0.90090, saving model to my_best_model.epoch04-accuracy0.90.hdf5\n",
      "781/781 [==============================] - 56s 71ms/step - loss: 0.2064 - accuracy: 0.9568 - val_loss: 0.4535 - val_accuracy: 0.9009\n",
      "Epoch 5/25\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.2070 - accuracy: 0.9564 - ETA: 49s - loss: 0.1977 - accurac - ETA: 48s - loss: 0.191 - ETA: 47s - loss: 0. - ETA: 45s - loss: 0.2002 -  - ETA: 44s - loss: 0.2012 -  - ETA: 43s - loss: 0.1972 - accurac - ETA: 43s - loss: 0.1973 - accu - ETA: 42s - loss: 0.1 - ETA: 41s - loss: 0.1970 - accura - ETA: 40s - loss: 0.19 - ETA: 39s - loss: 0.1966 - accuracy: 0. - ETA: 36s - loss: 0.197 - ETA: 2 - ETA: 20s - los - ETA: 19s - l - ETA: 17s - loss: 0.2075 - a - ETA: 16s - loss: 0.2071 - ac - ETA: 15s - loss: 0.2073 - accuracy: - ETA: 14s - loss: 0.2072 - accur - ETA: 14s - loss: 0.2070 -  - ETA: 12s - loss: 0.2071 - accuracy:  - ETA: 12s - loss: 0.2071 - accuracy: 0.956 - ETA: 12s - loss: 0.2071 - accuracy: 0 - ETA: 12s - loss: 0.2071 -  - ETA: 11s - loss: 0.2 - ETA: 9s - l - ETA: 7s - l - ETA: 5s - - ETA: 2s - loss: 0.2 - ETA: 1s - loss: 0.2064 -  - ETA: 1s - loss: 0.2067 - ac - ETA: 0s - loss: 0.2061 -  - ETA: 0s - loss: 0.2066 - accura\n",
      "Epoch 00005: val_accuracy did not improve from 0.90090\n",
      "781/781 [==============================] - 55s 71ms/step - loss: 0.2070 - accuracy: 0.9564 - val_loss: 0.4766 - val_accuracy: 0.8951\n",
      "Epoch 6/25\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.2082 - accuracy: 0.9556 - ETA: 49s - loss: 0.2060 - accuracy: - ETA: 49s - loss: 0.2069 - accuracy: 0.96 - ETA: 49s - loss: 0.2100 - accuracy: 0.957 - ETA: 49s - loss: 0.2113 - accuracy: 0. - ETA: 48s - loss: 0.2158 - accur - ETA: 48s - loss - ETA: 46s - loss: 0.2169 - a - ETA: 42s - loss: 0.2084 - accuracy - ETA: 42s - loss: 0.2091 - accuracy: 0.9 - ETA: 42s - loss: 0.2087 - accu - ETA: 41s - loss: 0.209 - ETA: 40s - loss: 0.2097 - accurac - ETA: 39s - loss: 0.2087 - accuracy:  - ETA: 39s - loss: 0.2072 - ac - ETA: 38s - loss: 0.2065 - accuracy: 0. - ETA: 37s - loss: 0.2068 - accuracy: 0.955 - ETA: 37s - loss: 0.2064 - a - ETA: 36s - loss: 0.2069 - accuracy: 0.95 - ETA: 36s - l - ETA: 34s - loss: 0.2065 - accuracy: 0 - ETA: 34s - loss: 0.2066 - accuracy: 0.9 - ETA: 34s - loss: - ETA: 32s - loss: 0.2054 - accuracy: 0. - E - ETA: 29s - loss: 0. - ETA: 27s - ETA: 25s - loss: 0.20 - ETA: 24s - loss: 0.2075 - accuracy: 0.956 - ETA: 24s - loss: 0.2076  - ETA: 14s - loss: 0.2057 - accur - ETA: 13s - loss: 0.2060 - accurac - ETA: 12s - loss: 0.2 - ETA: 0s - loss: 0.2083 - accu\n",
      "Epoch 00006: val_accuracy did not improve from 0.90090\n",
      "781/781 [==============================] - 56s 71ms/step - loss: 0.2082 - accuracy: 0.9556 - val_loss: 0.4484 - val_accuracy: 0.8998\n",
      "Epoch 7/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "781/781 [==============================] - ETA: 0s - loss: 0.2055 - accuracy: 0.9560 - ETA: 47s - loss: 0.1987 - accuracy - ETA: 46s - loss:  - ETA: 45s - loss: 0.2007 - accurac - ETA: 44s - loss: 0.1994 - accuracy: 0. - ETA: 44s - ETA: 39s - loss: 0.1977 - accuracy: 0.95 - ETA: 39s - loss: - ETA: 37s - loss: 0.1985 - accuracy:  - ETA: 37s -  - ETA: 35s - loss: 0.1983 - a - E - ETA: 32s - loss: 0.19 - ETA: 30s - loss: 0.1988 - accuracy: 0 - ETA: 30s - loss: 0.1983 - accuracy: 0 - ETA: 29s - loss: 0.1981 - accuracy: - - ETA: 26s - loss:  - ETA: 25s - loss: 0.2000 - accuracy - ETA: 24s - loss: 0.2005 - accuracy: 0. - ETA: 24s - loss: 0.2007 - accuracy: 0.958 - ETA: 24s - loss: 0.2006 - accuracy: 0 - ETA: 24s - loss: 0.2013 - accuracy: 0.958 - ETA: 23s - loss: 0.2014 - accur - ETA: 23s - loss: 0.2023 - acc - ETA: 22s - loss: 0 - ETA: 20s - loss: 0.2025 - accuracy: 0.95 - ETA: - - ETA: 15s - loss: 0.2037 - accuracy: 0.9 - ETA: 15s - loss: 0.2038 - accuracy: - ETA: 14s - loss: 0.2040 - a - ETA: 13s - loss: 0.20 - ETA: 12s - loss: 0.2045 - accurac - ETA: 11s - loss: 0.2044 - accuracy:  - ETA: 9s - loss: 0.2049 - accura - ETA:  - ETA: 6s - loss: 0.2050 - accuracy: 0.95 - ETA: 6s - loss: 0.2050 - accuracy - ETA: 5s - loss: 0.2047 - accuracy: 0.95 - ETA: 5s - loss: 0.2046 - accuracy: 0. - ETA: 5s - loss: 0.2 - ETA: 4s - loss: 0.2047 - accu - ETA: 0s - loss: 0.2055 - accuracy: \n",
      "Epoch 00007: val_accuracy did not improve from 0.90090\n",
      "781/781 [==============================] - 56s 72ms/step - loss: 0.2055 - accuracy: 0.9560 - val_loss: 0.4788 - val_accuracy: 0.8916\n",
      "Epoch 8/25\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.2015 - accuracy: 0.95928- ETA: 49s - loss: 0.1895 - acc - ETA: 48s - loss: 0.1897 - accuracy: 0 - ETA: 48s - loss: 0.1915 - acc - ETA: 47s - loss: 0.1930 - accuracy: 0 - ETA: 46s - loss: 0.1924 - accura - ETA: 46s - loss: 0.1925 - accuracy:  - ETA: 45s - loss:  - ETA: 4 - ETA: 41s - loss: 0.1930 - accuracy:  - ETA: 41s - loss: 0.1957 - accuracy: 0.96 - ETA: 40s - los - ETA: 38s - loss: 0.1967 - accuracy: 0. - ETA: 38s - loss: 0.1965 - ac - ETA: 37s - loss: 0.1966 - acc - ETA:  - ETA: 28s - loss: 0.1959 - accuracy: 0.961 - ETA: 28s - loss: 0.1961 - accurac - ETA: 27s - loss: 0.1965 - accuracy: - ETA: 27s - loss: 0.1967 - accuracy: 0. - ETA: 27s - loss: 0.1965 - accuracy:  - ETA: 26s - loss: 0.1969 - accuracy: 0.9 - ETA: 26s - loss: 0.197 - ETA: 25s - loss: 0.1969 - ac - ETA: 24s - loss: 0.1972 - a - ETA: 23s - loss: 0.1976  - ETA: 22s - loss: 0. - ETA: 2 - ETA: 18s - loss: 0.1991 - ac - ETA: 17s - loss: 0.1986 - accur - ETA: 16s - loss: 0.1988 - accura - ETA: 15s - loss: 0.1995 - accura - ETA: 15s - loss - ETA: 13s - loss: 0.2000 - accuracy:  - ETA: 13s  - ETA: 11s - loss: 0.2012 - accuracy: 0.95 - ETA: 10s - loss: 0.2010 - accura - ETA: 10s - loss: 0.2010 - accuracy: 0. - ETA: 9s -  - ETA: 8s - ETA: 7s - - ETA: 6s - loss: 0.2015 - accuracy - ETA: 6s - loss: 0.2017 -  - ETA: 5s - loss: 0.2019 - ac - ETA: 5s - loss: 0.2016 - accuracy: 0. - ETA: 3s - loss: 0.2015 - accuracy:  - ETA: 2s - l - ETA: 1s - loss: 0.2019 - accuracy: 0.95 - ETA: 1s - loss: 0.201 - ETA: 0s - loss: 0.2018 - \n",
      "Epoch 00008: val_accuracy did not improve from 0.90090\n",
      "781/781 [==============================] - 56s 72ms/step - loss: 0.2015 - accuracy: 0.9592 - val_loss: 0.4593 - val_accuracy: 0.8994\n",
      "Epoch 9/25\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.2014 - accuracy: 0.9583 - ETA: 49s - loss: 0.1918 - ac - ETA: 48s - loss: 0.1926 - accuracy: 0.9 - ETA: 48s - loss: 0.1919 - accuracy: 0. - ETA: 47s - loss: 0.1922 - accuracy: 0 - ETA: 47s - loss: 0.1937 - accuracy: 0 - ETA: 46s - loss: 0.1 - ETA: 40s - loss: 0.1971 - a - ETA: 39s - loss: 0.1968 - accuracy:  - ETA: 38s - loss: 0.1974 - accuracy: 0.9 - ETA: 38s - loss: 0.1966 - accuracy:  - ETA: 26s - loss: 0.1997 - accuracy: 0.95 - ETA: 26s - loss: 0.1996 - accuracy: 0. - ETA: 26s - loss:  - ETA: 21s - loss: 0.1996 - accura - ETA: 20s - loss: 0.2001 - accuracy: 0.9 - ETA: 20s - loss: 0.2003 - accurac - ETA: 19s - loss: 0.1996 - accuracy: 0. - ETA: 13s - loss: 0.1999 - accuracy: - ETA: 13s - loss: 0.1996 - accura - ETA: 9s - loss: 0.1995 - accu - ETA - ETA: 6s - l - ETA: 5s - loss: - ETA: 4s - loss: 0.2006 - ac - ETA: 4s - loss: 0.2008 - accuracy: 0.95 - ETA: 4s - loss: 0.2 - ETA: 3s - loss: 0.2010 - accuracy: 0.95 - ETA: 3s - loss: 0 - ETA: 2s - loss: 0.2 - ETA: 2s - loss: - ETA: 1s - loss: 0.2013 - accura - ETA: 0s - loss: 0.2014 - accu - ETA: 0s - loss: 0.2011 - ac\n",
      "Epoch 00009: val_accuracy did not improve from 0.90090\n",
      "781/781 [==============================] - 56s 71ms/step - loss: 0.2014 - accuracy: 0.9583 - val_loss: 0.4888 - val_accuracy: 0.8952\n",
      "Epoch 10/25\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.1986 - accuracy: 0.9583   - ETA: 47s - loss: 0. - ETA: 46s - loss: - ETA: 44s - loss: 0.1970  - ETA: 40s - loss: 0.1973 - accuracy: - ETA: 40s - loss: 0.1969 - accuracy: 0.9 - ETA: 40s - loss: - ETA: 38s - loss: 0.1972 - ac - ETA: 37s - loss: 0.1961 - accuracy - ETA: 37s - loss: 0.1952 - accuracy: 0 - ETA: 36s - loss: 0.1955 - accu - ETA: 35s - loss:  - ETA: 34s - loss: 0.1951 - accura - ETA: 33s - loss: 0.1948 - accuracy: 0.9 - ETA: - ETA: 31s - loss: 0.1938 - ETA: 29s - loss: 0.1948 - accuracy: 0 - ETA: 29s - loss: 0.1952 -  - ETA: 28s - loss: 0.1946 - accurac - ETA: 27s - loss: 0.1953 - accurac - ETA: 27s - loss: 0.1947 - accuracy: 0. - ETA: 26s - - ETA: 24s - loss: 0.19 - ETA: 23s - loss: 0.1949 - ac - ETA: 22s - loss: 0.1958 - accuracy: 0.9 - ETA: 22s - loss: 0.1957 - accuracy: 0.96 - ETA: 22s - los - ETA: 20s - loss: 0.1961 - accur - ETA: 19s - loss: 0.1967 - accuracy: 0.960 - ETA: 19s - loss: 0.1965 - accuracy: 0.960 - ETA: 19s - -  - ETA: 14s - loss: 0.1979 - accuracy: 0.959 - ETA: 14s - los - ETA:  - ETA: 1s - loss: 0.1988 - accuracy: 0.95 - ETA: 1s - loss: 0.1988 - accura - ETA: 0s - loss: 0.1987 -  - ETA: 0s - loss: 0.1986 - accura\n",
      "Epoch 00010: val_accuracy did not improve from 0.90090\n",
      "781/781 [==============================] - 56s 72ms/step - loss: 0.1986 - accuracy: 0.9583 - val_loss: 0.5063 - val_accuracy: 0.8943\n",
      "Epoch 11/25\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.2018 - accuracy: 0.9567 - ETA: 48s - loss: 0.1931 - accuracy: 0.959 - ETA: 48s - loss: 0.1905  - ETA: 47s - loss: 0.1867 - accu - ETA: 47s - loss:  - ETA: 46s - loss: 0.1937 - ETA: 45s - loss: 0.1897 - accura - ETA: 44s - loss: 0.1918 - accuracy: 0.9 - ETA: 44s - loss: 0.19 - ETA: 42s - loss: 0.1928 - ac - ETA: 41s - loss: 0.19 - ETA: 40s - loss: 0.1966 - accuracy: 0.9 - ETA: 3 - ETA: 34s - loss: 0.1983 - accur - ETA: 34s - loss: 0.1975 - accuracy: 0.9 - ETA: 34s - loss: 0.1975 - accuracy: 0.958 - ETA: 33s - loss: 0.1974 - accuracy: 0.95 - ETA: 33s - loss: 0.1974 - accuracy  - ETA: 30s - loss: - ETA: 28s - loss: 0.1971 - accu - ETA: 24s - loss: 0.1983 - accuracy: 0.958 - ETA: 24s - loss: 0.1983 - accuracy: 0.9 - ETA: 24s - loss: 0.1986 - accura - ETA: 23s - loss: 0.1988 - accuracy: 0. - ETA: 23s - loss: 0.1990 - ETA: 22s - loss: 0.1983 - accuracy: - ETA: 21s - loss: 0.1987 - accuracy: - ETA: 21s - loss: 0.1990 - accur - ETA: 20s - loss: 0.2007 - accuracy: - ETA: 20s - loss: 0.2003 - accuracy: 0.95 - ETA: 20s - loss: 0.2003 - ETA: 1 - ETA: 16s - loss: 0. - ETA: 15s - loss: 0.2000 - accuracy: 0.9 - ETA: 14s - loss: 0.2000 -  - ETA: 13s - loss: 0.1999 - accuracy:  - ETA: 13s - loss: 0.1 - ETA: 8s - loss: 0.2004 - accura - ETA: 7s - loss: 0.2001 - accuracy: 0. - ETA: 7s - l - ETA: 6s - loss: 0.2007 - accura - ETA: 6s - los - ETA: 2s - l - ETA: 1s - los - ETA: 0s - loss: 0.2016 - \n",
      "Epoch 00011: val_accuracy did not improve from 0.90090\n",
      "781/781 [==============================] - 56s 71ms/step - loss: 0.2018 - accuracy: 0.9567 - val_loss: 0.4576 - val_accuracy: 0.8983\n",
      "Epoch 12/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "781/781 [==============================] - ETA: 0s - loss: 0.2012 - accuracy: 0.9582 -  - ETA: 46s - ETA: 43s - loss: 0.1961 - accuracy - ETA: 43s - loss: 0.1957 -  - ETA: 42s - loss: 0.1969  - ETA: 41s - loss: 0.1970 - ac - ETA: 37s - loss: 0.1964 - accuracy:  - ETA: 33s - lo - ETA: 31s - loss: 0.1988 - a - ETA: 30s - loss: 0.1975 - accurac - ETA: 29s - loss: 0.1978 - ac - ETA: 28s - loss: 0.1987 - a - ETA: 27s - lo - ETA: 25s - loss: 0. - ETA: 24s - loss: 0.1993 - accuracy:  - ETA: 23 - ETA: 21s - loss: 0.1995 - a - ETA: 20s - loss: - ETA: 18s - loss: 0.1999 - accuracy: 0 - ETA: 18s - loss: 0.1995 - - ETA: 17s - lo - ETA: 15s - loss: 0.2010  - ETA: 11s - loss: 0.2013 - accuracy: 0.9 - ETA: 11s - loss: 0.2012 - accu - ETA: 10s - loss: 0.2009 - ac - ETA: 8s - loss: 0.2010 - accu - E - ETA: 3s - loss: 0.2011 - accura - E - ETA: 1s - loss: 0.2009 -  - ETA: 1s - loss: 0.2008 - accu - ETA: 0s - l\n",
      "Epoch 00012: val_accuracy did not improve from 0.90090\n",
      "781/781 [==============================] - 56s 72ms/step - loss: 0.2012 - accuracy: 0.9582 - val_loss: 0.4648 - val_accuracy: 0.9000\n",
      "Epoch 13/25\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.1993 - accuracy: 0.9581 - ETA: 50s - loss: 0.2074 - accura - ETA: 49s - loss: 0.2061 - accuracy: - ETA: 49s - loss: 0.1962 - accur - ETA: 48s - loss: 0.2057 - a - ETA: 47s - loss: 0.1979 - a - ETA: 46s - loss: 0.1967 - accuracy: 0.95 - ETA: 46s - loss: 0 - ETA: 35s - loss: 0.1958 - accuracy: 0.95 - ETA: 35s - loss: 0.1958 - - ETA: 34s - loss: 0.1957 - accuracy: 0. - ETA: 34s - loss: 0.1968 - accuracy - ETA: 33s - loss: 0.1977 - accu - ETA: 33s - loss: 0.1961 - accur - ETA: 32s - loss: 0.1971 - accurac - ETA:  - ETA: 29s - loss: 0.1976 - accuracy: 0.9 - ETA: 29s - loss: 0.1 - ETA: 27s - loss: 0.1984 - ac - ETA: 26s - loss: 0.1991 - accuracy - ETA: 26s - loss: 0.1993 - accur - ETA: 25s - loss: 0.1995 - accuracy: 0.9 - ETA: 25s - loss: 0.1996 - accuracy: 0.95 - ETA: 25s - loss:  - ETA: 20s - loss: 0.1995 - accuracy: 0.9 - ETA: 20s - loss: 0.1996 - accuracy: 0.95 - ETA: 20s - loss: 0.19 - ETA: 18s - loss: 0.1993 - accuracy: 0.95 - ETA: 18s - loss: 0.1992 - accuracy: - ETA: 18s - loss: 0.1989 - - ETA: 17s -  - ETA: 12s - loss: 0.2006 - accura - ETA: 11s - loss: 0.2006 - accuracy: 0 - ETA: 11s - loss: 0.2000 - accuracy: 0 - ETA:  - ETA: 6s - loss: 0 - ETA: 5s - loss: 0.2006 - accuracy: 0.95 - ETA: 5s - ETA: 4s - loss: 0.2004 - accuracy: 0.95 - ETA: 4s - loss: 0.2004 - accuracy - ETA: 4s - loss: 0.2002 - accuracy: 0.95 - ETA: 3s - loss: 0.2 - ETA: 1s - loss: 0 - ETA: 0s - loss: 0.1996 - accuracy: 0. - ETA: 0s - loss:\n",
      "Epoch 00013: val_accuracy did not improve from 0.90090\n",
      "781/781 [==============================] - 56s 72ms/step - loss: 0.1993 - accuracy: 0.9581 - val_loss: 0.4656 - val_accuracy: 0.8986\n",
      "Epoch 14/25\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.1999 - accuracy: 0.9578 - ETA: 47s - loss: 0.1942 - accuracy - ETA: 46s - loss: - ETA: 44s - loss: 0.1962 - accuracy: 0 - ETA: 44s - loss: 0.1970 - a - ETA: 43s - loss: 0.1967 - accur - ETA: 43s - loss: 0.1969 - acc - ETA: 42s - loss: 0.1965 - ETA: 40s - loss: 0.1980 - accura\n",
      "Epoch 00014: val_accuracy did not improve from 0.90090\n",
      "781/781 [==============================] - 56s 72ms/step - loss: 0.1999 - accuracy: 0.9578 - val_loss: 0.4597 - val_accuracy: 0.9007\n",
      "Epoch 15/25\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.2024 - accuracy: 0.9563 - ETA: 50s - l - ETA: 45s - loss: 0.2010 - a - ETA: 44s - loss: 0.1984 - - ETA: 40s - loss: 0.1974 - accuracy: 0 - ETA: 40s - loss: 0.1 - ETA: 38s - loss: 0.1986 -  - ETA: 37s - loss: 0.1977 - ETA: 30s - loss: 0.1998 - accuracy: 0. - ETA: 30s - loss: 0.200 - ETA: 28s - l - ETA: 26s - loss: 0.2011 - accuracy: 0.9 - ETA: 26s - loss: 0.2009 - - ETA: 25s - loss: 0.2012 - accuracy: 0 - ETA: 25s - loss: 0.2010 -  - ETA: 24s -  - ETA: 22s - loss: 0.2015 - accuracy:  - ETA: 21s - loss: 0.2017 - a - ETA: 20s - loss: 0.2016 - accuracy: 0.95 - ETA: 20s - lo - ETA: 18s - loss: - ETA: 17s - loss: 0.2017 - - ETA: 16s - loss: 0.2015 - accur - ETA: 15s - loss: 0.2012 - accu - ETA: 14s - loss: 0.2015 - accura - ETA: 13s - loss: - ETA: 12s - loss - ETA: 8s - loss: 0.2 - ETA:  - ETA: 6s - loss: 0 - ETA:  - ETA: 3s - loss: 0 - ETA: 2s - loss: 0.2026 - accuracy - ETA: 2s - los\n",
      "Epoch 00015: val_accuracy improved from 0.90090 to 0.90430, saving model to my_best_model.epoch15-accuracy0.90.hdf5\n",
      "781/781 [==============================] - 56s 72ms/step - loss: 0.2024 - accuracy: 0.9563 - val_loss: 0.4338 - val_accuracy: 0.9043\n",
      "Epoch 16/25\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.1988 - accuracy: 0.95832- ETA: 49s - loss: 0.1952 - accuracy - ETA: 45s - loss: 0.1879 - accuracy: 0 - ETA: 44s - loss: 0.1892 - ac - ETA: 44s - loss: 0.1922 - accuracy: 0.960 - ETA: 44s - loss: 0.1929 - ac - ETA: 40s - loss: 0. - ETA: 38s - loss: 0.1958 - accuracy: 0 - ETA: 38s - loss: 0.1953  - ETA: 37s - loss: 0.1954 - accuracy: - ETA: 36s - loss: 0.1953 - a - ETA: 35s - loss: 0 - ETA: 34s - loss: 0.1 - ETA: 32s  - ETA: 30s - loss: 0.1960 - accuracy:  - ETA: 30s - loss: 0.1973 - accuracy: 0.95 - ETA: 29s - loss: 0.1972 - accuracy: 0.958 - ETA: 29s - loss: 0.1970 - accuracy: 0.9 - ETA: 29s - loss: 0.1965 - accura - ETA: 23s - loss: 0.1948 - accur - ETA: 22s - loss: 0.1952 - accur - ETA: 21s - loss: 0.1951 - accuracy: 0.95 - ETA: 21s - loss: 0.1951 - accuracy:  - ETA: 21s - loss: 0.1947 -  - ETA: 17s - loss: 0.1966 - accuracy: 0. - ETA: 17s - loss: 0.1970 - a - ETA: 16s - loss: 0.1971 - accuracy: 0.958 - ETA: 15s - l - ETA: 10s - - ETA: 6s - loss: 0.1981 -  - ETA: 4s - loss: 0.1984  - E - ETA: 1s - loss: 0 - ETA: 0s - loss: 0.1985 - accura\n",
      "Epoch 00016: val_accuracy did not improve from 0.90430\n",
      "781/781 [==============================] - 56s 72ms/step - loss: 0.1988 - accuracy: 0.9583 - val_loss: 0.4902 - val_accuracy: 0.8909\n",
      "Epoch 17/25\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.1976 - accuracy: 0.95783- ETA: 48s - loss - ETA: 49s - loss: 0.1856 - accur - ETA: 48s - loss - ETA: 45s - loss: 0.1846 - accuracy: 0 - ETA: 45s - loss: 0. - ETA: 44s  - ETA: 42s - loss: 0.1886 - accuracy: 0.9 - ETA: 42s - loss: 0.1890 - accuracy: 0.95 - ETA: 42s - loss: 0.1883 - accuracy: 0. - ETA: 41s - loss: 0.1888 - - ETA: 40s - loss: 0.1899 -  - ETA: 39s - loss: 0.1903 - ETA: 38s - loss: 0.1931 - accurac - ETA: 37s - loss: 0.1936 - accuracy: 0. - ETA: 37s - loss: 0.1933 - accura - ETA: 36s - - ETA: 34s - - ETA: 32s - l - ETA: 30s - loss: 0.1938 - accuracy: 0.95 - ETA: 30s - loss: 0.1934 - accuracy: 0.957 - ETA: 30s - loss: 0.1938 - accuracy: 0.9 - ETA: 30s - loss: 0.1935  - ETA: 29s - loss: 0.1921 - accuracy: - ETA: 28s - loss: 0.1922 -  - ETA: 27s - loss: 0.1917 - accuracy - ETA: 27s - loss: 0.1914 - accu - ETA: 23s - loss: - ETA: 21s - loss: 0.1922 - accuracy: 0 - ETA: 21s -  - ETA: 16s - loss: 0.19 - ETA: 15s - loss: 0.1956 - accura - ETA: 14s - loss: 0.1966 - accura - ETA: 13s - loss: 0.1972 - accuracy: - ETA: 13s - loss: 0. - ETA: 11s - loss: 0.19\n",
      "Epoch 00017: val_accuracy did not improve from 0.90430\n",
      "781/781 [==============================] - 56s 71ms/step - loss: 0.1976 - accuracy: 0.9578 - val_loss: 0.4803 - val_accuracy: 0.8936\n",
      "Epoch 18/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "781/781 [==============================] - ETA: 0s - loss: 0.1964 - accuracy: 0.9588 - ETA: 50s - loss: 0.17 - ETA: 48s - loss: 0.1850 - accuracy - ETA: 47s - loss: 0 - ETA: 45s - loss: 0.1953 - accuracy:  - ETA: 45s - loss: 0.1952 - accuracy: 0. - ETA: 45s - loss: 0.1934 - accuracy: 0.95 - ETA: 45s - loss: 0.1939 - accuracy: 0 - ETA: 44s - loss: 0.1942 - accuracy: 0. - ETA: 44s - loss: 0.1943 - accuracy:  - ETA: 44 - ETA: 42s - loss: 0.1905 - accuracy: 0.95 - ETA: 41s - loss: 0.1908 - a - ETA: 37s - loss: 0.1935 - accurac - ETA: 37s - loss: 0.1933 - accuracy: 0.95 - ETA: 37s - loss: 0.1932 - accuracy: - ETA: 36s - loss: 0.1936 - accuracy: 0. - ETA: 36s - loss:  - ETA: 34s - loss: 0.1914 - accuracy: 0. - ETA: 34s - loss: 0.1912 - accuracy: 0.9 - ETA: 31s - loss - ETA: 26s - loss: 0.1 - ETA: 25s - loss: 0.1979 - - ETA: 24s - loss: 0 - ETA: 22s - l - ETA: 20s - loss: 0.1985 - accuracy: 0.958 - ETA: 20s - los - ETA: 18s - loss: 0.19 - ETA: 17s  - ETA: 15s - loss: 0.1979 - accuracy: 0 - ETA: 14s - loss: 0.1978 - accurac - ETA: 14s - loss: 0.1979 - accuracy: 0.95 - ETA: 14s - loss: 0.1978 - accuracy: - ETA: 13s - loss: 0.1974 - accurac - ETA: 13s - loss: 0.1971 - a - ETA: 5s - l - ETA: 4s - loss: 0.1957 - accuracy - ETA: 3s - ETA: 2s - loss: 0 - ETA: 1s - loss: 0.1961 - \n",
      "Epoch 00018: val_accuracy did not improve from 0.90430\n",
      "781/781 [==============================] - 56s 71ms/step - loss: 0.1964 - accuracy: 0.9588 - val_loss: 0.4603 - val_accuracy: 0.8997\n",
      "Epoch 19/25\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.1974 - accuracy: 0.9590 - ETA: 51s - loss: 0.1676 - accuracy:  - ETA: 52s - loss: 0.1573 - ETA: 50s - loss: 0.1934 - accuracy: - ETA: 49s - loss: 0.1897 - accuracy: 0.965 - ETA: 49s - loss: 0.1925 - accuracy: - ETA: 48s - loss: 0.1918 - accuracy: 0.9 - ETA: 48s - loss: 0.1904 - acc - ETA: 47s - loss: 0.1949 - accuracy: - ETA: 47s - loss: 0.1917 - accuracy: 0.962 - ETA: 46s - loss: 0.1924 - accurac - ETA: 46s - loss:  - ETA: 44s - loss: 0.1873 - ETA: 43 - ETA: 41s - loss: 0.1934 - accuracy:  - ETA: 40s - loss: 0.1 - ETA: 39s - loss: 0.1949 - accur - ETA: 38s - loss: 0.1945 - accuracy: - ETA: 38s - loss: 0.1935 - accuracy: 0.9 - ETA: 38 - ETA: 35s - loss: 0.1937 - accu - ETA: 35s - loss: 0.1921 - accuracy - ETA: 34s - loss: 0 - ETA: 32s - loss:  - ETA: 31s - loss: 0.1933 - - ETA: 30s - loss: 0.1934 - accurac - ETA: 29s - loss: 0.19 - ETA: - ETA: 25s - loss: 0.1923 - accurac - ETA: 24s - loss: 0.1929 - accuracy: 0.96 - ETA: 24s - loss: 0.1930  - ETA: 20s - loss: 0.1955 - accuracy: 0.95 - ETA: 20s - loss: 0.1954 - ETA: 19s - loss: 0.1957 - accuracy:  - ETA: 18s - loss: 0.1955 - accura - ETA: 18s - loss: 0.1956 - accuracy - ETA: 17s - loss: 0.1953 - accur - ETA: 16s - loss: 0.1950 - a - ETA: 15s - loss: 0.1956 - accuracy:  - ETA: 15s - loss: 0.1955  - ETA: 14s - loss: 0.1959 - accuracy: 0.9 - ETA: 14s - loss: 0.1957  - ETA: 12s - loss: 0. - ETA: 4s - loss: 0.1965 - accuracy: 0.95 - ETA: 4s - loss: 0.1966 - ac - ETA: 2s - ETA: 0s - loss: 0.1976 - accuracy: \n",
      "Epoch 00019: val_accuracy did not improve from 0.90430\n",
      "781/781 [==============================] - 56s 72ms/step - loss: 0.1974 - accuracy: 0.9590 - val_loss: 0.4722 - val_accuracy: 0.9002\n",
      "Epoch 20/25\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.2001 - accuracy: 0.9577 - ETA: 48s - loss: 0.1983 - accuracy:  - ETA: 48s - ETA: 46s - loss: 0.1944 -  - ETA: 45s - loss: 0.1934 - accuracy: 0 - ETA: 44s - loss: 0.1948 - accur - ETA: 44s - loss: 0.1973 - acc - ETA: 43s - loss: 0.1979 - ac - ETA: 42s - loss: 0.1966 - ac - ETA: 3 - ETA: 32s - loss: 0.1991 - accuracy: 0.9 - ETA: 32s - loss: 0.1995 - accuracy: 0.9 - ETA: 32s - loss: 0.2000 - accur - ETA: 31s - loss: 0.2000 - accuracy: 0 - ETA: 31s - loss - ETA: 29s - loss: 0.1997 -  - ETA: 28s - loss: 0.200 - ETA: 27s - loss: 0.1998  - ETA: 25s - loss: 0.1995 - accuracy: 0.9 - ETA: 25s - loss: 0.1994 - accuracy:  - ETA: 25s - loss: 0.1998 -  - ETA: 24s - loss: 0.1994  - ETA: 22s - loss: - ETA: 21s - - ETA: 19s - loss: 0. - ETA: 1s - - ETA: 0s - loss: 0.2001 - ac - ETA: 0s - loss: 0.2000 - accura\n",
      "Epoch 00020: val_accuracy did not improve from 0.90430\n",
      "781/781 [==============================] - 57s 73ms/step - loss: 0.2001 - accuracy: 0.9577 - val_loss: 0.4824 - val_accuracy: 0.8955\n",
      "Epoch 21/25\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.1985 - accuracy: 0.9575 - ETA: 48s - loss: 0.1906 - accuracy: 0. - ETA: 49s - loss: 0.192 - ETA: 47s - loss: 0.1984 - accuracy: 0 - ETA: 47s - loss: 0.1996 - accuracy: 0. - ETA: 47s - loss: 0.2010 - accurac - ETA: 46s - loss: 0.2005 - accuracy: 0.957 - ETA: 46s - loss: 0.2002 - acc - ETA: 45s  - ETA: 43s - loss - ETA: 41s - - ETA: 39s - - ETA: 37s - loss - ETA: 35s - loss: 0.1928 - ac - ETA: 34s - loss: - ETA: 33s - loss: 0.1975  - ETA: 31s - loss: 0.1965 - ac - ETA: - ETA: 28s - lo - ETA: 20s - loss: 0.1972 - accur - ETA: 19s - loss: 0.19 - ETA: 18s - loss: 0.1962 - accuracy: 0.9 - ETA: 18s - loss: 0.19 - ETA: 17s - loss: 0.1971 - ETA: 15s - loss: 0.19 - ETA: 14s - loss: 0.1974 - accu - ETA: 13s - loss: 0.1974 - accu - ETA: 12s - loss: 0.1975 - accuracy - ETA: 12s - loss: 0.1975 - ETA: 11s - loss: 0.1970 - ac - ETA: 10s - los - ETA: 7s - loss: 0.1969  - ETA: 4s - l - ETA: 3s - loss: 0.1979 - accuracy: 0. - ETA: 3s - loss: 0.1981 - accuracy: 0. - ETA: 3s - loss: 0.1980 - accu - ETA: 2s - loss: 0.1979 - accuracy - ETA: 2s - loss: 0.1979 - accuracy: 0.95 - ETA: 2s - loss: 0.1979 - accuracy - ETA: 2s - loss: 0.1982 - accu - ETA: 1s - loss: 0.1982 - accuracy: 0. - ETA: 1s - loss: 0.1983 -  - ETA: 0s - loss: 0.1981 - accura - ETA: 0s - loss: 0.1981 - accura - ETA: 0s - loss: 0.1983 - accuracy: 0.95 - ETA: 0s - loss: 0.1983 - accuracy\n",
      "Epoch 00021: val_accuracy did not improve from 0.90430\n",
      "781/781 [==============================] - 55s 71ms/step - loss: 0.1985 - accuracy: 0.9575 - val_loss: 0.5055 - val_accuracy: 0.8922\n",
      "Epoch 22/25\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.1970 - accuracy: 0.9579 - ETA - ETA: 44s - loss: 0.1870 - ETA: 43s - loss: 0.1873 - ac - ETA: 42s - loss: 0 - ETA: 41s - loss: 0.1893 - acc - ETA: 40s - loss: 0.1885 - accuracy: 0.96 - ETA - ETA: 37s - loss: 0.1892 - accuracy: 0. - ETA: 37s - l - ETA: 35s - loss:  - ETA: 33s - loss: 0.191 - ETA: 32s - loss: 0.1910 - accuracy: 0.96 - ETA: 32s - loss: 0.1910 - accuracy: 0.961 - ETA: 32s - loss: 0.1910 - accur - ETA: 31s - loss - ETA: 29s - loss: 0.1910 - a - ETA: 28s - loss: 0.1909 - accura - ETA: 28s - loss: 0.1911 - accu - ETA:  - ETA: 24s - loss - ETA: 23s - loss: 0.1933 - ac - ETA: 22s - loss: 0.1926 - accur - ETA: 21s - loss: 0.1927 - accur - ETA: 20s - loss: 0.1927 - a - ETA: 19s - loss: 0.1931 - - ETA: 18s - loss: 0. - ETA: 14s - loss - ETA: 12s - loss: 0.1959 -  - ETA: 11s - loss: 0.1956 - - ETA:  - ETA: 1s - loss: 0.1974 - accuracy:  - ETA: 1s - loss: 0.1973 - ac - ETA: 0s - loss: 0.1971 - ac - ETA: 0s - loss: 0.1971 - ac\n",
      "Epoch 00022: val_accuracy did not improve from 0.90430\n",
      "781/781 [==============================] - 56s 72ms/step - loss: 0.1970 - accuracy: 0.9579 - val_loss: 0.5070 - val_accuracy: 0.8937\n",
      "Epoch 23/25\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.1940 - accuracy: 0.9587 - ETA: 47s - loss: 0.202 - ETA: 45s - loss: 0.1952 - accuracy: 0. - ETA: 45s - los - ETA: - ETA: 41s - loss: 0.1897 - accuracy: 0 - ETA: 41s - loss: 0.1916 - accuracy: 0. - ETA: 40s - loss: 0.1916 - - ETA: 36s - lo - ETA: 34s - loss: 0.1919 - accuracy: 0 - ETA: 34s - loss: 0.1913 - accurac - ETA: 33s - loss: 0.1907 - accuracy: 0.96 - ETA: 33s - loss: 0.1904 - - ETA: 32s - loss: 0.1899 - accuracy:  - ETA: 32s - loss: 0.18 - - ETA: 28s - loss: 0.1897 - accuracy: 0.9 - ETA: 28s - loss: 0.1903 - accuracy: 0.96 - ETA: 27s - loss: 0.1902 - accuracy: 0.96 - ETA: 27s - loss: 0.1899 - accu - ETA: 27s - loss - ETA: 25s - loss: 0.1918 - acc  - E - - ETA: 1s - loss: 0.1938 - accura - ETA: 0s - loss: 0.1938 - accuracy - ETA: 0s - loss: 0.1937 \n",
      "Epoch 00023: val_accuracy did not improve from 0.90430\n",
      "781/781 [==============================] - 56s 72ms/step - loss: 0.1940 - accuracy: 0.9587 - val_loss: 0.4668 - val_accuracy: 0.8976\n",
      "Epoch 24/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "781/781 [==============================] - ETA: 0s - loss: 0.1932 - accuracy: 0.9594 - ETA: 50s - loss: 0.1916 - accuracy: 0.9 - ETA: 50s - loss: 0.1908 - accuracy: 0.956 - ETA: 50s - loss: 0.1918 -  - ETA: 48s - loss: 0.1929 - accura - ETA: 45s - loss: 0.1840 - ETA: 44s - loss: 0.1829 - accuracy - ETA: 43s - loss: 0.1826 - accuracy: 0 - ETA: 40s - loss: 0.1887 - accur - ETA: 39s - loss: 0.1896 - accuracy: 0.96 - ETA: 39s -  - ETA: 37s - loss: 0.1911 - accuracy: 0. - ETA: 36s - loss: 0.1910 - accuracy: 0.961 - ETA: 36s - loss: 0.1907 - accuracy: 0.96 - ETA: 36s - loss: 0.1906 - ac - ETA: 35s - loss: 0.1901 - a - ETA: 34s - loss: 0.1908 - accurac - ETA: 33 - ETA: 31s - loss: 0.1921 - accur - ETA: 3 - ETA:  - ETA: 25s - loss: 0.1917 - ETA: 24s - loss: 0.1918 - accuracy: 0. - ETA: 24s - loss: 0.1917 - accuracy - ETA: 23s - loss: 0.1917 - accurac -  - ETA: 20s - loss: 0.1921 - accuracy - ETA: 20s - loss: 0.1923 - accuracy: 0.9 - ETA: 19s - loss: 0.1921 - accur - ETA: 19s - loss: 0.1925 - accuracy: 0.9 - ETA: 18s - loss: 0.1925  - ETA: 17s - loss - ETA: 15\n",
      "Epoch 00024: val_accuracy did not improve from 0.90430\n",
      "781/781 [==============================] - 57s 72ms/step - loss: 0.1932 - accuracy: 0.9594 - val_loss: 0.4653 - val_accuracy: 0.9002\n",
      "Epoch 25/25\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.1941 - accuracy: 0.9592 - ETA: - ETA: 44s - loss: 0.1905 - ac - ETA: 43s - loss: 0.1868 - accuracy: 0. - ETA: 43s - loss: 0.1878 - accuracy: 0.96 - ETA: 43s - l - ETA: 40s - loss: 0.1849 - accuracy: 0.963 - ETA: 40s - loss: 0.1849 - accuracy:  - ETA: 4 - ETA: 38s - loss: 0.1874 - accuracy: 0.9 - ETA: 38s - loss: 0.1876 - accuracy: 0.96 - ETA: 37s - loss: 0.1888 - accur - ETA: 37s - loss: 0.1900 - accuracy - ETA: 36s - loss: 0.1903 - accuracy: 0. - ETA: 36 - ETA: 31s - loss: 0.1925 - accuracy: 0.959 - ETA: 31s - loss: 0.1924 - accuracy: 0 - ETA: 30s - loss: 0.1929 - accuracy - ETA: 30s - loss: 0.1929 - accuracy: 0.958 - ETA: 30s - lo - ETA: 16s - loss: 0.1925 - accur - ETA: 15s - loss: 0.1922 - accuracy: 0.959 - ETA: 15s - loss: 0.1922 - - ETA: 14s - loss: 0.1916 - - ETA: 13s - loss: 0.1919 - accuracy:  - ETA: 13s - loss: 0.1 - ETA - ETA: 0s - loss:\n",
      "Epoch 00025: val_accuracy did not improve from 0.90430\n",
      "781/781 [==============================] - 56s 71ms/step - loss: 0.1941 - accuracy: 0.9592 - val_loss: 0.4354 - val_accuracy: 0.9038\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24af8c41820>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(img_gen,\n",
    "          steps_per_epoch=steps,\n",
    "          epochs=25,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, y_test),\n",
    "          callbacks=[checkpoint,tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 7780), started 13:14:04 ago. (Use '!kill 7780' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-2a562129bf00cbff\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-2a562129bf00cbff\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 5s 12ms/step - loss: 0.4338 - accuracy: 0.9043\n",
      "Test loss: 0.43384525179862976\n",
      "Test accuracy: 0.9042999744415283\n"
     ]
    }
   ],
   "source": [
    "best_model = load_model('my_best_model.epoch15-accuracy0.90.hdf5')\n",
    "score = best_model.evaluate(X_test, y_test, verbose=1)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "DenseNet - cifar10.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
